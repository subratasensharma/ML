{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pierluigiferrari/ssd_keras/blob/master/models/keras_ssd7.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Lambda, Conv2D, MaxPooling2D, BatchNormalization, ELU, Reshape, Concatenate, Activation\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect ratios =  [[2.65, 2.85, 3.25], [2.65, 2.85, 3.25], [2.65, 2.85, 3.25], [2.65, 2.85, 3.25]]\n",
      "==============================================================================\n",
      "++++++++++++++++++++++++  n_boxes =  3\n",
      "------------------------  n_boxes =  [3, 3, 3, 3]\n",
      "[None, None, None, None]\n",
      "[None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "# Compute the anchor box parameters.\n",
    "############################################################################\n",
    "\n",
    "aspect_ratios_per_layer = None\n",
    "\n",
    "# aspect_ratios_global=[0.5, 1.0, 2.0]\n",
    "aspect_ratios_global=[2.65, 2.85, 3.25]\n",
    "\n",
    "# aspect_ratios_global (list, optional): The list of aspect ratios for which anchor boxes are to be\n",
    "# generated. This list is valid for all prediction layers. Note that you should set the aspect ratios such\n",
    "# that the resulting anchor box shapes roughly correspond to the shapes of the objects you are trying to detect.\n",
    "\n",
    "n_predictor_layers = 4 # The number of predictor conv layers in the network\n",
    "n_classes = 5 # (no. of classes)\n",
    "n_classes = n_classes + 1 # Account for the background class.\n",
    "\n",
    "two_boxes_for_ar1=True\n",
    "\n",
    "# two_boxes_for_ar1 (bool, optional): Only relevant for aspect ratio lists that contain 1. Will be ignored otherwise.\n",
    "# If `True`, two anchor boxes will be generated for aspect ratio 1. The first will be generated\n",
    "# using the scaling factor for the respective layer, the second one will be generated using\n",
    "# geometric mean of said scaling factor and next bigger scaling factor.\n",
    "\n",
    "steps = None\n",
    "offsets = None\n",
    "\n",
    "# Set the aspect ratios for each predictor layer. These are only needed for the anchor box layers.\n",
    "if aspect_ratios_per_layer:\n",
    "    aspect_ratios = aspect_ratios_per_layer\n",
    "else:\n",
    "    aspect_ratios = [aspect_ratios_global] * n_predictor_layers\n",
    "    \n",
    "print('aspect ratios = ', aspect_ratios)\n",
    "print('==============================================================================')\n",
    "\n",
    "# Compute the number of boxes to be predicted per cell for each predictor layer.\n",
    "# We need this so that we know how many channels the predictor layers need to have.\n",
    "if aspect_ratios_per_layer:\n",
    "    n_boxes = []\n",
    "    for ar in aspect_ratios_per_layer:\n",
    "        if (1 in ar) & two_boxes_for_ar1:\n",
    "            n_boxes.append(len(ar) + 1) # +1 for the second box for aspect ratio 1\n",
    "        else:\n",
    "            n_boxes.append(len(ar))\n",
    "else: # If only a global aspect ratio list was passed, then the number of boxes is the same for each predictor layer\n",
    "    if (1 in aspect_ratios_global) & two_boxes_for_ar1:\n",
    "        n_boxes = len(aspect_ratios_global) + 1\n",
    "    else:\n",
    "        n_boxes = len(aspect_ratios_global)\n",
    "        print('++++++++++++++++++++++++  n_boxes = ', n_boxes)\n",
    "    n_boxes = [n_boxes] * n_predictor_layers\n",
    "    print('------------------------  n_boxes = ', n_boxes)\n",
    "\n",
    "if steps is None:\n",
    "    steps = [None] * n_predictor_layers\n",
    "if offsets is None:\n",
    "    offsets = [None] * n_predictor_layers\n",
    "print(steps)\n",
    "print(offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 608, 608, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 608, 608, 32)      2432      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 608, 608, 32)      128       \n",
      "_________________________________________________________________\n",
      "elu1 (ELU)                   (None, 608, 608, 32)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 304, 304, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 304, 304, 48)      13872     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 304, 304, 48)      192       \n",
      "_________________________________________________________________\n",
      "elu2 (ELU)                   (None, 304, 304, 48)      0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 152, 152, 48)      0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 152, 152, 64)      27712     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 152, 152, 64)      256       \n",
      "_________________________________________________________________\n",
      "elu3 (ELU)                   (None, 152, 152, 64)      0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 76, 76, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 76, 76, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 76, 76, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu4 (ELU)                   (None, 76, 76, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 38, 38, 48)        27696     \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (None, 38, 38, 48)        192       \n",
      "_________________________________________________________________\n",
      "elu5 (ELU)                   (None, 38, 38, 48)        0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 19, 19, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 19, 19, 48)        20784     \n",
      "_________________________________________________________________\n",
      "bn6 (BatchNormalization)     (None, 19, 19, 48)        192       \n",
      "_________________________________________________________________\n",
      "elu6 (ELU)                   (None, 19, 19, 48)        0         \n",
      "_________________________________________________________________\n",
      "pool6 (MaxPooling2D)         (None, 9, 9, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv7 (Conv2D)               (None, 9, 9, 32)          13856     \n",
      "_________________________________________________________________\n",
      "bn7 (BatchNormalization)     (None, 9, 9, 32)          128       \n",
      "_________________________________________________________________\n",
      "elu7 (ELU)                   (None, 9, 9, 32)          0         \n",
      "=================================================================\n",
      "Total params: 144,624\n",
      "Trainable params: 143,952\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Base Model\n",
    "\n",
    "l2_reg = 0.0\n",
    "\n",
    "# x = Input(shape=(img_height, img_width, img_channels))\n",
    "\n",
    "x = Input(shape=(608, 608, 3))\n",
    "\n",
    "\"\"\"\n",
    "# The following identity layer is only needed so that the subsequent lambda layers can be optional.\n",
    "x1 = Lambda(identity_layer, output_shape=(img_height, img_width, img_channels), name='identity_layer')(x)\n",
    "if not (subtract_mean is None):\n",
    "    x1 = Lambda(input_mean_normalization, output_shape=(img_height, img_width, img_channels), name='input_mean_normalization')(x1)\n",
    "if not (divide_by_stddev is None):\n",
    "    x1 = Lambda(input_stddev_normalization, output_shape=(img_height, img_width, img_channels), name='input_stddev_normalization')(x1)\n",
    "if swap_channels:\n",
    "    x1 = Lambda(input_channel_swap, output_shape=(img_height, img_width, img_channels), name='input_channel_swap')(x1)\n",
    "\"\"\"\n",
    "\n",
    "conv1 = Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv1')(x)\n",
    "conv1 = BatchNormalization(axis=3, momentum=0.99, name='bn1')(conv1) # Tensorflow uses filter format [filter_height, filter_width, in_channels, out_channels], hence axis = 3\n",
    "conv1 = ELU(name='elu1')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "\n",
    "conv2 = Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv2')(pool1)\n",
    "conv2 = BatchNormalization(axis=3, momentum=0.99, name='bn2')(conv2)\n",
    "conv2 = ELU(name='elu2')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), name='pool2')(conv2)\n",
    "\n",
    "conv3 = Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv3')(pool2)\n",
    "conv3 = BatchNormalization(axis=3, momentum=0.99, name='bn3')(conv3)\n",
    "conv3 = ELU(name='elu3')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2), name='pool3')(conv3)\n",
    "\n",
    "conv4 = Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv4')(pool3)\n",
    "conv4 = BatchNormalization(axis=3, momentum=0.99, name='bn4')(conv4)\n",
    "conv4 = ELU(name='elu4')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2), name='pool4')(conv4)\n",
    "\n",
    "conv5 = Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv5')(pool4)\n",
    "conv5 = BatchNormalization(axis=3, momentum=0.99, name='bn5')(conv5)\n",
    "conv5 = ELU(name='elu5')(conv5)\n",
    "pool5 = MaxPooling2D(pool_size=(2, 2), name='pool5')(conv5)\n",
    "\n",
    "conv6 = Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv6')(pool5)\n",
    "conv6 = BatchNormalization(axis=3, momentum=0.99, name='bn6')(conv6)\n",
    "conv6 = ELU(name='elu6')(conv6)\n",
    "pool6 = MaxPooling2D(pool_size=(2, 2), name='pool6')(conv6)\n",
    "\n",
    "conv7 = Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv7')(pool6)\n",
    "conv7 = BatchNormalization(axis=3, momentum=0.99, name='bn7')(conv7)\n",
    "conv7 = ELU(name='elu7')(conv7)\n",
    "\n",
    "model = Model(inputs=x, outputs=conv7)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = Input(shape=(608, 608, 3))\n",
    "\n",
    "\"\"\"\n",
    "# The following identity layer is only needed so that the subsequent lambda layers can be optional.\n",
    "x1 = Lambda(identity_layer, output_shape=(img_height, img_width, img_channels), name='identity_layer')(x)\n",
    "if not (subtract_mean is None):\n",
    "    x1 = Lambda(input_mean_normalization, output_shape=(img_height, img_width, img_channels), name='input_mean_normalization')(x1)\n",
    "if not (divide_by_stddev is None):\n",
    "    x1 = Lambda(input_stddev_normalization, output_shape=(img_height, img_width, img_channels), name='input_stddev_normalization')(x1)\n",
    "if swap_channels:\n",
    "    x1 = Lambda(input_channel_swap, output_shape=(img_height, img_width, img_channels), name='input_channel_swap')(x1)\n",
    "\"\"\"\n",
    "\n",
    "conv1 = Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv1')(x)\n",
    "conv1 = BatchNormalization(axis=3, momentum=0.99, name='bn1')(conv1) # Tensorflow uses filter format [filter_height, filter_width, in_channels, out_channels], hence axis = 3\n",
    "conv1 = ELU(name='elu1')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "\n",
    "conv2 = Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv2')(pool1)\n",
    "conv2 = BatchNormalization(axis=3, momentum=0.99, name='bn2')(conv2)\n",
    "conv2 = ELU(name='elu2')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), name='pool2')(conv2)\n",
    "\n",
    "conv3 = Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv3')(pool2)\n",
    "conv3 = BatchNormalization(axis=3, momentum=0.99, name='bn3')(conv3)\n",
    "conv3 = ELU(name='elu3')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2), name='pool3')(conv3)\n",
    "\n",
    "conv4 = Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv4')(pool3)\n",
    "conv4 = BatchNormalization(axis=3, momentum=0.99, name='bn4')(conv4)\n",
    "conv4 = ELU(name='elu4')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2), name='pool4')(conv4)\n",
    "\n",
    "conv5 = Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv5')(pool4)\n",
    "conv5 = BatchNormalization(axis=3, momentum=0.99, name='bn5')(conv5)\n",
    "conv5 = ELU(name='elu5')(conv5)\n",
    "pool5 = MaxPooling2D(pool_size=(2, 2), name='pool5')(conv5)\n",
    "\n",
    "conv6 = Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv6')(pool5)\n",
    "conv6 = BatchNormalization(axis=3, momentum=0.99, name='bn6')(conv6)\n",
    "conv6 = ELU(name='elu6')(conv6)\n",
    "pool6 = MaxPooling2D(pool_size=(2, 2), name='pool6')(conv6)\n",
    "\n",
    "conv7 = Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv7')(pool6)\n",
    "conv7 = BatchNormalization(axis=3, momentum=0.99, name='bn7')(conv7)\n",
    "conv7 = ELU(name='elu7')(conv7)\n",
    "\n",
    "\n",
    "# Build the convolutional predictor layers on top of conv layers 4, 5, 6, and 7.\n",
    "# We build two predictor layers on top of each of these layers: One for class prediction (classification), one for box coordinate prediction (localization)\n",
    "# We precidt `n_classes` confidence values for each box, hence the `classes` predictors have depth `n_boxes * n_classes`\n",
    "# We predict 4 box coordinates for each box, hence the `boxes` predictors have depth `n_boxes * 4`\n",
    "# Output shape of `classes`: `(batch, height, width, n_boxes * n_classes)`\n",
    "\n",
    "classes4 = Conv2D(n_boxes[0] * n_classes, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes4')(conv4)\n",
    "classes5 = Conv2D(n_boxes[1] * n_classes, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes5')(conv5)\n",
    "classes6 = Conv2D(n_boxes[2] * n_classes, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes6')(conv6)\n",
    "classes7 = Conv2D(n_boxes[3] * n_classes, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes7')(conv7)\n",
    "# Output shape of `boxes`: `(batch, height, width, n_boxes * 4)`\n",
    "boxes4 = Conv2D(n_boxes[0] * 4, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes4')(conv4)\n",
    "boxes5 = Conv2D(n_boxes[1] * 4, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes5')(conv5)\n",
    "boxes6 = Conv2D(n_boxes[2] * 4, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes6')(conv6)\n",
    "boxes7 = Conv2D(n_boxes[3] * 4, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes7')(conv7)\n",
    "\n",
    "model_1_class = Model(inputs=x, outputs=classes4)\n",
    "model_2_class = Model(inputs=x, outputs=classes5)\n",
    "model_3_class = Model(inputs=x, outputs=classes6)\n",
    "model_4_class = Model(inputs=x, outputs=classes7)\n",
    "\n",
    "model_1_boxes = Model(inputs=x, outputs=boxes4)\n",
    "model_2_boxes = Model(inputs=x, outputs=boxes5)\n",
    "model_3_boxes = Model(inputs=x, outputs=boxes6)\n",
    "model_4_boxes = Model(inputs=x, outputs=boxes7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 608, 608, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 608, 608, 32)      2432      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 608, 608, 32)      128       \n",
      "_________________________________________________________________\n",
      "elu1 (ELU)                   (None, 608, 608, 32)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 304, 304, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 304, 304, 48)      13872     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 304, 304, 48)      192       \n",
      "_________________________________________________________________\n",
      "elu2 (ELU)                   (None, 304, 304, 48)      0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 152, 152, 48)      0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 152, 152, 64)      27712     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 152, 152, 64)      256       \n",
      "_________________________________________________________________\n",
      "elu3 (ELU)                   (None, 152, 152, 64)      0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 76, 76, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 76, 76, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 76, 76, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu4 (ELU)                   (None, 76, 76, 64)        0         \n",
      "_________________________________________________________________\n",
      "classes4 (Conv2D)            (None, 76, 76, 18)        10386     \n",
      "=================================================================\n",
      "Total params: 92,162\n",
      "Trainable params: 91,746\n",
      "Non-trainable params: 416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1_class.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.3 0.5 0.7 0.9]\n"
     ]
    }
   ],
   "source": [
    "# scales (list, optional): A list of floats containing scaling factors per convolutional predictor layer.\n",
    "# This list must be one element longer than the number of predictor layers. The first `k` elements are the\n",
    "# scaling factors for the `k` predictor layers, while the last element is used for the second box\n",
    "# for aspect ratio 1 in the last predictor layer if `two_boxes_for_ar1` is `True`. This additional\n",
    "# last scaling factor must be passed either way, even if it is not being used. If a list is passed,\n",
    "# this argument overrides `min_scale` and `max_scale`. All scaling factors must be greater than zero.\n",
    "\n",
    "min_scale = 0.1\n",
    "max_scale = 0.9\n",
    "scales = np.linspace(min_scale, max_scale, n_predictor_layers+1)\n",
    "print(scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variances (list, optional): A list of 4 floats >0. The anchor box offset for each coordinate will be divided by\n",
    "# its respective variance value.\n",
    "\n",
    "variances = [1., 1., 1., 1.]\n",
    "variances = np.array(variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect ratios =  [[2.65, 2.85, 3.25], [2.65, 2.85, 3.25], [2.65, 2.85, 3.25], [2.65, 2.85, 3.25]]\n",
      "[None, None, None, None]\n",
      "[None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print('aspect ratios = ', aspect_ratios)\n",
    "print(steps)\n",
    "print(offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.65, 2.85, 3.25]\n",
      "[2.65, 2.85, 3.25]\n",
      "[2.65, 2.85, 3.25]\n",
      "[2.65, 2.85, 3.25]\n"
     ]
    }
   ],
   "source": [
    "for ar in aspect_ratios:\n",
    "    print(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchorboxes(img_height,img_width,this_scale,next_scale,aspect_ratiostwo_boxes_for_ar1=True,\n",
    "                 this_steps=None,this_offsets=None,clip_boxes=False,variancescoords='centroids',\n",
    "                 normalize_coords=False):\n",
    "    \n",
    "    # Compute box width and height for each aspect ratio\n",
    "    # The shorter side of the image will be used to compute `w` and `h` using `scale` and `aspect_ratios`.\n",
    "    size = min(img_height, img_width)\n",
    "    # Compute the box widths and and heights for all aspect ratios\n",
    "    wh_list = []\n",
    "    for ar in aspect_ratios:\n",
    "        if (ar == 1):\n",
    "            # Compute the regular anchor box for aspect ratio 1.\n",
    "            box_height = box_width = this_scale * size\n",
    "            wh_list.append((box_width, box_height))\n",
    "            if two_boxes_for_ar1:\n",
    "                \n",
    "                # Compute one slightly larger version using the geometric mean of this scale value and the next.\n",
    "                box_height = box_width = np.sqrt(this_scale * next_scale) * size\n",
    "                wh_list.append((box_width, box_height))\n",
    "        else:\n",
    "            box_height = this_scale * size / np.sqrt(ar)\n",
    "            box_width = this_scale * size * np.sqrt(ar)\n",
    "            wh_list.append((box_width, box_height))\n",
    "    wh_list = np.array(wh_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
