{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-a117b699a4da>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a117b699a4da>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    Using TensorFlow backend.\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# In [1]:\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *\n",
    "\n",
    "Using TensorFlow backend.\n",
    "\n",
    "# In [2]:\n",
    "limit_mem()\n",
    "\n",
    "# In [3]:\n",
    "from keras.datasets.cifar10 import load_batch\n",
    "\n",
    "# This notebook contains a Keras implementation of Huang et al.'s DenseNet\n",
    "\n",
    "# Our motivation behind studying DenseNet is because of how well it works with limited data.\n",
    "\n",
    "# DenseNet beats state-of-the-art results on CIFAR-10/CIFAR-100 w/ and w/o data augmentation, but the performance \n",
    "# increase is most pronounced w/o data augmentation.\n",
    "\n",
    "# Compare to FractalNet, state-of-the-art on both datasets:\n",
    "\n",
    "#    a) CIFAR-10: ~ 30 % performance increase w/ DenseNet\n",
    "#    b) CIFAR-100: ~ 30 % performance increase w/ DenseNet\n",
    "# That increase is motivation enough.\n",
    "\n",
    "# So what is a DenseNet?\n",
    "\n",
    "# Put simply, DenseNet is a Resnet where we replace addition with concatenation.\n",
    "\n",
    "# Idea¶\n",
    "# Recall that in broad terms, a Resnet is a Convnet that uses residual block structures.\n",
    "\n",
    "# These \"blocks\" work as follows:\n",
    "\n",
    "#    - Let Lt be the input layer to block\n",
    "#    - Perform conv layer transformations/activations on Lt, denote by f(t)\n",
    "#    - Call output layer of block Lt+1\n",
    "#    - Define Lt+1 = f(Lt)+ Lt\n",
    "#             - That is, total output is the conv layer outputs plus the original input\n",
    "#    - We call residual block b.c. f(Lt)=Lt+1 - Lt, the residual\n",
    "\n",
    "# As mentioned, the difference w/ DenseNet is instead of adding Lt to Lt+1, it is being concatenated.\n",
    "\n",
    "# As with Resnet, DenseNet consists of multiple blocks. Therefore, there is a recursive relationship across blocks:\n",
    "\n",
    "#    - Block Bi takes as input the ouput of block Bi-1 concatenated with the input of Bi-1\n",
    "#    - The input to Bi-1 is the ouput of block Bi-2 concatenated with the input of Bi-2\n",
    "#    - So on and so forth\n",
    "#\n",
    "# The number of filters added to each layer needs to be monitored, given that the input space for each block keeps growing.\n",
    "\n",
    "# Huang et al. calls the # of filters added at each layer the growth rate, and appropriately denotes this number with the related letter k.\n",
    "\n",
    "# Densenet / CIFAR 10¶\n",
    "# From http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "\n",
    "# Let's load data.\n",
    "\n",
    "# In [4]:\n",
    "def load_data():\n",
    "    path = 'data/cifar-10-batches-py'\n",
    "    num_train_samples = 50000\n",
    "    x_train = np.zeros((num_train_samples, 3, 32, 32), dtype='uint8')\n",
    "    y_train = np.zeros((num_train_samples,), dtype='uint8')\n",
    "    for i in range(1, 6):\n",
    "        data, labels = load_batch(os.path.join(path, 'data_batch_' + str(i)))\n",
    "        x_train[(i - 1) * 10000: i * 10000, :, :, :] = data\n",
    "        y_train[(i - 1) * 10000: i * 10000] = labels\n",
    "    x_test, y_test = load_batch(os.path.join(path, 'test_batch'))\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "    x_train = x_train.transpose(0, 2, 3, 1)\n",
    "    x_test = x_test.transpose(0, 2, 3, 1)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "# In [5]:\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "Here's an example of CIFAR-10\n",
    "\n",
    "# In [6]:\n",
    "plt.imshow(x_train[1])\n",
    "# Out[6]:\n",
    "<matplotlib.image.AxesImage at 0x7f137c53d470>\n",
    "\n",
    "# We want to normalize pixel values (0-255) to unit interval.\n",
    "\n",
    "# In [7]:\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "\n",
    "# Densenet¶\n",
    "\n",
    "# The pieces¶\n",
    "\n",
    "# Let's make some helper functions for piecing together our network using Keras' Functional API.\n",
    "\n",
    "# These components should all be familiar to you:\n",
    "\n",
    "#    - Relu activation\n",
    "#    - Dropout regularization\n",
    "#    - Batch-normalization\n",
    "\n",
    "# In [8]:\n",
    "def relu(x): return Activation('relu')(x)\n",
    "def dropout(x, p): return Dropout(p)(x) if p else x\n",
    "def bn(x): return BatchNormalization(mode=0, axis=-1)(x)\n",
    "def relu_bn(x): return relu(bn(x))\n",
    "\n",
    "# Convolutional layer:\n",
    "\n",
    "#     - L2 Regularization\n",
    "#     - 'same' border mode returns same width/height\n",
    "#     - Pass output through Dropout\n",
    "\n",
    "# In [9]:\n",
    "# nf = no. of filters, sz X sz = kernel_size, border_mode = padding, no activation, init = intializer, \n",
    "# W_regularizer = Regularizer function applied to the kernel weights matrix, p = Dropout %, wd=value of regulizer\n",
    "\n",
    "def conv(x, nf, sz, wd, p):\n",
    "    \n",
    "    x = Convolution2D(nf, sz, sz, init='he_uniform', border_mode='same', \n",
    "                          W_regularizer=l2(wd))(x)\n",
    "    return dropout(x,p)\n",
    "\n",
    "# Define ConvBlock as sequence:\n",
    "\n",
    "#     - Batchnorm\n",
    "#     - ReLU Activation\n",
    "#     - Conv layer (conv w/ Dropout)\n",
    "\n",
    "# The authors also use something called a bottleneck layer to reduce dimensionality of inputs.\n",
    "\n",
    "# Recall that the filter space dimensionality grows at each block. The input dimensionality will determine the\n",
    "# dimensionality of your convolution weight matrices, i.e. # of parameters.\n",
    "\n",
    "# At size 3x3 or larger, convolutions can become extremely costly and # of parameters can increase quickly as a\n",
    "# function of the input feature (filter) space. Therefore, a smart approach is to reduce dimensionality of filters\n",
    "# by using a 1x1 convolution w/ smaller # of filters before the larger convolution.\n",
    "\n",
    "# Bottleneck consists of:\n",
    "\n",
    "#     - 1x1 conv\n",
    "#     - Compress # of filters into growth factor nf * 4\n",
    "#     - Batchnorm -> ReLU\n",
    "\n",
    "# In [10]:\n",
    "def conv_block(x, nf, bottleneck=False, p=None, wd=0):\n",
    "    x = relu_bn(x)\n",
    "    if bottleneck: x = relu_bn(conv(x, nf * 4, 1, wd, p))\n",
    "    return conv(x, nf, 3, wd, p)\n",
    ".\n",
    "# Now we can define the dense block:\n",
    "\n",
    "#     - Take given input x\n",
    "#     - Pass through a conv block for output b\n",
    "#     - Concatenate input x and conv block output b\n",
    "#     - Set concatenation as new input x for next block\n",
    "#     - Repeat\n",
    "\n",
    "# In [11]:\n",
    "def dense_block(x, nb_layers, growth_rate, bottleneck=False, p=None, wd=0):\n",
    "    if bottleneck: nb_layers //= 2\n",
    "    for i in range(nb_layers):\n",
    "        b = conv_block(x, growth_rate, bottleneck=bottleneck, p=p, wd=wd)\n",
    "        x = merge([x,b], mode='concat', concat_axis=-1)\n",
    "    return x\n",
    "\n",
    "# As typical for CV architectures, we'll do some pooling after computation.\n",
    "\n",
    "# We'll define this unit as the transition block, and we'll put one between each dense block.\n",
    "\n",
    "# Aside from BN -> ReLU and Average Pooling, there is also an option for filter compression in this block. This\n",
    "# is simply feature reduction via 1x1 conv as discussed before, where the new # of filters is a percentage of the\n",
    "# incoming # of filters.\n",
    "\n",
    "# Together with bottleneck, compression has been shown to improve performance and computational efficiency of\n",
    "# DenseNet architectures. (the authors call this DenseNet-BC)\n",
    "\n",
    "# In [12]:\n",
    "def transition_block(x, compression=1.0, p=None, wd=0):\n",
    "    nf = int(x.get_shape().as_list()[-1] * compression)\n",
    "    x = relu_bn(x)\n",
    "    x = conv(x, nf, 1, wd, p)\n",
    "    return AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "# Build the DenseNet model¶\n",
    "\n",
    "# We've now defined all the building blocks (literally) to put together a DenseNet.\n",
    "\n",
    "#     - nb_classes: number of classes\n",
    "#     - img_input: tuple of shape (channels, rows, columns) or (rows, columns, channels)\n",
    "#     - depth: total number of layers\n",
    "#          - Includes 4 extra non-block layers\n",
    "#               - 1 input conv, 3 output layers\n",
    "#     - nb_block: number of dense blocks (generally = 3).\n",
    "#          - NOTE: Layers / block are evenly allocated. Therefore nb_block must be a factor of (Depth - 4)\n",
    "#     - growth_rate: number of filters to add per dense block\n",
    "#     - nb_filter: initial number of filters\n",
    "#     - bottleneck: add bottleneck blocks\n",
    "#     - Compression: Filter compression factor in transition blocks.\n",
    "#     - p: dropout rate\n",
    "#     - wd: weight decay\n",
    "#     - activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'. Note that if\n",
    "#       sigmoid is used, classes must be 1.\n",
    "\n",
    "# Returns: keras tensor with nb_layers of conv_block appended\n",
    "\n",
    "# From start to finish, this generates:\n",
    "\n",
    "#     - Conv input layer\n",
    "#     - Alternate between Dense/Transition blocks nb_block times, ommitting Transition block after last Dense block\n",
    "#           - Each Dense block has (Depth-4)/nb_block layers\n",
    "#     - Pass final Dense block to BN -> ReLU\n",
    "#     - Global Avg Pooling\n",
    "#     - Dense layer w/ desired output activation\n",
    "\n",
    "# In [13]:\n",
    "def create_dense_net(nb_classes, img_input, depth=40, nb_block=3, \n",
    "     growth_rate=12, nb_filter=16, bottleneck=False, compression=1.0, p=None, wd=0, activation='softmax'):\n",
    "    \n",
    "    assert activation == 'softmax' or activation == 'sigmoid'\n",
    "    assert (depth - 4) % nb_block == 0\n",
    "    nb_layers_per_block = int((depth - 4) / nb_block)\n",
    "    nb_layers = [nb_layers_per_block] * nb_block\n",
    "\n",
    "    x = conv(img_input, nb_filter, 3, wd, 0)\n",
    "    for i,block in enumerate(nb_layers):\n",
    "        x = dense_block(x, block, growth_rate, bottleneck=bottleneck, p=p, wd=wd)\n",
    "        if i != len(nb_layers)-1:\n",
    "            x = transition_block(x, compression=compression, p=p, wd=wd)\n",
    "\n",
    "    x = relu_bn(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    return Dense(nb_classes, activation=activation, W_regularizer=l2(wd))(x)\n",
    "\n",
    "# Train¶\n",
    "\n",
    "# Now we can test it out on CIFAR-10.\n",
    "\n",
    "# In [14]:\n",
    "input_shape = (32,32,3)\n",
    "\n",
    "# In [15]:\n",
    "img_input = Input(shape=input_shape)\n",
    "\n",
    "# In [16]:\n",
    "x = create_dense_net(10, img_input, depth=100, nb_filter=16, compression=0.5, \n",
    "                     bottleneck=True, p=0.2, wd=1e-4)\n",
    "\n",
    "# In [17]:\n",
    "model = Model(img_input, x)\n",
    "\n",
    "# In [18]:\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "      optimizer=keras.optimizers.SGD(0.1, 0.9, nesterov=True), metrics=[\"accuracy\"])\n",
    "\n",
    "# In [19]:\n",
    "parms = {'verbose': 2, 'callbacks': [TQDMNotebookCallback()]}\n",
    "\n",
    "# In [20]:\n",
    "K.set_value(model.optimizer.lr, 0.1)\n",
    "\n",
    "# This will likely need to run overnight + lr annealing...\n",
    "\n",
    "# In [21]:\n",
    "model.fit(x_train, y_train, 64, 20, validation_data=(x_test, y_test), **parms)\n",
    "\n",
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/20\n",
    "561s - loss: 1.9801 - acc: 0.4810 - val_loss: 2.0473 - val_acc: 0.5045\n",
    "Epoch 2/20\n",
    "556s - loss: 1.4368 - acc: 0.6571 - val_loss: 1.8446 - val_acc: 0.5864\n",
    "Epoch 3/20\n",
    "547s - loss: 1.2204 - acc: 0.7122 - val_loss: 1.3181 - val_acc: 0.6696\n",
    "Epoch 4/20\n",
    "556s - loss: 1.0634 - acc: 0.7547 - val_loss: 1.3620 - val_acc: 0.6658\n",
    "Epoch 5/20\n",
    "560s - loss: 0.9536 - acc: 0.7829 - val_loss: 2.6235 - val_acc: 0.4702\n",
    "Epoch 6/20\n",
    "557s - loss: 0.8835 - acc: 0.8025 - val_loss: 2.4969 - val_acc: 0.4981\n",
    "Epoch 7/20\n",
    "551s - loss: 0.8293 - acc: 0.8155 - val_loss: 1.1944 - val_acc: 0.7281\n",
    "Epoch 8/20\n",
    "551s - loss: 0.7949 - acc: 0.8244 - val_loss: 1.1396 - val_acc: 0.7366\n",
    "Epoch 9/20\n",
    "551s - loss: 0.7620 - acc: 0.8340 - val_loss: 1.9196 - val_acc: 0.5916\n",
    "Epoch 10/20\n",
    "551s - loss: 0.7472 - acc: 0.8389 - val_loss: 2.6207 - val_acc: 0.4900\n",
    "Epoch 11/20\n",
    "550s - loss: 0.7251 - acc: 0.8449 - val_loss: 1.4957 - val_acc: 0.6859\n",
    "Epoch 12/20\n",
    "551s - loss: 0.7117 - acc: 0.8503 - val_loss: 1.0381 - val_acc: 0.7751\n",
    "Epoch 13/20\n",
    "552s - loss: 0.7006 - acc: 0.8547 - val_loss: 1.6471 - val_acc: 0.6685\n",
    "Epoch 14/20\n",
    "556s - loss: 0.6945 - acc: 0.8555 - val_loss: 0.9267 - val_acc: 0.8087\n",
    "Epoch 15/20\n",
    "551s - loss: 0.6859 - acc: 0.8592 - val_loss: 1.0987 - val_acc: 0.7642\n",
    "Epoch 16/20\n",
    "550s - loss: 0.6756 - acc: 0.8645 - val_loss: 0.9704 - val_acc: 0.7940\n",
    "Epoch 17/20\n",
    "551s - loss: 0.6730 - acc: 0.8642 - val_loss: 0.9401 - val_acc: 0.7800\n",
    "Epoch 18/20\n",
    "551s - loss: 0.6666 - acc: 0.8700 - val_loss: 0.9759 - val_acc: 0.7830\n",
    "Epoch 19/20\n",
    "550s - loss: 0.6654 - acc: 0.8709 - val_loss: 0.8896 - val_acc: 0.8044\n",
    "Epoch 20/20\n",
    "551s - loss: 0.6617 - acc: 0.8712 - val_loss: 1.1052 - val_acc: 0.7570\n",
    "\n",
    "# Out[21]:\n",
    "<keras.callbacks.History at 0x7f04f8b132b0>\n",
    "\n",
    "# In [22]:\n",
    "K.set_value(model.optimizer.lr, 0.01)\n",
    "\n",
    "# In [23]:\n",
    "model.fit(x_train, y_train, 64, 4, validation_data=(x_test, y_test), **parms)\n",
    "\n",
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/4\n",
    "550s - loss: 0.5463 - acc: 0.9128 - val_loss: 0.5737 - val_acc: 0.9033\n",
    "Epoch 2/4\n",
    "551s - loss: 0.4833 - acc: 0.9311 - val_loss: 0.5695 - val_acc: 0.9033\n",
    "Epoch 3/4\n",
    "551s - loss: 0.4575 - acc: 0.9366 - val_loss: 0.5590 - val_acc: 0.9051\n",
    "Epoch 4/4\n",
    "550s - loss: 0.4361 - acc: 0.9429 - val_loss: 0.5656 - val_acc: 0.9048\n",
    "\n",
    "# Out[23]:\n",
    "<keras.callbacks.History at 0x7f05ec7caf28>\n",
    "\n",
    "# In [24]:\n",
    "K.set_value(model.optimizer.lr, 0.1)\n",
    "\n",
    "# In [26]:\n",
    "model.fit(x_train, y_train, 64, 20, validation_data=(x_test, y_test), **parms)\n",
    "\n",
    "Train on 50000 samples, validate on 10000 samples\n",
    "\n",
    "Epoch 1/20\n",
    "551s - loss: 0.6589 - acc: 0.8728 - val_loss: 1.3259 - val_acc: 0.6935\n",
    "Epoch 2/20\n",
    "551s - loss: 0.6510 - acc: 0.8766 - val_loss: 0.9672 - val_acc: 0.7880\n",
    "Epoch 3/20\n",
    "551s - loss: 0.6508 - acc: 0.8784 - val_loss: 1.1104 - val_acc: 0.7581\n",
    "Epoch 4/20\n",
    "551s - loss: 0.6462 - acc: 0.8793 - val_loss: 1.0601 - val_acc: 0.7877\n",
    "Epoch 5/20\n",
    "550s - loss: 0.6456 - acc: 0.8816 - val_loss: 0.9799 - val_acc: 0.7876\n",
    "Epoch 6/20\n",
    "551s - loss: 0.6427 - acc: 0.8830 - val_loss: 0.9377 - val_acc: 0.8028\n",
    "Epoch 7/20\n",
    "551s - loss: 0.6409 - acc: 0.8837 - val_loss: 1.8484 - val_acc: 0.5932\n",
    "Epoch 8/20\n",
    "551s - loss: 0.6378 - acc: 0.8831 - val_loss: 1.1806 - val_acc: 0.7420\n",
    "Epoch 9/20\n",
    "550s - loss: 0.6381 - acc: 0.8843 - val_loss: 1.0799 - val_acc: 0.7774\n",
    "Epoch 10/20\n",
    "551s - loss: 0.6344 - acc: 0.8870 - val_loss: 0.9114 - val_acc: 0.8163\n",
    "Epoch 11/20\n",
    "561s - loss: 0.6394 - acc: 0.8858 - val_loss: 0.9710 - val_acc: 0.7982\n",
    "Epoch 12/20\n",
    "560s - loss: 0.6367 - acc: 0.8863 - val_loss: 0.8751 - val_acc: 0.8249\n",
    "Epoch 13/20\n",
    "561s - loss: 0.6230 - acc: 0.8899 - val_loss: 1.2588 - val_acc: 0.7254\n",
    "Epoch 14/20\n",
    "561s - loss: 0.6298 - acc: 0.8895 - val_loss: 0.9942 - val_acc: 0.7801\n",
    "Epoch 15/20\n",
    "560s - loss: 0.6321 - acc: 0.8888 - val_loss: 0.8516 - val_acc: 0.8378\n",
    "Epoch 16/20\n",
    "559s - loss: 0.6268 - acc: 0.8893 - val_loss: 0.8288 - val_acc: 0.8301\n",
    "Epoch 17/20\n",
    "561s - loss: 0.6279 - acc: 0.8904 - val_loss: 1.2768 - val_acc: 0.7219\n",
    "Epoch 18/20\n",
    "561s - loss: 0.6248 - acc: 0.8920 - val_loss: 0.9362 - val_acc: 0.8015\n",
    "Epoch 19/20\n",
    "561s - loss: 0.6184 - acc: 0.8941 - val_loss: 0.9204 - val_acc: 0.8181\n",
    "Epoch 20/20\n",
    "561s - loss: 0.6254 - acc: 0.8915 - val_loss: 1.0211 - val_acc: 0.7706\n",
    "\n",
    "# Out[26]:\n",
    "<keras.callbacks.History at 0x7f04f55fcb00>\n",
    "\n",
    "# In [27]:\n",
    "K.set_value(model.optimizer.lr, 0.01)\n",
    "\n",
    "# In [28]:\n",
    "model.fit(x_train, y_train, 64, 40, validation_data=(x_test, y_test), **parms)\n",
    "\n",
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/40\n",
    "556s - loss: 0.5141 - acc: 0.9320 - val_loss: 0.5652 - val_acc: 0.9165\n",
    "Epoch 2/40\n",
    "560s - loss: 0.4530 - acc: 0.9477 - val_loss: 0.5451 - val_acc: 0.9199\n",
    "Epoch 3/40\n",
    "560s - loss: 0.4290 - acc: 0.9546 - val_loss: 0.5409 - val_acc: 0.9188\n",
    "Epoch 4/40\n",
    "559s - loss: 0.4101 - acc: 0.9584 - val_loss: 0.5259 - val_acc: 0.9224\n",
    "Epoch 5/40\n",
    "549s - loss: 0.3934 - acc: 0.9620 - val_loss: 0.5365 - val_acc: 0.9198\n",
    "Epoch 6/40\n",
    "551s - loss: 0.3813 - acc: 0.9631 - val_loss: 0.5150 - val_acc: 0.9209\n",
    "Epoch 7/40\n",
    "556s - loss: 0.3685 - acc: 0.9644 - val_loss: 0.5238 - val_acc: 0.9197\n",
    "Epoch 8/40\n",
    "556s - loss: 0.3565 - acc: 0.9668 - val_loss: 0.5188 - val_acc: 0.9204\n",
    "Epoch 9/40\n",
    "555s - loss: 0.3430 - acc: 0.9693 - val_loss: 0.5078 - val_acc: 0.9206\n",
    "Epoch 10/40\n",
    "553s - loss: 0.3325 - acc: 0.9707 - val_loss: 0.5107 - val_acc: 0.9191\n",
    "Epoch 11/40\n",
    "556s - loss: 0.3220 - acc: 0.9721 - val_loss: 0.5091 - val_acc: 0.9191\n",
    "Epoch 12/40\n",
    "556s - loss: 0.3121 - acc: 0.9738 - val_loss: 0.5033 - val_acc: 0.9212\n",
    "Epoch 13/40\n",
    "556s - loss: 0.3082 - acc: 0.9723 - val_loss: 0.4970 - val_acc: 0.9226\n",
    "Epoch 14/40\n",
    "556s - loss: 0.2986 - acc: 0.9749 - val_loss: 0.5553 - val_acc: 0.9058\n",
    "Epoch 15/40\n",
    "555s - loss: 0.2913 - acc: 0.9746 - val_loss: 0.5065 - val_acc: 0.9203\n",
    "Epoch 16/40\n",
    "552s - loss: 0.2824 - acc: 0.9762 - val_loss: 0.4912 - val_acc: 0.9218\n",
    "Epoch 17/40\n",
    "554s - loss: 0.2774 - acc: 0.9764 - val_loss: 0.5191 - val_acc: 0.9125\n",
    "Epoch 18/40\n",
    "554s - loss: 0.2722 - acc: 0.9769 - val_loss: 0.5023 - val_acc: 0.9184\n",
    "Epoch 19/40\n",
    "550s - loss: 0.2654 - acc: 0.9771 - val_loss: 0.4965 - val_acc: 0.9183\n",
    "Epoch 20/40\n",
    "547s - loss: 0.2603 - acc: 0.9778 - val_loss: 0.5552 - val_acc: 0.9061\n",
    "Epoch 21/40\n",
    "547s - loss: 0.2549 - acc: 0.9779 - val_loss: 0.4868 - val_acc: 0.9168\n",
    "Epoch 22/40\n",
    "547s - loss: 0.2494 - acc: 0.9793 - val_loss: 0.4754 - val_acc: 0.9242\n",
    "Epoch 23/40\n",
    "547s - loss: 0.2462 - acc: 0.9785 - val_loss: 0.5014 - val_acc: 0.9136\n",
    "Epoch 24/40\n",
    "548s - loss: 0.2427 - acc: 0.9792 - val_loss: 0.5226 - val_acc: 0.9075\n",
    "Epoch 25/40\n",
    "547s - loss: 0.2376 - acc: 0.9794 - val_loss: 0.4829 - val_acc: 0.9159\n",
    "Epoch 26/40\n",
    "547s - loss: 0.2325 - acc: 0.9800 - val_loss: 0.5066 - val_acc: 0.9125\n",
    "Epoch 27/40\n",
    "548s - loss: 0.2312 - acc: 0.9790 - val_loss: 0.4887 - val_acc: 0.9155\n",
    "Epoch 28/40\n",
    "548s - loss: 0.2277 - acc: 0.9792 - val_loss: 0.4959 - val_acc: 0.9107\n",
    "Epoch 29/40\n",
    "547s - loss: 0.2255 - acc: 0.9788 - val_loss: 0.6025 - val_acc: 0.8956\n",
    "Epoch 30/40\n",
    "548s - loss: 0.2216 - acc: 0.9798 - val_loss: 0.4708 - val_acc: 0.9180\n",
    "Epoch 31/40\n",
    "548s - loss: 0.2238 - acc: 0.9772 - val_loss: 0.5193 - val_acc: 0.9084\n",
    "Epoch 32/40\n",
    "548s - loss: 0.2174 - acc: 0.9790 - val_loss: 0.5216 - val_acc: 0.9100\n",
    "Epoch 33/40\n",
    "547s - loss: 0.2176 - acc: 0.9782 - val_loss: 0.4960 - val_acc: 0.9153\n",
    "Epoch 34/40\n",
    "548s - loss: 0.2128 - acc: 0.9790 - val_loss: 0.4644 - val_acc: 0.9188\n",
    "Epoch 35/40\n",
    "548s - loss: 0.2113 - acc: 0.9795 - val_loss: 0.4759 - val_acc: 0.9196\n",
    "Epoch 36/40\n",
    "547s - loss: 0.2090 - acc: 0.9789 - val_loss: 0.5176 - val_acc: 0.9066\n",
    "Epoch 37/40\n",
    "548s - loss: 0.2078 - acc: 0.9802 - val_loss: 0.4602 - val_acc: 0.9208\n",
    "Epoch 38/40\n",
    "547s - loss: 0.2112 - acc: 0.9772 - val_loss: 0.4998 - val_acc: 0.9096\n",
    "Epoch 39/40\n",
    "548s - loss: 0.2051 - acc: 0.9794 - val_loss: 0.5156 - val_acc: 0.9066\n",
    "Epoch 40/40\n",
    "547s - loss: 0.2046 - acc: 0.9781 - val_loss: 0.4961 - val_acc: 0.9108\n",
    "\n",
    "# Out[28]:\n",
    "<keras.callbacks.History at 0x7f04f5497d30>\n",
    "\n",
    "# In [29]:\n",
    "K.set_value(model.optimizer.lr, 0.001)\n",
    "\n",
    "# In [30]:\n",
    "model.fit(x_train, y_train, 64, 20, validation_data=(x_test, y_test), **parms)\n",
    "\n",
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/20\n",
    "547s - loss: 0.1885 - acc: 0.9845 - val_loss: 0.4287 - val_acc: 0.9256\n",
    "Epoch 2/20\n",
    "548s - loss: 0.1772 - acc: 0.9886 - val_loss: 0.4198 - val_acc: 0.9279\n",
    "Epoch 3/20\n",
    "547s - loss: 0.1734 - acc: 0.9901 - val_loss: 0.4181 - val_acc: 0.9283\n",
    "Epoch 4/20\n",
    "547s - loss: 0.1706 - acc: 0.9910 - val_loss: 0.4188 - val_acc: 0.9280\n",
    "Epoch 5/20\n",
    "548s - loss: 0.1679 - acc: 0.9918 - val_loss: 0.4127 - val_acc: 0.9298\n",
    "Epoch 6/20\n",
    "548s - loss: 0.1670 - acc: 0.9921 - val_loss: 0.4159 - val_acc: 0.9301\n",
    "Epoch 7/20\n",
    "548s - loss: 0.1650 - acc: 0.9926 - val_loss: 0.4139 - val_acc: 0.9300\n",
    "Epoch 8/20\n",
    "547s - loss: 0.1631 - acc: 0.9933 - val_loss: 0.4087 - val_acc: 0.9304\n",
    "Epoch 9/20\n",
    "548s - loss: 0.1619 - acc: 0.9934 - val_loss: 0.4150 - val_acc: 0.9302\n",
    "Epoch 10/20\n",
    "547s - loss: 0.1609 - acc: 0.9939 - val_loss: 0.4154 - val_acc: 0.9294\n",
    "Epoch 11/20\n",
    "547s - loss: 0.1611 - acc: 0.9933 - val_loss: 0.4102 - val_acc: 0.9310\n",
    "Epoch 12/20\n",
    "547s - loss: 0.1584 - acc: 0.9943 - val_loss: 0.4105 - val_acc: 0.9306\n",
    "Epoch 13/20\n",
    "547s - loss: 0.1594 - acc: 0.9934 - val_loss: 0.4093 - val_acc: 0.9309\n",
    "Epoch 14/20\n",
    "547s - loss: 0.1582 - acc: 0.9940 - val_loss: 0.4110 - val_acc: 0.9298\n",
    "Epoch 15/20\n",
    "547s - loss: 0.1567 - acc: 0.9942 - val_loss: 0.4080 - val_acc: 0.9315\n",
    "Epoch 16/20\n",
    "547s - loss: 0.1565 - acc: 0.9940 - val_loss: 0.4113 - val_acc: 0.9304\n",
    "Epoch 17/20\n",
    "548s - loss: 0.1558 - acc: 0.9942 - val_loss: 0.4093 - val_acc: 0.9292\n",
    "Epoch 18/20\n",
    "548s - loss: 0.1561 - acc: 0.9939 - val_loss: 0.4079 - val_acc: 0.9310\n",
    "Epoch 19/20\n",
    "548s - loss: 0.1552 - acc: 0.9942 - val_loss: 0.4153 - val_acc: 0.9297\n",
    "Epoch 20/20\n",
    "547s - loss: 0.1535 - acc: 0.9951 - val_loss: 0.4069 - val_acc: 0.9313\n",
    "\n",
    "# Out[30]:\n",
    "<keras.callbacks.History at 0x7f05ec7ea6a0>\n",
    "\n",
    "# In [31]:\n",
    "K.set_value(model.optimizer.lr, 0.01)\n",
    "\n",
    "# In [32]:\n",
    "model.fit(x_train, y_train, 64, 10, validation_data=(x_test, y_test), **parms)\n",
    "\n",
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/10\n",
    "548s - loss: 0.1819 - acc: 0.9842 - val_loss: 0.4929 - val_acc: 0.9092\n",
    "Epoch 2/10\n",
    "547s - loss: 0.2018 - acc: 0.9751 - val_loss: 0.5761 - val_acc: 0.8880\n",
    "Epoch 3/10\n",
    "548s - loss: 0.2046 - acc: 0.9742 - val_loss: 0.5411 - val_acc: 0.8950\n",
    "Epoch 4/10\n",
    "548s - loss: 0.2008 - acc: 0.9765 - val_loss: 0.5607 - val_acc: 0.8957\n",
    "Epoch 5/10\n",
    "548s - loss: 0.1956 - acc: 0.9778 - val_loss: 0.4991 - val_acc: 0.9049\n",
    "Epoch 6/10\n",
    "548s - loss: 0.1996 - acc: 0.9760 - val_loss: 0.4714 - val_acc: 0.9112\n",
    "Epoch 7/10\n",
    "548s - loss: 0.1947 - acc: 0.9779 - val_loss: 0.5921 - val_acc: 0.8855\n",
    "Epoch 8/10\n",
    "547s - loss: 0.1958 - acc: 0.9770 - val_loss: 0.5096 - val_acc: 0.9058\n",
    "Epoch 9/10\n",
    "547s - loss: 0.1976 - acc: 0.9754 - val_loss: 0.5129 - val_acc: 0.9041\n",
    "Epoch 10/10\n",
    "548s - loss: 0.1940 - acc: 0.9767 - val_loss: 0.5693 - val_acc: 0.8869\n",
    "\n",
    "# Out[32]:\n",
    "<keras.callbacks.History at 0x7f04f52ac668>\n",
    "\n",
    "# In [33]:\n",
    "K.set_value(model.optimizer.lr, 0.001)\n",
    "\n",
    "# In [34]:\n",
    "model.fit(x_train, y_train, 64, 20, validation_data=(x_test, y_test), **parms)\n",
    "\n",
    "Train on 50000 samples, validate on 10000 samples\n",
    "Epoch 1/20\n",
    "548s - loss: 0.1879 - acc: 0.9801 - val_loss: 0.4073 - val_acc: 0.9270\n",
    "Epoch 2/20\n",
    "548s - loss: 0.1631 - acc: 0.9893 - val_loss: 0.4040 - val_acc: 0.9265\n",
    "Epoch 3/20\n",
    "547s - loss: 0.1601 - acc: 0.9905 - val_loss: 0.4007 - val_acc: 0.9295\n",
    "Epoch 4/20\n",
    "547s - loss: 0.1560 - acc: 0.9919 - val_loss: 0.4016 - val_acc: 0.9294\n",
    "Epoch 5/20\n",
    "548s - loss: 0.1540 - acc: 0.9921 - val_loss: 0.3988 - val_acc: 0.9293\n",
    "Epoch 6/20\n",
    "547s - loss: 0.1529 - acc: 0.9926 - val_loss: 0.4013 - val_acc: 0.9283\n",
    "Epoch 7/20\n",
    "548s - loss: 0.1497 - acc: 0.9937 - val_loss: 0.3984 - val_acc: 0.9312\n",
    "Epoch 8/20\n",
    "548s - loss: 0.1508 - acc: 0.9929 - val_loss: 0.3993 - val_acc: 0.9304\n",
    "Epoch 9/20\n",
    "547s - loss: 0.1486 - acc: 0.9937 - val_loss: 0.3988 - val_acc: 0.9303\n",
    "Epoch 10/20\n",
    "547s - loss: 0.1471 - acc: 0.9938 - val_loss: 0.3978 - val_acc: 0.9302\n",
    "Epoch 11/20\n",
    "547s - loss: 0.1460 - acc: 0.9942 - val_loss: 0.3945 - val_acc: 0.9306\n",
    "Epoch 12/20\n",
    "547s - loss: 0.1453 - acc: 0.9943 - val_loss: 0.3988 - val_acc: 0.9292\n",
    "Epoch 13/20\n",
    "547s - loss: 0.1456 - acc: 0.9939 - val_loss: 0.4004 - val_acc: 0.9298\n",
    "Epoch 14/20\n",
    "547s - loss: 0.1434 - acc: 0.9946 - val_loss: 0.3978 - val_acc: 0.9314\n",
    "Epoch 15/20\n",
    "547s - loss: 0.1427 - acc: 0.9946 - val_loss: 0.3974 - val_acc: 0.9311\n",
    "Epoch 16/20\n",
    "547s - loss: 0.1417 - acc: 0.9949 - val_loss: 0.3978 - val_acc: 0.9320\n",
    "Epoch 17/20\n",
    "548s - loss: 0.1403 - acc: 0.9954 - val_loss: 0.4010 - val_acc: 0.9317\n",
    "Epoch 18/20\n",
    "548s - loss: 0.1395 - acc: 0.9955 - val_loss: 0.3989 - val_acc: 0.9324\n",
    "Epoch 19/20\n",
    "547s - loss: 0.1409 - acc: 0.9951 - val_loss: 0.3997 - val_acc: 0.9312\n",
    "Epoch 20/20\n",
    "548s - loss: 0.1402 - acc: 0.9948 - val_loss: 0.3973 - val_acc: 0.9323\n",
    "\n",
    "# Out[34]:\n",
    "<keras.callbacks.History at 0x7f04f5264588>\n",
    "\n",
    "# And we're able to replicate their state-of-the-art results!\n",
    "\n",
    "# In [35]:\n",
    "%time model.save_weights('models/93.h5')\n",
    "\n",
    "CPU times: user 31.1 s, sys: 452 ms, total: 31.6 s\n",
    "Wall time: 31.1 s\n",
    "End¶\n",
    "\n",
    "In [ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): return Activation('relu')(x)\n",
    "def dropout(x, p): return Dropout(p)(x) if p else x\n",
    "def bn(x): return BatchNormalization(mode=0, axis=-1)(x)\n",
    "def relu_bn(x): return relu(bn(x))\n",
    "\n",
    "\n",
    "def conv(x, nf, sz, wd, p):\n",
    "    x = Convolution2D(nf, sz, sz, init='he_uniform', border_mode='same', \n",
    "                          W_regularizer=l2(wd))(x)\n",
    "    return dropout(x,p)\n",
    "\n",
    "def conv_block(x, nf, bottleneck=False, p=None, wd=0):\n",
    "    x = relu_bn(x)\n",
    "    if bottleneck: x = relu_bn(conv(x, nf * 4, 1, wd, p))\n",
    "    return conv(x, nf, 3, wd, p)\n",
    "\n",
    "def dense_block(x, nb_layers, growth_rate, bottleneck=False, p=None, wd=0):\n",
    "    if bottleneck: nb_layers //= 2\n",
    "    for i in range(nb_layers):\n",
    "        b = conv_block(x, growth_rate, bottleneck=bottleneck, p=p, wd=wd)\n",
    "#        x = merge([x,b], mode='concat', concat_axis=-1)\n",
    "        x = concatenate([x,b], axis=-1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, compression=1.0, p=None, wd=0):\n",
    "    nf = int(x.get_shape().as_list()[-1] * compression)\n",
    "    x = relu_bn(x)\n",
    "    x = conv(x, nf, 1, wd, p)\n",
    "    return AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "def create_dense_net(nb_classes, img_input, depth=40, nb_block=3, \n",
    "     growth_rate=12, nb_filter=16, bottleneck=False, compression=1.0, p=None, wd=0, activation='softmax'):\n",
    "    \n",
    "    assert activation == 'softmax' or activation == 'sigmoid'\n",
    "    assert (depth - 4) % nb_block == 0\n",
    "    nb_layers_per_block = int((depth - 4) / nb_block)\n",
    "    nb_layers = [nb_layers_per_block] * nb_block\n",
    "\n",
    "    x = conv(img_input, nb_filter, 3, wd, 0)\n",
    "    for i,block in enumerate(nb_layers):\n",
    "        x = dense_block(x, block, growth_rate, bottleneck=bottleneck, p=p, wd=wd)\n",
    "        if i != len(nb_layers)-1:\n",
    "            x = transition_block(x, compression=compression, p=p, wd=wd)\n",
    "\n",
    "    x = relu_bn(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    return Dense(nb_classes, activation=activation, W_regularizer=l2(wd))(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_initializer=\"he_uniform\", kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=-1)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), kernel_initializer=\"he_uniform\", kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), kernel_initializer=\"he_uniform\", kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(104, (1, 1), kernel_initializer=\"he_uniform\", kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(148, (1, 1), kernel_initializer=\"he_uniform\", kernel_regularizer=<keras.reg..., padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/ipykernel_launcher.py:48: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, kernel_regularizer=<keras.reg..., activation=\"softmax\")`\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Convolution2D, BatchNormalization, Activation, Dropout, concatenate, AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.regularizers import l2\n",
    "from keras import models\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "input_shape = (32,32,3)\n",
    "\n",
    "# In [15]:\n",
    "img_input = Input(shape=input_shape)\n",
    "\n",
    "# In [16]:\n",
    "x = create_dense_net(10, img_input, depth=100, nb_filter=16, compression=0.5, \n",
    "                     bottleneck=True, p=0.2, wd=1e-4)\n",
    "\n",
    "# In [17]:\n",
    "model = Model(img_input, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 32, 32, 16)   448         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 32, 32, 16)   64          conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 32, 32, 16)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 32, 32, 48)   816         activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 32, 32, 48)   0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 32, 32, 48)   192         dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 32, 32, 48)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 32, 32, 12)   5196        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 32, 32, 12)   0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 32, 32, 28)   0           conv2d_100[0][0]                 \n",
      "                                                                 dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 32, 32, 28)   112         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 32, 32, 28)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 32, 32, 48)   1392        activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 32, 32, 48)   0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 32, 32, 48)   192         dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 32, 32, 48)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 32, 32, 12)   5196        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 32, 32, 12)   0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 32, 32, 40)   0           concatenate_49[0][0]             \n",
      "                                                                 dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 32, 32, 40)   160         concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 32, 32, 40)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 32, 32, 48)   1968        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 32, 32, 48)   0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 32, 32, 48)   192         dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 32, 32, 48)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 32, 32, 12)   5196        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 32, 32, 12)   0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 32, 32, 52)   0           concatenate_50[0][0]             \n",
      "                                                                 dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 32, 32, 52)   208         concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 32, 32, 52)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 32, 32, 48)   2544        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 32, 32, 48)   0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 32, 32, 48)   192         dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 32, 32, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 32, 32, 12)   5196        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 32, 32, 12)   0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 32, 32, 64)   0           concatenate_51[0][0]             \n",
      "                                                                 dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 32, 32, 64)   256         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 32, 32, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 32, 32, 48)   3120        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 32, 32, 48)   0           conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 32, 32, 48)   192         dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 32, 32, 48)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 32, 32, 12)   5196        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 32, 32, 12)   0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 32, 32, 76)   0           concatenate_52[0][0]             \n",
      "                                                                 dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 32, 32, 76)   304         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 32, 32, 76)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 32, 32, 48)   3696        activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 32, 32, 48)   0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 32, 32, 48)   192         dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 32, 32, 48)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 32, 32, 12)   5196        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 32, 32, 12)   0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 32, 32, 88)   0           concatenate_53[0][0]             \n",
      "                                                                 dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 32, 32, 88)   352         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 32, 32, 88)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 32, 32, 48)   4272        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 32, 32, 48)   0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 32, 32, 48)   192         dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 32, 32, 48)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 32, 32, 12)   5196        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 32, 32, 12)   0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 32, 32, 100)  0           concatenate_54[0][0]             \n",
      "                                                                 dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 32, 32, 100)  400         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 32, 32, 100)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 32, 32, 48)   4848        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 32, 32, 48)   0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 32, 32, 48)   192         dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 32, 32, 48)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 32, 32, 12)   5196        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 32, 32, 12)   0           conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 32, 32, 112)  0           concatenate_55[0][0]             \n",
      "                                                                 dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 32, 32, 112)  448         concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 32, 32, 112)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 32, 32, 48)   5424        activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 32, 32, 48)   0           conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 32, 32, 48)   192         dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 32, 32, 48)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 32, 32, 12)   5196        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 32, 32, 12)   0           conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 32, 32, 124)  0           concatenate_56[0][0]             \n",
      "                                                                 dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 32, 32, 124)  496         concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 32, 32, 124)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 32, 32, 48)   6000        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 32, 32, 48)   0           conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 32, 32, 48)   192         dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 32, 32, 48)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 32, 32, 12)   5196        activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 32, 32, 12)   0           conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 32, 32, 136)  0           concatenate_57[0][0]             \n",
      "                                                                 dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 32, 32, 136)  544         concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 32, 32, 136)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 32, 32, 48)   6576        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 32, 32, 48)   0           conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 32, 32, 48)   192         dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 32, 32, 48)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 32, 32, 12)   5196        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 32, 32, 12)   0           conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 32, 32, 148)  0           concatenate_58[0][0]             \n",
      "                                                                 dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 32, 32, 148)  592         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 32, 32, 148)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 32, 32, 48)   7152        activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 32, 32, 48)   0           conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 32, 32, 48)   192         dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 32, 32, 48)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 32, 32, 12)   5196        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 32, 32, 12)   0           conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 32, 32, 160)  0           concatenate_59[0][0]             \n",
      "                                                                 dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 32, 32, 160)  640         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 32, 32, 160)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 32, 32, 48)   7728        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 32, 32, 48)   0           conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 32, 32, 48)   192         dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 32, 32, 48)   0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 32, 32, 12)   5196        activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 32, 32, 12)   0           conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 32, 32, 172)  0           concatenate_60[0][0]             \n",
      "                                                                 dropout_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 32, 32, 172)  688         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 32, 32, 172)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 32, 32, 48)   8304        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, 32, 32, 48)   0           conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 32, 32, 48)   192         dropout_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 32, 32, 48)   0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 32, 32, 12)   5196        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)           (None, 32, 32, 12)   0           conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 32, 32, 184)  0           concatenate_61[0][0]             \n",
      "                                                                 dropout_126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 32, 32, 184)  736         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 32, 32, 184)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 32, 32, 48)   8880        activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)           (None, 32, 32, 48)   0           conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 32, 32, 48)   192         dropout_127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 32, 32, 48)   0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 32, 32, 12)   5196        activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)           (None, 32, 32, 12)   0           conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 32, 32, 196)  0           concatenate_62[0][0]             \n",
      "                                                                 dropout_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 32, 32, 196)  784         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 32, 32, 196)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 32, 32, 48)   9456        activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)           (None, 32, 32, 48)   0           conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 32, 32, 48)   192         dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 32, 32, 48)   0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 32, 32, 12)   5196        activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)           (None, 32, 32, 12)   0           conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 32, 32, 208)  0           concatenate_63[0][0]             \n",
      "                                                                 dropout_130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 32, 32, 208)  832         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 32, 32, 208)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 32, 32, 104)  21736       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)           (None, 32, 32, 104)  0           conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 16, 16, 104)  0           dropout_131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 16, 16, 104)  416         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 16, 16, 104)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 16, 16, 48)   5040        activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)           (None, 16, 16, 48)   0           conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 16, 16, 48)   192         dropout_132[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 16, 16, 48)   0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 16, 16, 12)   5196        activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)           (None, 16, 16, 12)   0           conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 16, 16, 116)  0           average_pooling2d_3[0][0]        \n",
      "                                                                 dropout_133[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 16, 16, 116)  464         concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 16, 16, 116)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 16, 16, 48)   5616        activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)           (None, 16, 16, 48)   0           conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 16, 16, 48)   192         dropout_134[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 16, 16, 48)   0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 16, 16, 12)   5196        activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)           (None, 16, 16, 12)   0           conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 16, 16, 128)  0           concatenate_65[0][0]             \n",
      "                                                                 dropout_135[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 16, 16, 128)  512         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 16, 16, 128)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 16, 16, 48)   6192        activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 16, 16, 48)   0           conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 16, 16, 48)   192         dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 16, 16, 48)   0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 16, 16, 12)   5196        activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)           (None, 16, 16, 12)   0           conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 16, 16, 140)  0           concatenate_66[0][0]             \n",
      "                                                                 dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 16, 16, 140)  560         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 16, 16, 140)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 16, 16, 48)   6768        activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)           (None, 16, 16, 48)   0           conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 16, 16, 48)   192         dropout_138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 16, 16, 48)   0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 16, 16, 12)   5196        activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)           (None, 16, 16, 12)   0           conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 16, 16, 152)  0           concatenate_67[0][0]             \n",
      "                                                                 dropout_139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 16, 16, 152)  608         concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 16, 16, 152)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 16, 16, 48)   7344        activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 16, 16, 48)   0           conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 16, 16, 48)   192         dropout_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 16, 16, 48)   0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 16, 16, 12)   5196        activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)           (None, 16, 16, 12)   0           conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 16, 16, 164)  0           concatenate_68[0][0]             \n",
      "                                                                 dropout_141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 16, 16, 164)  656         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 16, 16, 164)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 16, 16, 48)   7920        activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)           (None, 16, 16, 48)   0           conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 16, 16, 48)   192         dropout_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 16, 16, 48)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 16, 16, 12)   5196        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)           (None, 16, 16, 12)   0           conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 16, 16, 176)  0           concatenate_69[0][0]             \n",
      "                                                                 dropout_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 16, 16, 176)  704         concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 16, 16, 176)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 16, 16, 48)   8496        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, 16, 16, 48)   0           conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 16, 16, 48)   192         dropout_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 16, 16, 48)   0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 16, 16, 12)   5196        activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)           (None, 16, 16, 12)   0           conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 16, 16, 188)  0           concatenate_70[0][0]             \n",
      "                                                                 dropout_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 16, 16, 188)  752         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 16, 16, 188)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 16, 16, 48)   9072        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, 16, 16, 48)   0           conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 16, 16, 48)   192         dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 16, 16, 48)   0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 16, 16, 12)   5196        activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)           (None, 16, 16, 12)   0           conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 16, 16, 200)  0           concatenate_71[0][0]             \n",
      "                                                                 dropout_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 16, 16, 200)  800         concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 16, 16, 200)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 16, 16, 48)   9648        activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)           (None, 16, 16, 48)   0           conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 16, 16, 48)   192         dropout_148[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 16, 16, 48)   0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 16, 16, 12)   5196        activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)           (None, 16, 16, 12)   0           conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 16, 16, 212)  0           concatenate_72[0][0]             \n",
      "                                                                 dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 16, 16, 212)  848         concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 16, 16, 212)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 16, 16, 48)   10224       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, 16, 16, 48)   0           conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 16, 16, 48)   192         dropout_150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 16, 16, 48)   0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 16, 16, 12)   5196        activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)           (None, 16, 16, 12)   0           conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 16, 16, 224)  0           concatenate_73[0][0]             \n",
      "                                                                 dropout_151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 16, 16, 224)  896         concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 16, 16, 224)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 16, 16, 48)   10800       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, 16, 16, 48)   0           conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 16, 16, 48)   192         dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 16, 16, 48)   0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 16, 16, 12)   5196        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)           (None, 16, 16, 12)   0           conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 16, 16, 236)  0           concatenate_74[0][0]             \n",
      "                                                                 dropout_153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 16, 16, 236)  944         concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 16, 16, 236)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 16, 16, 48)   11376       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)           (None, 16, 16, 48)   0           conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 16, 16, 48)   192         dropout_154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 16, 16, 48)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 16, 16, 12)   5196        activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)           (None, 16, 16, 12)   0           conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 16, 16, 248)  0           concatenate_75[0][0]             \n",
      "                                                                 dropout_155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 16, 16, 248)  992         concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 16, 16, 248)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 16, 16, 48)   11952       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, 16, 16, 48)   0           conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 16, 16, 48)   192         dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 16, 16, 48)   0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 16, 16, 12)   5196        activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)           (None, 16, 16, 12)   0           conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 16, 16, 260)  0           concatenate_76[0][0]             \n",
      "                                                                 dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 16, 16, 260)  1040        concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 16, 16, 260)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 16, 16, 48)   12528       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)           (None, 16, 16, 48)   0           conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 16, 16, 48)   192         dropout_158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 16, 16, 48)   0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 16, 16, 12)   5196        activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)           (None, 16, 16, 12)   0           conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 16, 16, 272)  0           concatenate_77[0][0]             \n",
      "                                                                 dropout_159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 16, 16, 272)  1088        concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 16, 16, 272)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 16, 16, 48)   13104       activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 16, 16, 48)   0           conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 16, 16, 48)   192         dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 16, 16, 48)   0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 16, 16, 12)   5196        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)           (None, 16, 16, 12)   0           conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 16, 16, 284)  0           concatenate_78[0][0]             \n",
      "                                                                 dropout_161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 16, 16, 284)  1136        concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 16, 16, 284)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 16, 16, 48)   13680       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)           (None, 16, 16, 48)   0           conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 16, 16, 48)   192         dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 16, 16, 48)   0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 16, 16, 12)   5196        activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)           (None, 16, 16, 12)   0           conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 16, 16, 296)  0           concatenate_79[0][0]             \n",
      "                                                                 dropout_163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 16, 16, 296)  1184        concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 16, 16, 296)  0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 16, 16, 148)  43956       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_164 (Dropout)           (None, 16, 16, 148)  0           conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 8, 8, 148)    0           dropout_164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 8, 8, 148)    592         average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 148)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 48)     7152        activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_165 (Dropout)           (None, 8, 8, 48)     0           conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 8, 8, 48)     192         dropout_165[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 8, 8, 48)     0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 8, 8, 12)     5196        activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_166 (Dropout)           (None, 8, 8, 12)     0           conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 8, 8, 160)    0           average_pooling2d_4[0][0]        \n",
      "                                                                 dropout_166[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 8, 8, 160)    640         concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 8, 8, 160)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 48)     7728        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_167 (Dropout)           (None, 8, 8, 48)     0           conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 8, 8, 48)     192         dropout_167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 8, 8, 48)     0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 12)     5196        activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_168 (Dropout)           (None, 8, 8, 12)     0           conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 8, 8, 172)    0           concatenate_81[0][0]             \n",
      "                                                                 dropout_168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 172)    688         concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 172)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 48)     8304        activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_169 (Dropout)           (None, 8, 8, 48)     0           conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 8, 8, 48)     192         dropout_169[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 8, 8, 48)     0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 12)     5196        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)           (None, 8, 8, 12)     0           conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 8, 8, 184)    0           concatenate_82[0][0]             \n",
      "                                                                 dropout_170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 8, 8, 184)    736         concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 8, 8, 184)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 48)     8880        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 8, 8, 48)     0           conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 8, 8, 48)     192         dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 8, 8, 48)     0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 12)     5196        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)           (None, 8, 8, 12)     0           conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 8, 8, 196)    0           concatenate_83[0][0]             \n",
      "                                                                 dropout_172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 8, 8, 196)    784         concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 8, 8, 196)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 8, 8, 48)     9456        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 8, 8, 48)     0           conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 8, 8, 48)     192         dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 8, 8, 48)     0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 8, 8, 12)     5196        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 8, 8, 12)     0           conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 8, 8, 208)    0           concatenate_84[0][0]             \n",
      "                                                                 dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 8, 8, 208)    832         concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 8, 8, 208)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 8, 8, 48)     10032       activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)           (None, 8, 8, 48)     0           conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 8, 8, 48)     192         dropout_175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 8, 8, 48)     0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 8, 8, 12)     5196        activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 8, 8, 12)     0           conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 8, 8, 220)    0           concatenate_85[0][0]             \n",
      "                                                                 dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 8, 8, 220)    880         concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 8, 8, 220)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 8, 8, 48)     10608       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_177 (Dropout)           (None, 8, 8, 48)     0           conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 8, 8, 48)     192         dropout_177[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 8, 8, 48)     0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 8, 8, 12)     5196        activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_178 (Dropout)           (None, 8, 8, 12)     0           conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 8, 8, 232)    0           concatenate_86[0][0]             \n",
      "                                                                 dropout_178[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 8, 8, 232)    928         concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 8, 8, 232)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 8, 8, 48)     11184       activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_179 (Dropout)           (None, 8, 8, 48)     0           conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 8, 8, 48)     192         dropout_179[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 8, 8, 48)     0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 8, 8, 12)     5196        activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_180 (Dropout)           (None, 8, 8, 12)     0           conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 8, 8, 244)    0           concatenate_87[0][0]             \n",
      "                                                                 dropout_180[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 8, 8, 244)    976         concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 8, 8, 244)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 8, 8, 48)     11760       activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_181 (Dropout)           (None, 8, 8, 48)     0           conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 8, 8, 48)     192         dropout_181[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 8, 8, 48)     0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 8, 8, 12)     5196        activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_182 (Dropout)           (None, 8, 8, 12)     0           conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 8, 8, 256)    0           concatenate_88[0][0]             \n",
      "                                                                 dropout_182[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 8, 8, 256)    1024        concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 8, 8, 256)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 8, 8, 48)     12336       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_183 (Dropout)           (None, 8, 8, 48)     0           conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 8, 8, 48)     192         dropout_183[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 8, 8, 48)     0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 8, 8, 12)     5196        activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_184 (Dropout)           (None, 8, 8, 12)     0           conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 8, 8, 268)    0           concatenate_89[0][0]             \n",
      "                                                                 dropout_184[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 8, 8, 268)    1072        concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 268)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 8, 8, 48)     12912       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_185 (Dropout)           (None, 8, 8, 48)     0           conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 8, 8, 48)     192         dropout_185[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 48)     0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 8, 8, 12)     5196        activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_186 (Dropout)           (None, 8, 8, 12)     0           conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 8, 8, 280)    0           concatenate_90[0][0]             \n",
      "                                                                 dropout_186[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 8, 8, 280)    1120        concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 8, 8, 280)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 8, 8, 48)     13488       activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_187 (Dropout)           (None, 8, 8, 48)     0           conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 8, 8, 48)     192         dropout_187[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 8, 8, 48)     0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 8, 8, 12)     5196        activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_188 (Dropout)           (None, 8, 8, 12)     0           conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 8, 8, 292)    0           concatenate_91[0][0]             \n",
      "                                                                 dropout_188[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 8, 8, 292)    1168        concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 8, 8, 292)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 8, 8, 48)     14064       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_189 (Dropout)           (None, 8, 8, 48)     0           conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 8, 8, 48)     192         dropout_189[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 8, 8, 48)     0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 8, 8, 12)     5196        activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_190 (Dropout)           (None, 8, 8, 12)     0           conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 8, 8, 304)    0           concatenate_92[0][0]             \n",
      "                                                                 dropout_190[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 8, 8, 304)    1216        concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 8, 8, 304)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 8, 8, 48)     14640       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_191 (Dropout)           (None, 8, 8, 48)     0           conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 8, 8, 48)     192         dropout_191[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 8, 8, 48)     0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 8, 8, 12)     5196        activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_192 (Dropout)           (None, 8, 8, 12)     0           conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 8, 8, 316)    0           concatenate_93[0][0]             \n",
      "                                                                 dropout_192[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 8, 8, 316)    1264        concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 8, 8, 316)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 8, 8, 48)     15216       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_193 (Dropout)           (None, 8, 8, 48)     0           conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 8, 8, 48)     192         dropout_193[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 8, 8, 48)     0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 8, 8, 12)     5196        activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_194 (Dropout)           (None, 8, 8, 12)     0           conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 8, 8, 328)    0           concatenate_94[0][0]             \n",
      "                                                                 dropout_194[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 8, 8, 328)    1312        concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 8, 8, 328)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 8, 8, 48)     15792       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_195 (Dropout)           (None, 8, 8, 48)     0           conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 8, 8, 48)     192         dropout_195[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 8, 8, 48)     0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 8, 8, 12)     5196        activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_196 (Dropout)           (None, 8, 8, 12)     0           conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 8, 8, 340)    0           concatenate_95[0][0]             \n",
      "                                                                 dropout_196[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 8, 8, 340)    1360        concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 8, 8, 340)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 340)          0           activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           3410        global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 781,470\n",
      "Trainable params: 757,958\n",
      "Non-trainable params: 23,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f6f042252e8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6f04225198>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f6f042256d8>,\n",
       " <keras.layers.core.Activation at 0x7f6f04225710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f6f041d0da0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = model.layers[:5]\n",
    "print(type(model_1))\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x))\n",
    "print(type(img_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer -5 =  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer -5 =  <class 'keras.layers.merge.Concatenate'>\n",
      "layer -2 =  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "layer -2 =  <class 'keras.layers.pooling.GlobalAveragePooling2D'>\n"
     ]
    }
   ],
   "source": [
    "y = model.layers[-5].output\n",
    "z = model.layers[-5]\n",
    "print('layer -5 = ', type(y))\n",
    "print('layer -5 = ', type(z))\n",
    "a = model.layers[-2].output\n",
    "b = model.layers[-2]\n",
    "print('layer -2 = ', type(a))\n",
    "print('layer -2 = ', type(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(8), Dimension(8), Dimension(340)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() got an unexpected keyword argument 'require_flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-a4ba8c990515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_flatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# next_1 = Dense(5, activation = 'softmax')(a)  # for 5 class classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: call() got an unexpected keyword argument 'require_flatten'"
     ]
    }
   ],
   "source": [
    "base_model = model(weights = None, require_flatten = False, inputs = img_input)\n",
    "\n",
    "# next_1 = Dense(5, activation = 'softmax')(a)  # for 5 class classification\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 32, 32, 16)   448         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 32, 32, 16)   64          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 32, 32, 16)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 32, 32, 48)   816         activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_197 (Dropout)           (None, 32, 32, 48)   0           conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 32, 32, 48)   192         dropout_197[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 32, 32, 48)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 32, 32, 12)   5196        activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_198 (Dropout)           (None, 32, 32, 12)   0           conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 32, 32, 28)   0           conv2d_199[0][0]                 \n",
      "                                                                 dropout_198[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 32, 32, 28)   112         concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 32, 32, 28)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 32, 32, 48)   1392        activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_199 (Dropout)           (None, 32, 32, 48)   0           conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 32, 32, 48)   192         dropout_199[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 32, 32, 48)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 32, 32, 12)   5196        activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_200 (Dropout)           (None, 32, 32, 12)   0           conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 32, 32, 40)   0           concatenate_97[0][0]             \n",
      "                                                                 dropout_200[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 32, 32, 40)   160         concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 32, 32, 40)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 32, 32, 48)   1968        activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_201 (Dropout)           (None, 32, 32, 48)   0           conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 32, 32, 48)   192         dropout_201[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 32, 32, 48)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 32, 32, 12)   5196        activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_202 (Dropout)           (None, 32, 32, 12)   0           conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 32, 32, 52)   0           concatenate_98[0][0]             \n",
      "                                                                 dropout_202[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 32, 32, 52)   208         concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 32, 32, 52)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 32, 32, 48)   2544        activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_203 (Dropout)           (None, 32, 32, 48)   0           conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 32, 32, 48)   192         dropout_203[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 32, 32, 48)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 32, 32, 12)   5196        activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_204 (Dropout)           (None, 32, 32, 12)   0           conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 32, 32, 64)   0           concatenate_99[0][0]             \n",
      "                                                                 dropout_204[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 32, 32, 64)   256         concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 32, 32, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 32, 32, 48)   3120        activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_205 (Dropout)           (None, 32, 32, 48)   0           conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 32, 32, 48)   192         dropout_205[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 32, 32, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 32, 32, 12)   5196        activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_206 (Dropout)           (None, 32, 32, 12)   0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 32, 32, 76)   0           concatenate_100[0][0]            \n",
      "                                                                 dropout_206[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 32, 32, 76)   304         concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 32, 32, 76)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 32, 32, 48)   3696        activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_207 (Dropout)           (None, 32, 32, 48)   0           conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 32, 32, 48)   192         dropout_207[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 32, 32, 48)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 32, 32, 12)   5196        activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_208 (Dropout)           (None, 32, 32, 12)   0           conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 32, 32, 88)   0           concatenate_101[0][0]            \n",
      "                                                                 dropout_208[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 32, 32, 88)   352         concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 32, 32, 88)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 32, 32, 48)   4272        activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_209 (Dropout)           (None, 32, 32, 48)   0           conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 32, 32, 48)   192         dropout_209[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 32, 32, 48)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 32, 32, 12)   5196        activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_210 (Dropout)           (None, 32, 32, 12)   0           conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 32, 32, 100)  0           concatenate_102[0][0]            \n",
      "                                                                 dropout_210[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 32, 32, 100)  400         concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 32, 32, 100)  0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 32, 32, 48)   4848        activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_211 (Dropout)           (None, 32, 32, 48)   0           conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 32, 32, 48)   192         dropout_211[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 32, 32, 48)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 32, 32, 12)   5196        activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_212 (Dropout)           (None, 32, 32, 12)   0           conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 32, 32, 112)  0           concatenate_103[0][0]            \n",
      "                                                                 dropout_212[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 32, 32, 112)  448         concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 32, 32, 112)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 32, 32, 48)   5424        activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_213 (Dropout)           (None, 32, 32, 48)   0           conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 32, 32, 48)   192         dropout_213[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 32, 32, 48)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 32, 32, 12)   5196        activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_214 (Dropout)           (None, 32, 32, 12)   0           conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 32, 32, 124)  0           concatenate_104[0][0]            \n",
      "                                                                 dropout_214[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 32, 32, 124)  496         concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 32, 32, 124)  0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 32, 32, 48)   6000        activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_215 (Dropout)           (None, 32, 32, 48)   0           conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 32, 32, 48)   192         dropout_215[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 32, 32, 48)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 32, 32, 12)   5196        activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_216 (Dropout)           (None, 32, 32, 12)   0           conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 32, 32, 136)  0           concatenate_105[0][0]            \n",
      "                                                                 dropout_216[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 32, 32, 136)  544         concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 32, 32, 136)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 32, 32, 48)   6576        activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_217 (Dropout)           (None, 32, 32, 48)   0           conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 32, 32, 48)   192         dropout_217[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 32, 32, 48)   0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 32, 32, 12)   5196        activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_218 (Dropout)           (None, 32, 32, 12)   0           conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 32, 32, 148)  0           concatenate_106[0][0]            \n",
      "                                                                 dropout_218[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 32, 32, 148)  592         concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 32, 32, 148)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 32, 32, 48)   7152        activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_219 (Dropout)           (None, 32, 32, 48)   0           conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 32, 32, 48)   192         dropout_219[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 32, 32, 48)   0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 32, 32, 12)   5196        activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_220 (Dropout)           (None, 32, 32, 12)   0           conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 32, 32, 160)  0           concatenate_107[0][0]            \n",
      "                                                                 dropout_220[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 32, 32, 160)  640         concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 32, 32, 160)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 32, 32, 48)   7728        activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_221 (Dropout)           (None, 32, 32, 48)   0           conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 32, 32, 48)   192         dropout_221[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 32, 32, 48)   0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 32, 32, 12)   5196        activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_222 (Dropout)           (None, 32, 32, 12)   0           conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 32, 32, 172)  0           concatenate_108[0][0]            \n",
      "                                                                 dropout_222[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 32, 32, 172)  688         concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 32, 32, 172)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 32, 32, 48)   8304        activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_223 (Dropout)           (None, 32, 32, 48)   0           conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 32, 32, 48)   192         dropout_223[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 32, 32, 48)   0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 32, 32, 12)   5196        activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_224 (Dropout)           (None, 32, 32, 12)   0           conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 32, 32, 184)  0           concatenate_109[0][0]            \n",
      "                                                                 dropout_224[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 32, 32, 184)  736         concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 32, 32, 184)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 32, 32, 48)   8880        activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_225 (Dropout)           (None, 32, 32, 48)   0           conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 32, 32, 48)   192         dropout_225[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 32, 32, 48)   0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 32, 32, 12)   5196        activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_226 (Dropout)           (None, 32, 32, 12)   0           conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 32, 32, 196)  0           concatenate_110[0][0]            \n",
      "                                                                 dropout_226[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 32, 32, 196)  784         concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 32, 32, 196)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 32, 32, 48)   9456        activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_227 (Dropout)           (None, 32, 32, 48)   0           conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 32, 32, 48)   192         dropout_227[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 32, 32, 48)   0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 32, 32, 12)   5196        activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_228 (Dropout)           (None, 32, 32, 12)   0           conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 32, 32, 208)  0           concatenate_111[0][0]            \n",
      "                                                                 dropout_228[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 32, 32, 208)  832         concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 32, 32, 208)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 32, 32, 104)  21736       activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_229 (Dropout)           (None, 32, 32, 104)  0           conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 16, 16, 104)  0           dropout_229[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 16, 16, 104)  416         average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 16, 16, 104)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 16, 16, 48)   5040        activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_230 (Dropout)           (None, 16, 16, 48)   0           conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 16, 16, 48)   192         dropout_230[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 16, 16, 48)   0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 16, 16, 12)   5196        activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_231 (Dropout)           (None, 16, 16, 12)   0           conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 16, 16, 116)  0           average_pooling2d_5[0][0]        \n",
      "                                                                 dropout_231[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 16, 16, 116)  464         concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 16, 16, 116)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 16, 16, 48)   5616        activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_232 (Dropout)           (None, 16, 16, 48)   0           conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 16, 16, 48)   192         dropout_232[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 16, 16, 48)   0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 16, 16, 12)   5196        activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_233 (Dropout)           (None, 16, 16, 12)   0           conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 16, 16, 128)  0           concatenate_113[0][0]            \n",
      "                                                                 dropout_233[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 16, 16, 128)  512         concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 16, 16, 128)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 16, 16, 48)   6192        activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_234 (Dropout)           (None, 16, 16, 48)   0           conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 16, 16, 48)   192         dropout_234[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 16, 16, 48)   0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 16, 16, 12)   5196        activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_235 (Dropout)           (None, 16, 16, 12)   0           conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 16, 16, 140)  0           concatenate_114[0][0]            \n",
      "                                                                 dropout_235[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 16, 16, 140)  560         concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 16, 16, 140)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 16, 16, 48)   6768        activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_236 (Dropout)           (None, 16, 16, 48)   0           conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 16, 16, 48)   192         dropout_236[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 16, 16, 48)   0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 16, 16, 12)   5196        activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_237 (Dropout)           (None, 16, 16, 12)   0           conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 16, 16, 152)  0           concatenate_115[0][0]            \n",
      "                                                                 dropout_237[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 16, 16, 152)  608         concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 16, 16, 152)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 16, 16, 48)   7344        activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_238 (Dropout)           (None, 16, 16, 48)   0           conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 16, 16, 48)   192         dropout_238[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 16, 16, 48)   0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 16, 16, 12)   5196        activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_239 (Dropout)           (None, 16, 16, 12)   0           conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 16, 16, 164)  0           concatenate_116[0][0]            \n",
      "                                                                 dropout_239[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 16, 16, 164)  656         concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 16, 16, 164)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 16, 16, 48)   7920        activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_240 (Dropout)           (None, 16, 16, 48)   0           conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 16, 16, 48)   192         dropout_240[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 16, 16, 48)   0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 16, 16, 12)   5196        activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_241 (Dropout)           (None, 16, 16, 12)   0           conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 16, 16, 176)  0           concatenate_117[0][0]            \n",
      "                                                                 dropout_241[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 16, 16, 176)  704         concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 16, 16, 176)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 16, 16, 48)   8496        activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_242 (Dropout)           (None, 16, 16, 48)   0           conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 16, 16, 48)   192         dropout_242[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 16, 16, 48)   0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 16, 16, 12)   5196        activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_243 (Dropout)           (None, 16, 16, 12)   0           conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 16, 16, 188)  0           concatenate_118[0][0]            \n",
      "                                                                 dropout_243[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 16, 16, 188)  752         concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 16, 16, 188)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 16, 16, 48)   9072        activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_244 (Dropout)           (None, 16, 16, 48)   0           conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 16, 16, 48)   192         dropout_244[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 16, 16, 48)   0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 16, 16, 12)   5196        activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_245 (Dropout)           (None, 16, 16, 12)   0           conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 16, 16, 200)  0           concatenate_119[0][0]            \n",
      "                                                                 dropout_245[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 16, 16, 200)  800         concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 16, 16, 200)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 16, 16, 48)   9648        activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_246 (Dropout)           (None, 16, 16, 48)   0           conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 16, 16, 48)   192         dropout_246[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 16, 16, 48)   0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 16, 16, 12)   5196        activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_247 (Dropout)           (None, 16, 16, 12)   0           conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 16, 16, 212)  0           concatenate_120[0][0]            \n",
      "                                                                 dropout_247[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 16, 16, 212)  848         concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 16, 16, 212)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 16, 16, 48)   10224       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_248 (Dropout)           (None, 16, 16, 48)   0           conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 16, 16, 48)   192         dropout_248[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 16, 16, 48)   0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 16, 16, 12)   5196        activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_249 (Dropout)           (None, 16, 16, 12)   0           conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 16, 16, 224)  0           concatenate_121[0][0]            \n",
      "                                                                 dropout_249[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 16, 16, 224)  896         concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 16, 16, 224)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 16, 16, 48)   10800       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_250 (Dropout)           (None, 16, 16, 48)   0           conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 16, 16, 48)   192         dropout_250[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 16, 16, 48)   0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 16, 16, 12)   5196        activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_251 (Dropout)           (None, 16, 16, 12)   0           conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 16, 16, 236)  0           concatenate_122[0][0]            \n",
      "                                                                 dropout_251[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 16, 16, 236)  944         concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 16, 16, 236)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 16, 16, 48)   11376       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_252 (Dropout)           (None, 16, 16, 48)   0           conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 16, 16, 48)   192         dropout_252[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 16, 16, 48)   0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 16, 16, 12)   5196        activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_253 (Dropout)           (None, 16, 16, 12)   0           conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 16, 16, 248)  0           concatenate_123[0][0]            \n",
      "                                                                 dropout_253[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 16, 16, 248)  992         concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 16, 16, 248)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 16, 16, 48)   11952       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_254 (Dropout)           (None, 16, 16, 48)   0           conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 16, 16, 48)   192         dropout_254[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 16, 16, 48)   0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 16, 16, 12)   5196        activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_255 (Dropout)           (None, 16, 16, 12)   0           conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 16, 16, 260)  0           concatenate_124[0][0]            \n",
      "                                                                 dropout_255[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 16, 16, 260)  1040        concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 16, 16, 260)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 16, 16, 48)   12528       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_256 (Dropout)           (None, 16, 16, 48)   0           conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 16, 16, 48)   192         dropout_256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 16, 16, 48)   0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 16, 16, 12)   5196        activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_257 (Dropout)           (None, 16, 16, 12)   0           conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 16, 16, 272)  0           concatenate_125[0][0]            \n",
      "                                                                 dropout_257[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 16, 16, 272)  1088        concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 16, 16, 272)  0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 16, 16, 48)   13104       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_258 (Dropout)           (None, 16, 16, 48)   0           conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 16, 16, 48)   192         dropout_258[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 16, 16, 48)   0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 16, 16, 12)   5196        activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_259 (Dropout)           (None, 16, 16, 12)   0           conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 16, 16, 284)  0           concatenate_126[0][0]            \n",
      "                                                                 dropout_259[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 16, 16, 284)  1136        concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 16, 16, 284)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 16, 16, 48)   13680       activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_260 (Dropout)           (None, 16, 16, 48)   0           conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 16, 16, 48)   192         dropout_260[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 16, 16, 48)   0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 16, 16, 12)   5196        activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_261 (Dropout)           (None, 16, 16, 12)   0           conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 16, 16, 296)  0           concatenate_127[0][0]            \n",
      "                                                                 dropout_261[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 16, 16, 296)  1184        concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 16, 16, 296)  0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 16, 16, 148)  43956       activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_262 (Dropout)           (None, 16, 16, 148)  0           conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 8, 8, 148)    0           dropout_262[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 8, 8, 148)    592         average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 8, 8, 148)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 8, 8, 48)     7152        activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_263 (Dropout)           (None, 8, 8, 48)     0           conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 8, 8, 48)     192         dropout_263[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 8, 8, 48)     0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 8, 8, 12)     5196        activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_264 (Dropout)           (None, 8, 8, 12)     0           conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 8, 8, 160)    0           average_pooling2d_6[0][0]        \n",
      "                                                                 dropout_264[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 8, 8, 160)    640         concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 8, 8, 160)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 8, 8, 48)     7728        activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_265 (Dropout)           (None, 8, 8, 48)     0           conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 8, 8, 48)     192         dropout_265[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 8, 8, 48)     0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 8, 8, 12)     5196        activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_266 (Dropout)           (None, 8, 8, 12)     0           conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 8, 8, 172)    0           concatenate_129[0][0]            \n",
      "                                                                 dropout_266[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 8, 8, 172)    688         concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 8, 8, 172)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 8, 8, 48)     8304        activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_267 (Dropout)           (None, 8, 8, 48)     0           conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 8, 8, 48)     192         dropout_267[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 8, 8, 48)     0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 8, 8, 12)     5196        activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_268 (Dropout)           (None, 8, 8, 12)     0           conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 8, 8, 184)    0           concatenate_130[0][0]            \n",
      "                                                                 dropout_268[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 8, 8, 184)    736         concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 8, 8, 184)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 8, 8, 48)     8880        activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_269 (Dropout)           (None, 8, 8, 48)     0           conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 8, 8, 48)     192         dropout_269[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 8, 8, 48)     0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 8, 8, 12)     5196        activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_270 (Dropout)           (None, 8, 8, 12)     0           conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 8, 8, 196)    0           concatenate_131[0][0]            \n",
      "                                                                 dropout_270[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 8, 8, 196)    784         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 8, 8, 196)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 8, 8, 48)     9456        activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_271 (Dropout)           (None, 8, 8, 48)     0           conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 8, 8, 48)     192         dropout_271[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 8, 8, 48)     0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 8, 8, 12)     5196        activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_272 (Dropout)           (None, 8, 8, 12)     0           conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 8, 8, 208)    0           concatenate_132[0][0]            \n",
      "                                                                 dropout_272[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 8, 8, 208)    832         concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 8, 8, 208)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 8, 8, 48)     10032       activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_273 (Dropout)           (None, 8, 8, 48)     0           conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 8, 8, 48)     192         dropout_273[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 8, 8, 48)     0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 8, 8, 12)     5196        activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_274 (Dropout)           (None, 8, 8, 12)     0           conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 8, 8, 220)    0           concatenate_133[0][0]            \n",
      "                                                                 dropout_274[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 8, 8, 220)    880         concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 8, 8, 220)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 8, 8, 48)     10608       activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_275 (Dropout)           (None, 8, 8, 48)     0           conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 8, 8, 48)     192         dropout_275[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 8, 8, 48)     0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 8, 8, 12)     5196        activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_276 (Dropout)           (None, 8, 8, 12)     0           conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 8, 8, 232)    0           concatenate_134[0][0]            \n",
      "                                                                 dropout_276[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 8, 8, 232)    928         concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 8, 8, 232)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 8, 8, 48)     11184       activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_277 (Dropout)           (None, 8, 8, 48)     0           conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 8, 8, 48)     192         dropout_277[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 8, 8, 48)     0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 8, 8, 12)     5196        activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_278 (Dropout)           (None, 8, 8, 12)     0           conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 8, 8, 244)    0           concatenate_135[0][0]            \n",
      "                                                                 dropout_278[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 8, 8, 244)    976         concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 8, 8, 244)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 8, 8, 48)     11760       activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_279 (Dropout)           (None, 8, 8, 48)     0           conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 8, 8, 48)     192         dropout_279[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 8, 8, 48)     0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 8, 8, 12)     5196        activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_280 (Dropout)           (None, 8, 8, 12)     0           conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 8, 8, 256)    0           concatenate_136[0][0]            \n",
      "                                                                 dropout_280[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 8, 8, 256)    1024        concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 8, 8, 256)    0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 8, 8, 48)     12336       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_281 (Dropout)           (None, 8, 8, 48)     0           conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 8, 8, 48)     192         dropout_281[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 8, 8, 48)     0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 8, 8, 12)     5196        activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_282 (Dropout)           (None, 8, 8, 12)     0           conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 8, 8, 268)    0           concatenate_137[0][0]            \n",
      "                                                                 dropout_282[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 8, 8, 268)    1072        concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 8, 8, 268)    0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 8, 8, 48)     12912       activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_283 (Dropout)           (None, 8, 8, 48)     0           conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 8, 8, 48)     192         dropout_283[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 8, 8, 48)     0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 8, 8, 12)     5196        activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_284 (Dropout)           (None, 8, 8, 12)     0           conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 8, 8, 280)    0           concatenate_138[0][0]            \n",
      "                                                                 dropout_284[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 8, 8, 280)    1120        concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 8, 8, 280)    0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 8, 8, 48)     13488       activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_285 (Dropout)           (None, 8, 8, 48)     0           conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 8, 8, 48)     192         dropout_285[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 8, 8, 48)     0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 8, 8, 12)     5196        activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_286 (Dropout)           (None, 8, 8, 12)     0           conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 8, 8, 292)    0           concatenate_139[0][0]            \n",
      "                                                                 dropout_286[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 8, 8, 292)    1168        concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 8, 8, 292)    0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 8, 8, 48)     14064       activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_287 (Dropout)           (None, 8, 8, 48)     0           conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 8, 8, 48)     192         dropout_287[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 8, 8, 48)     0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 8, 8, 12)     5196        activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_288 (Dropout)           (None, 8, 8, 12)     0           conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 8, 8, 304)    0           concatenate_140[0][0]            \n",
      "                                                                 dropout_288[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 8, 8, 304)    1216        concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 8, 8, 304)    0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 8, 8, 48)     14640       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_289 (Dropout)           (None, 8, 8, 48)     0           conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 8, 8, 48)     192         dropout_289[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 8, 8, 48)     0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 8, 8, 12)     5196        activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_290 (Dropout)           (None, 8, 8, 12)     0           conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 8, 8, 316)    0           concatenate_141[0][0]            \n",
      "                                                                 dropout_290[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 8, 8, 316)    1264        concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 8, 8, 316)    0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 8, 8, 48)     15216       activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_291 (Dropout)           (None, 8, 8, 48)     0           conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 8, 8, 48)     192         dropout_291[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 8, 8, 48)     0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 8, 8, 12)     5196        activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_292 (Dropout)           (None, 8, 8, 12)     0           conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 8, 8, 328)    0           concatenate_142[0][0]            \n",
      "                                                                 dropout_292[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 8, 8, 328)    1312        concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 8, 8, 328)    0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 8, 8, 48)     15792       activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_293 (Dropout)           (None, 8, 8, 48)     0           conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 8, 8, 48)     192         dropout_293[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 8, 8, 48)     0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 8, 8, 12)     5196        activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_294 (Dropout)           (None, 8, 8, 12)     0           conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 8, 8, 340)    0           concatenate_143[0][0]            \n",
      "                                                                 dropout_294[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 8, 8, 340)    1360        concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 8, 8, 340)    0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 340)          0           activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           3410        global_average_pooling2d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 781,470\n",
      "Trainable params: 757,958\n",
      "Non-trainable params: 23,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import InceptionResNetV2\n",
    "\n",
    "conv_base = InceptionResNetV2(weights = None, include_top = False, input_shape = (150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import DenseNet121\n",
    "\n",
    "conv_base = DenseNet121(weights = None, include_top = False, input_shape = (150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 156, 156, 3)  0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 75, 75, 64)   9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 75, 75, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 75, 75, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 77, 77, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 38, 38, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 38, 38, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 38, 38, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 38, 38, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 38, 38, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 38, 38, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 38, 38, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 38, 38, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 38, 38, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 38, 38, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 38, 38, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 38, 38, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 38, 38, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 38, 38, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 38, 38, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 38, 38, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 38, 38, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 38, 38, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 38, 38, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 38, 38, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 38, 38, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 38, 38, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 38, 38, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 38, 38, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 38, 38, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 38, 38, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 38, 38, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 38, 38, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 38, 38, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 38, 38, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 38, 38, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 38, 38, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 38, 38, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 19, 19, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 19, 19, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 19, 19, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 19, 19, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 19, 19, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 19, 19, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 19, 19, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 19, 19, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 19, 19, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 19, 19, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 19, 19, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 19, 19, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 19, 19, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 19, 19, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 19, 19, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 19, 19, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 19, 19, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 19, 19, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 19, 19, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 19, 19, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 19, 19, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 19, 19, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 19, 19, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 19, 19, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 19, 19, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 19, 19, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 19, 19, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 19, 19, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 19, 19, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 19, 19, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 19, 19, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 19, 19, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 19, 19, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 19, 19, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 19, 19, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 19, 19, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 19, 19, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 19, 19, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 19, 19, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 19, 19, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 19, 19, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 19, 19, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 19, 19, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 19, 19, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 19, 19, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 19, 19, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 19, 19, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 19, 19, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 19, 19, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 19, 19, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 19, 19, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 19, 19, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 19, 19, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 19, 19, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 19, 19, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 19, 19, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 19, 19, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 19, 19, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 19, 19, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 19, 19, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 19, 19, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 19, 19, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 19, 19, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 19, 19, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 19, 19, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 19, 19, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 19, 19, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 19, 19, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 19, 19, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 19, 19, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 9, 9, 256)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 9, 9, 256)    1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 9, 9, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 9, 9, 128)    32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 9, 9, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 9, 9, 288)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 9, 9, 288)    1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 9, 9, 288)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 9, 9, 128)    36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 9, 9, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 9, 9, 320)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 9, 9, 320)    1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 9, 9, 320)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 9, 9, 128)    40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 9, 9, 128)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 9, 9, 352)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 9, 9, 352)    1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 9, 9, 352)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 9, 9, 128)    45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 9, 9, 128)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 9, 9, 384)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 9, 9, 384)    1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 9, 9, 384)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 9, 9, 128)    49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 9, 9, 128)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 9, 9, 416)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 9, 9, 416)    1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 9, 9, 416)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 9, 9, 128)    53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 9, 9, 128)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 9, 9, 448)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 9, 9, 448)    1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 9, 9, 448)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 9, 9, 128)    57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 9, 9, 128)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 9, 9, 480)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 9, 9, 480)    1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 9, 9, 480)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 9, 9, 128)    61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 9, 9, 128)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 9, 9, 512)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 9, 9, 512)    2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 9, 9, 512)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 9, 9, 128)    65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 9, 9, 128)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 9, 9, 544)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 9, 9, 544)    2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 9, 9, 544)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 9, 9, 128)    69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 9, 9, 576)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 9, 9, 576)    2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 9, 9, 576)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 9, 9, 128)    73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 9, 9, 608)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 9, 9, 608)    2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 9, 9, 608)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 9, 9, 128)    77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 9, 9, 640)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 9, 9, 640)    2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 9, 9, 640)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 9, 9, 128)    81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 9, 9, 672)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 9, 9, 672)    2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 9, 9, 672)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 9, 9, 128)    86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 9, 9, 704)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 9, 9, 704)    2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 9, 9, 704)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 9, 9, 128)    90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 9, 9, 736)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 9, 9, 736)    2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 9, 9, 736)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 9, 9, 128)    94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 9, 9, 768)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 9, 9, 768)    3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 9, 9, 768)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 9, 9, 128)    98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 9, 9, 800)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 9, 9, 800)    3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 9, 9, 800)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 9, 9, 128)    102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 9, 9, 832)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 9, 9, 832)    3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 9, 9, 832)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 9, 9, 128)    106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 9, 9, 864)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 9, 9, 864)    3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 9, 9, 864)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 9, 9, 128)    110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 9, 9, 896)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 9, 9, 896)    3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 9, 9, 896)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 9, 9, 128)    114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 9, 9, 928)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 9, 9, 928)    3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 9, 9, 928)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 9, 9, 128)    118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 9, 9, 960)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 9, 9, 960)    3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 9, 9, 960)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 9, 9, 128)    122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 9, 9, 992)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 9, 9, 992)    3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 9, 9, 992)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 9, 9, 128)    126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 9, 9, 1024)   0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 9, 9, 1024)   4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 9, 9, 1024)   0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 9, 9, 512)    524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 4, 4, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 4, 4, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 4, 4, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 4, 4, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 4, 4, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 4, 4, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 4, 4, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 4, 4, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 4, 4, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 4, 4, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 4, 4, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 4, 4, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 4, 4, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 4, 4, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 4, 4, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 4, 4, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 4, 4, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 4, 4, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 4, 4, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 4, 4, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 4, 4, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 4, 4, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 4, 4, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 4, 4, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 4, 4, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 4, 4, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 4, 4, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 4, 4, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 4, 4, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 4, 4, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 4, 4, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 4, 4, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 4, 4, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 4, 4, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 4, 4, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 4, 4, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 4, 4, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 4, 4, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 4, 4, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 4, 4, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 4, 4, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 4, 4, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 4, 4, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 4, 4, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 4, 4, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 4, 4, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 4, 4, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 4, 4, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 4, 4, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 4, 4, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 4, 4, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 4, 4, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 4, 4, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 4, 4, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 4, 4, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 4, 4, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 4, 4, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 4, 4, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 4, 4, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 4, 4, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 4, 4, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 4, 4, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 4, 4, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 4, 4, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 4, 4, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 4, 4, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 4, 4, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, 4, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 4, 4, 1024)   0           bn[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 7,037,504\n",
      "Trainable params: 6,953,856\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base_1 = DenseNet121(weights = None, include_top = True, input_shape = (150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 156, 156, 3)  0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 75, 75, 64)   9408        zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 75, 75, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 75, 75, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 77, 77, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 38, 38, 64)   0           zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 38, 38, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 38, 38, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 38, 38, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 38, 38, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 38, 38, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 38, 38, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 38, 38, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 38, 38, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 38, 38, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 38, 38, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 38, 38, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 38, 38, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 38, 38, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 38, 38, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 38, 38, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 38, 38, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 38, 38, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 38, 38, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 38, 38, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 38, 38, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 38, 38, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 38, 38, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 38, 38, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 38, 38, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 38, 38, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 38, 38, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 38, 38, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 38, 38, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 38, 38, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 38, 38, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 38, 38, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 38, 38, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 38, 38, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 38, 38, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 19, 19, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 19, 19, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 19, 19, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 19, 19, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 19, 19, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 19, 19, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 19, 19, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 19, 19, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 19, 19, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 19, 19, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 19, 19, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 19, 19, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 19, 19, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 19, 19, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 19, 19, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 19, 19, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 19, 19, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 19, 19, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 19, 19, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 19, 19, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 19, 19, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 19, 19, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 19, 19, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 19, 19, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 19, 19, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 19, 19, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 19, 19, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 19, 19, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 19, 19, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 19, 19, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 19, 19, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 19, 19, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 19, 19, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 19, 19, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 19, 19, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 19, 19, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 19, 19, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 19, 19, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 19, 19, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 19, 19, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 19, 19, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 19, 19, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 19, 19, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 19, 19, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 19, 19, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 19, 19, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 19, 19, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 19, 19, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 19, 19, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 19, 19, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 19, 19, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 19, 19, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 19, 19, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 19, 19, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 19, 19, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 19, 19, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 19, 19, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 19, 19, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 19, 19, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 19, 19, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 19, 19, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 19, 19, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 19, 19, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 19, 19, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 19, 19, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 19, 19, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 19, 19, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 19, 19, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 19, 19, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 19, 19, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 19, 19, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 9, 9, 256)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 9, 9, 256)    1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 9, 9, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 9, 9, 128)    32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 9, 9, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 9, 9, 288)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 9, 9, 288)    1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 9, 9, 288)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 9, 9, 128)    36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 9, 9, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 9, 9, 320)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 9, 9, 320)    1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 9, 9, 320)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 9, 9, 128)    40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 9, 9, 128)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 9, 9, 352)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 9, 9, 352)    1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 9, 9, 352)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 9, 9, 128)    45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 9, 9, 128)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 9, 9, 384)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 9, 9, 384)    1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 9, 9, 384)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 9, 9, 128)    49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 9, 9, 128)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 9, 9, 416)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 9, 9, 416)    1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 9, 9, 416)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 9, 9, 128)    53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 9, 9, 128)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 9, 9, 448)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 9, 9, 448)    1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 9, 9, 448)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 9, 9, 128)    57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 9, 9, 128)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 9, 9, 480)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 9, 9, 480)    1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 9, 9, 480)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 9, 9, 128)    61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 9, 9, 128)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 9, 9, 512)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 9, 9, 512)    2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 9, 9, 512)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 9, 9, 128)    65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 9, 9, 128)    512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 9, 9, 128)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 9, 9, 544)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 9, 9, 544)    2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 9, 9, 544)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 9, 9, 128)    69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 9, 9, 576)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 9, 9, 576)    2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 9, 9, 576)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 9, 9, 128)    73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 9, 9, 608)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 9, 9, 608)    2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 9, 9, 608)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 9, 9, 128)    77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 9, 9, 640)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 9, 9, 640)    2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 9, 9, 640)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 9, 9, 128)    81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 9, 9, 672)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 9, 9, 672)    2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 9, 9, 672)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 9, 9, 128)    86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 9, 9, 704)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 9, 9, 704)    2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 9, 9, 704)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 9, 9, 128)    90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 9, 9, 736)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 9, 9, 736)    2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 9, 9, 736)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 9, 9, 128)    94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 9, 9, 768)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 9, 9, 768)    3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 9, 9, 768)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 9, 9, 128)    98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 9, 9, 800)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 9, 9, 800)    3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 9, 9, 800)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 9, 9, 128)    102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 9, 9, 832)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 9, 9, 832)    3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 9, 9, 832)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 9, 9, 128)    106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 9, 9, 864)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 9, 9, 864)    3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 9, 9, 864)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 9, 9, 128)    110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 9, 9, 896)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 9, 9, 896)    3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 9, 9, 896)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 9, 9, 128)    114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 9, 9, 928)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 9, 9, 928)    3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 9, 9, 928)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 9, 9, 128)    118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 9, 9, 960)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 9, 9, 960)    3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 9, 9, 960)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 9, 9, 128)    122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 9, 9, 992)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 9, 9, 992)    3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 9, 9, 992)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 9, 9, 128)    126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 9, 9, 128)    512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 9, 9, 128)    0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 9, 9, 1024)   0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 9, 9, 1024)   4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 9, 9, 1024)   0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 9, 9, 512)    524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 4, 4, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 4, 4, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 4, 4, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 4, 4, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 4, 4, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 4, 4, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 4, 4, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 4, 4, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 4, 4, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 4, 4, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 4, 4, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 4, 4, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 4, 4, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 4, 4, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 4, 4, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 4, 4, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 4, 4, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 4, 4, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 4, 4, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 4, 4, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 4, 4, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 4, 4, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 4, 4, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 4, 4, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 4, 4, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 4, 4, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 4, 4, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 4, 4, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 4, 4, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 4, 4, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 4, 4, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 4, 4, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 4, 4, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 4, 4, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 4, 4, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 4, 4, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 4, 4, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 4, 4, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 4, 4, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 4, 4, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 4, 4, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 4, 4, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 4, 4, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 4, 4, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 4, 4, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 4, 4, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 4, 4, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 4, 4, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 4, 4, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 4, 4, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 4, 4, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 4, 4, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 4, 4, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 4, 4, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 4, 4, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 4, 4, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 4, 4, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 4, 4, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 4, 4, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 4, 4, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 4, 4, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 4, 4, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 4, 4, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 4, 4, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 4, 4, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 4, 4, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 4, 4, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, 4, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 4, 4, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         1025000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 8,062,504\n",
      "Trainable params: 7,978,856\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('own_densenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "dense_net = load_model('own_densenet.h5')\n",
    "#dense_net = own_densenet(weights = None, include_top = True, input_shape = (32, 32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 32, 32, 16)   448         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 32, 32, 16)   64          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 32, 32, 16)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 32, 32, 48)   816         activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_197 (Dropout)           (None, 32, 32, 48)   0           conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 32, 32, 48)   192         dropout_197[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 32, 32, 48)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 32, 32, 12)   5196        activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_198 (Dropout)           (None, 32, 32, 12)   0           conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 32, 32, 28)   0           conv2d_199[0][0]                 \n",
      "                                                                 dropout_198[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 32, 32, 28)   112         concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 32, 32, 28)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 32, 32, 48)   1392        activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_199 (Dropout)           (None, 32, 32, 48)   0           conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 32, 32, 48)   192         dropout_199[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 32, 32, 48)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 32, 32, 12)   5196        activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_200 (Dropout)           (None, 32, 32, 12)   0           conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 32, 32, 40)   0           concatenate_97[0][0]             \n",
      "                                                                 dropout_200[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 32, 32, 40)   160         concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 32, 32, 40)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 32, 32, 48)   1968        activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_201 (Dropout)           (None, 32, 32, 48)   0           conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 32, 32, 48)   192         dropout_201[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 32, 32, 48)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 32, 32, 12)   5196        activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_202 (Dropout)           (None, 32, 32, 12)   0           conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 32, 32, 52)   0           concatenate_98[0][0]             \n",
      "                                                                 dropout_202[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 32, 32, 52)   208         concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 32, 32, 52)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 32, 32, 48)   2544        activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_203 (Dropout)           (None, 32, 32, 48)   0           conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 32, 32, 48)   192         dropout_203[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 32, 32, 48)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 32, 32, 12)   5196        activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_204 (Dropout)           (None, 32, 32, 12)   0           conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 32, 32, 64)   0           concatenate_99[0][0]             \n",
      "                                                                 dropout_204[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 32, 32, 64)   256         concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 32, 32, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 32, 32, 48)   3120        activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_205 (Dropout)           (None, 32, 32, 48)   0           conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 32, 32, 48)   192         dropout_205[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 32, 32, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 32, 32, 12)   5196        activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_206 (Dropout)           (None, 32, 32, 12)   0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 32, 32, 76)   0           concatenate_100[0][0]            \n",
      "                                                                 dropout_206[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 32, 32, 76)   304         concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 32, 32, 76)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 32, 32, 48)   3696        activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_207 (Dropout)           (None, 32, 32, 48)   0           conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 32, 32, 48)   192         dropout_207[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 32, 32, 48)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 32, 32, 12)   5196        activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_208 (Dropout)           (None, 32, 32, 12)   0           conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 32, 32, 88)   0           concatenate_101[0][0]            \n",
      "                                                                 dropout_208[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 32, 32, 88)   352         concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 32, 32, 88)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 32, 32, 48)   4272        activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_209 (Dropout)           (None, 32, 32, 48)   0           conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 32, 32, 48)   192         dropout_209[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 32, 32, 48)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 32, 32, 12)   5196        activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_210 (Dropout)           (None, 32, 32, 12)   0           conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 32, 32, 100)  0           concatenate_102[0][0]            \n",
      "                                                                 dropout_210[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 32, 32, 100)  400         concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 32, 32, 100)  0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 32, 32, 48)   4848        activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_211 (Dropout)           (None, 32, 32, 48)   0           conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 32, 32, 48)   192         dropout_211[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 32, 32, 48)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 32, 32, 12)   5196        activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_212 (Dropout)           (None, 32, 32, 12)   0           conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 32, 32, 112)  0           concatenate_103[0][0]            \n",
      "                                                                 dropout_212[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 32, 32, 112)  448         concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 32, 32, 112)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 32, 32, 48)   5424        activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_213 (Dropout)           (None, 32, 32, 48)   0           conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 32, 32, 48)   192         dropout_213[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 32, 32, 48)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 32, 32, 12)   5196        activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_214 (Dropout)           (None, 32, 32, 12)   0           conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 32, 32, 124)  0           concatenate_104[0][0]            \n",
      "                                                                 dropout_214[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 32, 32, 124)  496         concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 32, 32, 124)  0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 32, 32, 48)   6000        activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_215 (Dropout)           (None, 32, 32, 48)   0           conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 32, 32, 48)   192         dropout_215[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 32, 32, 48)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 32, 32, 12)   5196        activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_216 (Dropout)           (None, 32, 32, 12)   0           conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 32, 32, 136)  0           concatenate_105[0][0]            \n",
      "                                                                 dropout_216[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 32, 32, 136)  544         concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 32, 32, 136)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 32, 32, 48)   6576        activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_217 (Dropout)           (None, 32, 32, 48)   0           conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 32, 32, 48)   192         dropout_217[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 32, 32, 48)   0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 32, 32, 12)   5196        activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_218 (Dropout)           (None, 32, 32, 12)   0           conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 32, 32, 148)  0           concatenate_106[0][0]            \n",
      "                                                                 dropout_218[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 32, 32, 148)  592         concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 32, 32, 148)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 32, 32, 48)   7152        activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_219 (Dropout)           (None, 32, 32, 48)   0           conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 32, 32, 48)   192         dropout_219[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 32, 32, 48)   0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 32, 32, 12)   5196        activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_220 (Dropout)           (None, 32, 32, 12)   0           conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 32, 32, 160)  0           concatenate_107[0][0]            \n",
      "                                                                 dropout_220[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 32, 32, 160)  640         concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 32, 32, 160)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 32, 32, 48)   7728        activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_221 (Dropout)           (None, 32, 32, 48)   0           conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 32, 32, 48)   192         dropout_221[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 32, 32, 48)   0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 32, 32, 12)   5196        activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_222 (Dropout)           (None, 32, 32, 12)   0           conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 32, 32, 172)  0           concatenate_108[0][0]            \n",
      "                                                                 dropout_222[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 32, 32, 172)  688         concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 32, 32, 172)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 32, 32, 48)   8304        activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_223 (Dropout)           (None, 32, 32, 48)   0           conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 32, 32, 48)   192         dropout_223[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 32, 32, 48)   0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 32, 32, 12)   5196        activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_224 (Dropout)           (None, 32, 32, 12)   0           conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 32, 32, 184)  0           concatenate_109[0][0]            \n",
      "                                                                 dropout_224[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 32, 32, 184)  736         concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 32, 32, 184)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 32, 32, 48)   8880        activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_225 (Dropout)           (None, 32, 32, 48)   0           conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 32, 32, 48)   192         dropout_225[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 32, 32, 48)   0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 32, 32, 12)   5196        activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_226 (Dropout)           (None, 32, 32, 12)   0           conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 32, 32, 196)  0           concatenate_110[0][0]            \n",
      "                                                                 dropout_226[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 32, 32, 196)  784         concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 32, 32, 196)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 32, 32, 48)   9456        activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_227 (Dropout)           (None, 32, 32, 48)   0           conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 32, 32, 48)   192         dropout_227[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 32, 32, 48)   0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 32, 32, 12)   5196        activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_228 (Dropout)           (None, 32, 32, 12)   0           conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 32, 32, 208)  0           concatenate_111[0][0]            \n",
      "                                                                 dropout_228[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 32, 32, 208)  832         concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 32, 32, 208)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 32, 32, 104)  21736       activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_229 (Dropout)           (None, 32, 32, 104)  0           conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 16, 16, 104)  0           dropout_229[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 16, 16, 104)  416         average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 16, 16, 104)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 16, 16, 48)   5040        activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_230 (Dropout)           (None, 16, 16, 48)   0           conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 16, 16, 48)   192         dropout_230[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 16, 16, 48)   0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 16, 16, 12)   5196        activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_231 (Dropout)           (None, 16, 16, 12)   0           conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 16, 16, 116)  0           average_pooling2d_5[0][0]        \n",
      "                                                                 dropout_231[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 16, 16, 116)  464         concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 16, 16, 116)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 16, 16, 48)   5616        activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_232 (Dropout)           (None, 16, 16, 48)   0           conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 16, 16, 48)   192         dropout_232[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 16, 16, 48)   0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 16, 16, 12)   5196        activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_233 (Dropout)           (None, 16, 16, 12)   0           conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 16, 16, 128)  0           concatenate_113[0][0]            \n",
      "                                                                 dropout_233[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 16, 16, 128)  512         concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 16, 16, 128)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 16, 16, 48)   6192        activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_234 (Dropout)           (None, 16, 16, 48)   0           conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 16, 16, 48)   192         dropout_234[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 16, 16, 48)   0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 16, 16, 12)   5196        activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_235 (Dropout)           (None, 16, 16, 12)   0           conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 16, 16, 140)  0           concatenate_114[0][0]            \n",
      "                                                                 dropout_235[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 16, 16, 140)  560         concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 16, 16, 140)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 16, 16, 48)   6768        activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_236 (Dropout)           (None, 16, 16, 48)   0           conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 16, 16, 48)   192         dropout_236[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 16, 16, 48)   0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 16, 16, 12)   5196        activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_237 (Dropout)           (None, 16, 16, 12)   0           conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 16, 16, 152)  0           concatenate_115[0][0]            \n",
      "                                                                 dropout_237[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 16, 16, 152)  608         concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 16, 16, 152)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 16, 16, 48)   7344        activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_238 (Dropout)           (None, 16, 16, 48)   0           conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 16, 16, 48)   192         dropout_238[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 16, 16, 48)   0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 16, 16, 12)   5196        activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_239 (Dropout)           (None, 16, 16, 12)   0           conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 16, 16, 164)  0           concatenate_116[0][0]            \n",
      "                                                                 dropout_239[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 16, 16, 164)  656         concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 16, 16, 164)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 16, 16, 48)   7920        activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_240 (Dropout)           (None, 16, 16, 48)   0           conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 16, 16, 48)   192         dropout_240[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 16, 16, 48)   0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 16, 16, 12)   5196        activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_241 (Dropout)           (None, 16, 16, 12)   0           conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 16, 16, 176)  0           concatenate_117[0][0]            \n",
      "                                                                 dropout_241[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 16, 16, 176)  704         concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 16, 16, 176)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 16, 16, 48)   8496        activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_242 (Dropout)           (None, 16, 16, 48)   0           conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 16, 16, 48)   192         dropout_242[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 16, 16, 48)   0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 16, 16, 12)   5196        activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_243 (Dropout)           (None, 16, 16, 12)   0           conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 16, 16, 188)  0           concatenate_118[0][0]            \n",
      "                                                                 dropout_243[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 16, 16, 188)  752         concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 16, 16, 188)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 16, 16, 48)   9072        activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_244 (Dropout)           (None, 16, 16, 48)   0           conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 16, 16, 48)   192         dropout_244[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 16, 16, 48)   0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 16, 16, 12)   5196        activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_245 (Dropout)           (None, 16, 16, 12)   0           conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 16, 16, 200)  0           concatenate_119[0][0]            \n",
      "                                                                 dropout_245[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 16, 16, 200)  800         concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 16, 16, 200)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 16, 16, 48)   9648        activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_246 (Dropout)           (None, 16, 16, 48)   0           conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 16, 16, 48)   192         dropout_246[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 16, 16, 48)   0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 16, 16, 12)   5196        activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_247 (Dropout)           (None, 16, 16, 12)   0           conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 16, 16, 212)  0           concatenate_120[0][0]            \n",
      "                                                                 dropout_247[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 16, 16, 212)  848         concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 16, 16, 212)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 16, 16, 48)   10224       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_248 (Dropout)           (None, 16, 16, 48)   0           conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 16, 16, 48)   192         dropout_248[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 16, 16, 48)   0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 16, 16, 12)   5196        activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_249 (Dropout)           (None, 16, 16, 12)   0           conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 16, 16, 224)  0           concatenate_121[0][0]            \n",
      "                                                                 dropout_249[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 16, 16, 224)  896         concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 16, 16, 224)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 16, 16, 48)   10800       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_250 (Dropout)           (None, 16, 16, 48)   0           conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 16, 16, 48)   192         dropout_250[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 16, 16, 48)   0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 16, 16, 12)   5196        activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_251 (Dropout)           (None, 16, 16, 12)   0           conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 16, 16, 236)  0           concatenate_122[0][0]            \n",
      "                                                                 dropout_251[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 16, 16, 236)  944         concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 16, 16, 236)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 16, 16, 48)   11376       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_252 (Dropout)           (None, 16, 16, 48)   0           conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 16, 16, 48)   192         dropout_252[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 16, 16, 48)   0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 16, 16, 12)   5196        activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_253 (Dropout)           (None, 16, 16, 12)   0           conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 16, 16, 248)  0           concatenate_123[0][0]            \n",
      "                                                                 dropout_253[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 16, 16, 248)  992         concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 16, 16, 248)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 16, 16, 48)   11952       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_254 (Dropout)           (None, 16, 16, 48)   0           conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 16, 16, 48)   192         dropout_254[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 16, 16, 48)   0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 16, 16, 12)   5196        activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_255 (Dropout)           (None, 16, 16, 12)   0           conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 16, 16, 260)  0           concatenate_124[0][0]            \n",
      "                                                                 dropout_255[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 16, 16, 260)  1040        concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 16, 16, 260)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 16, 16, 48)   12528       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_256 (Dropout)           (None, 16, 16, 48)   0           conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 16, 16, 48)   192         dropout_256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 16, 16, 48)   0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 16, 16, 12)   5196        activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_257 (Dropout)           (None, 16, 16, 12)   0           conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 16, 16, 272)  0           concatenate_125[0][0]            \n",
      "                                                                 dropout_257[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 16, 16, 272)  1088        concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 16, 16, 272)  0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 16, 16, 48)   13104       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_258 (Dropout)           (None, 16, 16, 48)   0           conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 16, 16, 48)   192         dropout_258[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 16, 16, 48)   0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 16, 16, 12)   5196        activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_259 (Dropout)           (None, 16, 16, 12)   0           conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 16, 16, 284)  0           concatenate_126[0][0]            \n",
      "                                                                 dropout_259[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 16, 16, 284)  1136        concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 16, 16, 284)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 16, 16, 48)   13680       activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_260 (Dropout)           (None, 16, 16, 48)   0           conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 16, 16, 48)   192         dropout_260[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 16, 16, 48)   0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 16, 16, 12)   5196        activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_261 (Dropout)           (None, 16, 16, 12)   0           conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 16, 16, 296)  0           concatenate_127[0][0]            \n",
      "                                                                 dropout_261[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 16, 16, 296)  1184        concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 16, 16, 296)  0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 16, 16, 148)  43956       activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_262 (Dropout)           (None, 16, 16, 148)  0           conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 8, 8, 148)    0           dropout_262[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 8, 8, 148)    592         average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 8, 8, 148)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 8, 8, 48)     7152        activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_263 (Dropout)           (None, 8, 8, 48)     0           conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 8, 8, 48)     192         dropout_263[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 8, 8, 48)     0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 8, 8, 12)     5196        activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_264 (Dropout)           (None, 8, 8, 12)     0           conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 8, 8, 160)    0           average_pooling2d_6[0][0]        \n",
      "                                                                 dropout_264[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 8, 8, 160)    640         concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 8, 8, 160)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 8, 8, 48)     7728        activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_265 (Dropout)           (None, 8, 8, 48)     0           conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 8, 8, 48)     192         dropout_265[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 8, 8, 48)     0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 8, 8, 12)     5196        activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_266 (Dropout)           (None, 8, 8, 12)     0           conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 8, 8, 172)    0           concatenate_129[0][0]            \n",
      "                                                                 dropout_266[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 8, 8, 172)    688         concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 8, 8, 172)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 8, 8, 48)     8304        activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_267 (Dropout)           (None, 8, 8, 48)     0           conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 8, 8, 48)     192         dropout_267[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 8, 8, 48)     0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 8, 8, 12)     5196        activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_268 (Dropout)           (None, 8, 8, 12)     0           conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 8, 8, 184)    0           concatenate_130[0][0]            \n",
      "                                                                 dropout_268[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 8, 8, 184)    736         concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 8, 8, 184)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 8, 8, 48)     8880        activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_269 (Dropout)           (None, 8, 8, 48)     0           conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 8, 8, 48)     192         dropout_269[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 8, 8, 48)     0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 8, 8, 12)     5196        activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_270 (Dropout)           (None, 8, 8, 12)     0           conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 8, 8, 196)    0           concatenate_131[0][0]            \n",
      "                                                                 dropout_270[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 8, 8, 196)    784         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 8, 8, 196)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 8, 8, 48)     9456        activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_271 (Dropout)           (None, 8, 8, 48)     0           conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 8, 8, 48)     192         dropout_271[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 8, 8, 48)     0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 8, 8, 12)     5196        activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_272 (Dropout)           (None, 8, 8, 12)     0           conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 8, 8, 208)    0           concatenate_132[0][0]            \n",
      "                                                                 dropout_272[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 8, 8, 208)    832         concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 8, 8, 208)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 8, 8, 48)     10032       activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_273 (Dropout)           (None, 8, 8, 48)     0           conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 8, 8, 48)     192         dropout_273[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 8, 8, 48)     0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 8, 8, 12)     5196        activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_274 (Dropout)           (None, 8, 8, 12)     0           conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 8, 8, 220)    0           concatenate_133[0][0]            \n",
      "                                                                 dropout_274[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 8, 8, 220)    880         concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 8, 8, 220)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 8, 8, 48)     10608       activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_275 (Dropout)           (None, 8, 8, 48)     0           conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 8, 8, 48)     192         dropout_275[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 8, 8, 48)     0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 8, 8, 12)     5196        activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_276 (Dropout)           (None, 8, 8, 12)     0           conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 8, 8, 232)    0           concatenate_134[0][0]            \n",
      "                                                                 dropout_276[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 8, 8, 232)    928         concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 8, 8, 232)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 8, 8, 48)     11184       activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_277 (Dropout)           (None, 8, 8, 48)     0           conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 8, 8, 48)     192         dropout_277[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 8, 8, 48)     0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 8, 8, 12)     5196        activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_278 (Dropout)           (None, 8, 8, 12)     0           conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 8, 8, 244)    0           concatenate_135[0][0]            \n",
      "                                                                 dropout_278[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 8, 8, 244)    976         concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 8, 8, 244)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 8, 8, 48)     11760       activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_279 (Dropout)           (None, 8, 8, 48)     0           conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 8, 8, 48)     192         dropout_279[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 8, 8, 48)     0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 8, 8, 12)     5196        activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_280 (Dropout)           (None, 8, 8, 12)     0           conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 8, 8, 256)    0           concatenate_136[0][0]            \n",
      "                                                                 dropout_280[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 8, 8, 256)    1024        concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 8, 8, 256)    0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 8, 8, 48)     12336       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_281 (Dropout)           (None, 8, 8, 48)     0           conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 8, 8, 48)     192         dropout_281[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 8, 8, 48)     0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 8, 8, 12)     5196        activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_282 (Dropout)           (None, 8, 8, 12)     0           conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 8, 8, 268)    0           concatenate_137[0][0]            \n",
      "                                                                 dropout_282[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 8, 8, 268)    1072        concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 8, 8, 268)    0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 8, 8, 48)     12912       activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_283 (Dropout)           (None, 8, 8, 48)     0           conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 8, 8, 48)     192         dropout_283[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 8, 8, 48)     0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 8, 8, 12)     5196        activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_284 (Dropout)           (None, 8, 8, 12)     0           conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 8, 8, 280)    0           concatenate_138[0][0]            \n",
      "                                                                 dropout_284[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 8, 8, 280)    1120        concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 8, 8, 280)    0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 8, 8, 48)     13488       activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_285 (Dropout)           (None, 8, 8, 48)     0           conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 8, 8, 48)     192         dropout_285[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 8, 8, 48)     0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 8, 8, 12)     5196        activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_286 (Dropout)           (None, 8, 8, 12)     0           conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 8, 8, 292)    0           concatenate_139[0][0]            \n",
      "                                                                 dropout_286[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 8, 8, 292)    1168        concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 8, 8, 292)    0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 8, 8, 48)     14064       activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_287 (Dropout)           (None, 8, 8, 48)     0           conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 8, 8, 48)     192         dropout_287[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 8, 8, 48)     0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 8, 8, 12)     5196        activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_288 (Dropout)           (None, 8, 8, 12)     0           conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 8, 8, 304)    0           concatenate_140[0][0]            \n",
      "                                                                 dropout_288[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 8, 8, 304)    1216        concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 8, 8, 304)    0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 8, 8, 48)     14640       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_289 (Dropout)           (None, 8, 8, 48)     0           conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 8, 8, 48)     192         dropout_289[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 8, 8, 48)     0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 8, 8, 12)     5196        activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_290 (Dropout)           (None, 8, 8, 12)     0           conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 8, 8, 316)    0           concatenate_141[0][0]            \n",
      "                                                                 dropout_290[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 8, 8, 316)    1264        concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 8, 8, 316)    0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 8, 8, 48)     15216       activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_291 (Dropout)           (None, 8, 8, 48)     0           conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 8, 8, 48)     192         dropout_291[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 8, 8, 48)     0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 8, 8, 12)     5196        activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_292 (Dropout)           (None, 8, 8, 12)     0           conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 8, 8, 328)    0           concatenate_142[0][0]            \n",
      "                                                                 dropout_292[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 8, 8, 328)    1312        concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 8, 8, 328)    0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 8, 8, 48)     15792       activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_293 (Dropout)           (None, 8, 8, 48)     0           conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 8, 8, 48)     192         dropout_293[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 8, 8, 48)     0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 8, 8, 12)     5196        activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_294 (Dropout)           (None, 8, 8, 12)     0           conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 8, 8, 340)    0           concatenate_143[0][0]            \n",
      "                                                                 dropout_294[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 8, 8, 340)    1360        concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 8, 8, 340)    0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 340)          0           activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           3410        global_average_pooling2d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 781,470\n",
      "Trainable params: 757,958\n",
      "Non-trainable params: 23,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 32, 32, 16)   448         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 32, 32, 16)   64          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 32, 32, 16)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 32, 32, 48)   816         activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_197 (Dropout)           (None, 32, 32, 48)   0           conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 32, 32, 48)   192         dropout_197[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 32, 32, 48)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 32, 32, 12)   5196        activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_198 (Dropout)           (None, 32, 32, 12)   0           conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 32, 32, 28)   0           conv2d_199[0][0]                 \n",
      "                                                                 dropout_198[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 32, 32, 28)   112         concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 32, 32, 28)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 32, 32, 48)   1392        activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_199 (Dropout)           (None, 32, 32, 48)   0           conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 32, 32, 48)   192         dropout_199[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 32, 32, 48)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 32, 32, 12)   5196        activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_200 (Dropout)           (None, 32, 32, 12)   0           conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 32, 32, 40)   0           concatenate_97[0][0]             \n",
      "                                                                 dropout_200[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 32, 32, 40)   160         concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 32, 32, 40)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 32, 32, 48)   1968        activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_201 (Dropout)           (None, 32, 32, 48)   0           conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 32, 32, 48)   192         dropout_201[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 32, 32, 48)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 32, 32, 12)   5196        activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_202 (Dropout)           (None, 32, 32, 12)   0           conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 32, 32, 52)   0           concatenate_98[0][0]             \n",
      "                                                                 dropout_202[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 32, 32, 52)   208         concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 32, 32, 52)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 32, 32, 48)   2544        activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_203 (Dropout)           (None, 32, 32, 48)   0           conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 32, 32, 48)   192         dropout_203[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 32, 32, 48)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 32, 32, 12)   5196        activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_204 (Dropout)           (None, 32, 32, 12)   0           conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 32, 32, 64)   0           concatenate_99[0][0]             \n",
      "                                                                 dropout_204[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 32, 32, 64)   256         concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 32, 32, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 32, 32, 48)   3120        activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_205 (Dropout)           (None, 32, 32, 48)   0           conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 32, 32, 48)   192         dropout_205[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 32, 32, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 32, 32, 12)   5196        activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_206 (Dropout)           (None, 32, 32, 12)   0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 32, 32, 76)   0           concatenate_100[0][0]            \n",
      "                                                                 dropout_206[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 32, 32, 76)   304         concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 32, 32, 76)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 32, 32, 48)   3696        activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_207 (Dropout)           (None, 32, 32, 48)   0           conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 32, 32, 48)   192         dropout_207[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 32, 32, 48)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 32, 32, 12)   5196        activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_208 (Dropout)           (None, 32, 32, 12)   0           conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 32, 32, 88)   0           concatenate_101[0][0]            \n",
      "                                                                 dropout_208[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 32, 32, 88)   352         concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 32, 32, 88)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 32, 32, 48)   4272        activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_209 (Dropout)           (None, 32, 32, 48)   0           conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 32, 32, 48)   192         dropout_209[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 32, 32, 48)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 32, 32, 12)   5196        activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_210 (Dropout)           (None, 32, 32, 12)   0           conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 32, 32, 100)  0           concatenate_102[0][0]            \n",
      "                                                                 dropout_210[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 32, 32, 100)  400         concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 32, 32, 100)  0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 32, 32, 48)   4848        activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_211 (Dropout)           (None, 32, 32, 48)   0           conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 32, 32, 48)   192         dropout_211[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 32, 32, 48)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 32, 32, 12)   5196        activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_212 (Dropout)           (None, 32, 32, 12)   0           conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 32, 32, 112)  0           concatenate_103[0][0]            \n",
      "                                                                 dropout_212[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 32, 32, 112)  448         concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 32, 32, 112)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 32, 32, 48)   5424        activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_213 (Dropout)           (None, 32, 32, 48)   0           conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 32, 32, 48)   192         dropout_213[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 32, 32, 48)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 32, 32, 12)   5196        activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_214 (Dropout)           (None, 32, 32, 12)   0           conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 32, 32, 124)  0           concatenate_104[0][0]            \n",
      "                                                                 dropout_214[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 32, 32, 124)  496         concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 32, 32, 124)  0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 32, 32, 48)   6000        activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_215 (Dropout)           (None, 32, 32, 48)   0           conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 32, 32, 48)   192         dropout_215[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 32, 32, 48)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 32, 32, 12)   5196        activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_216 (Dropout)           (None, 32, 32, 12)   0           conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 32, 32, 136)  0           concatenate_105[0][0]            \n",
      "                                                                 dropout_216[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 32, 32, 136)  544         concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 32, 32, 136)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 32, 32, 48)   6576        activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_217 (Dropout)           (None, 32, 32, 48)   0           conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 32, 32, 48)   192         dropout_217[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 32, 32, 48)   0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 32, 32, 12)   5196        activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_218 (Dropout)           (None, 32, 32, 12)   0           conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 32, 32, 148)  0           concatenate_106[0][0]            \n",
      "                                                                 dropout_218[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 32, 32, 148)  592         concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 32, 32, 148)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 32, 32, 48)   7152        activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_219 (Dropout)           (None, 32, 32, 48)   0           conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 32, 32, 48)   192         dropout_219[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 32, 32, 48)   0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 32, 32, 12)   5196        activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_220 (Dropout)           (None, 32, 32, 12)   0           conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 32, 32, 160)  0           concatenate_107[0][0]            \n",
      "                                                                 dropout_220[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 32, 32, 160)  640         concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 32, 32, 160)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 32, 32, 48)   7728        activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_221 (Dropout)           (None, 32, 32, 48)   0           conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 32, 32, 48)   192         dropout_221[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 32, 32, 48)   0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 32, 32, 12)   5196        activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_222 (Dropout)           (None, 32, 32, 12)   0           conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 32, 32, 172)  0           concatenate_108[0][0]            \n",
      "                                                                 dropout_222[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 32, 32, 172)  688         concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 32, 32, 172)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 32, 32, 48)   8304        activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_223 (Dropout)           (None, 32, 32, 48)   0           conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 32, 32, 48)   192         dropout_223[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 32, 32, 48)   0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 32, 32, 12)   5196        activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_224 (Dropout)           (None, 32, 32, 12)   0           conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 32, 32, 184)  0           concatenate_109[0][0]            \n",
      "                                                                 dropout_224[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 32, 32, 184)  736         concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 32, 32, 184)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 32, 32, 48)   8880        activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_225 (Dropout)           (None, 32, 32, 48)   0           conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 32, 32, 48)   192         dropout_225[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 32, 32, 48)   0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 32, 32, 12)   5196        activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_226 (Dropout)           (None, 32, 32, 12)   0           conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 32, 32, 196)  0           concatenate_110[0][0]            \n",
      "                                                                 dropout_226[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 32, 32, 196)  784         concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 32, 32, 196)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 32, 32, 48)   9456        activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_227 (Dropout)           (None, 32, 32, 48)   0           conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 32, 32, 48)   192         dropout_227[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 32, 32, 48)   0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 32, 32, 12)   5196        activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_228 (Dropout)           (None, 32, 32, 12)   0           conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 32, 32, 208)  0           concatenate_111[0][0]            \n",
      "                                                                 dropout_228[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 32, 32, 208)  832         concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 32, 32, 208)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 32, 32, 104)  21736       activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_229 (Dropout)           (None, 32, 32, 104)  0           conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 16, 16, 104)  0           dropout_229[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 16, 16, 104)  416         average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 16, 16, 104)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 16, 16, 48)   5040        activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_230 (Dropout)           (None, 16, 16, 48)   0           conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 16, 16, 48)   192         dropout_230[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 16, 16, 48)   0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 16, 16, 12)   5196        activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_231 (Dropout)           (None, 16, 16, 12)   0           conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 16, 16, 116)  0           average_pooling2d_5[0][0]        \n",
      "                                                                 dropout_231[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 16, 16, 116)  464         concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 16, 16, 116)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 16, 16, 48)   5616        activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_232 (Dropout)           (None, 16, 16, 48)   0           conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 16, 16, 48)   192         dropout_232[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 16, 16, 48)   0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 16, 16, 12)   5196        activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_233 (Dropout)           (None, 16, 16, 12)   0           conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 16, 16, 128)  0           concatenate_113[0][0]            \n",
      "                                                                 dropout_233[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 16, 16, 128)  512         concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 16, 16, 128)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 16, 16, 48)   6192        activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_234 (Dropout)           (None, 16, 16, 48)   0           conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 16, 16, 48)   192         dropout_234[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 16, 16, 48)   0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 16, 16, 12)   5196        activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_235 (Dropout)           (None, 16, 16, 12)   0           conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 16, 16, 140)  0           concatenate_114[0][0]            \n",
      "                                                                 dropout_235[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 16, 16, 140)  560         concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 16, 16, 140)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 16, 16, 48)   6768        activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_236 (Dropout)           (None, 16, 16, 48)   0           conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 16, 16, 48)   192         dropout_236[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 16, 16, 48)   0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 16, 16, 12)   5196        activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_237 (Dropout)           (None, 16, 16, 12)   0           conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 16, 16, 152)  0           concatenate_115[0][0]            \n",
      "                                                                 dropout_237[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 16, 16, 152)  608         concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 16, 16, 152)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 16, 16, 48)   7344        activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_238 (Dropout)           (None, 16, 16, 48)   0           conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 16, 16, 48)   192         dropout_238[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 16, 16, 48)   0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 16, 16, 12)   5196        activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_239 (Dropout)           (None, 16, 16, 12)   0           conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 16, 16, 164)  0           concatenate_116[0][0]            \n",
      "                                                                 dropout_239[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 16, 16, 164)  656         concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 16, 16, 164)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 16, 16, 48)   7920        activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_240 (Dropout)           (None, 16, 16, 48)   0           conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 16, 16, 48)   192         dropout_240[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 16, 16, 48)   0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 16, 16, 12)   5196        activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_241 (Dropout)           (None, 16, 16, 12)   0           conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 16, 16, 176)  0           concatenate_117[0][0]            \n",
      "                                                                 dropout_241[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 16, 16, 176)  704         concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 16, 16, 176)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 16, 16, 48)   8496        activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_242 (Dropout)           (None, 16, 16, 48)   0           conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 16, 16, 48)   192         dropout_242[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 16, 16, 48)   0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 16, 16, 12)   5196        activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_243 (Dropout)           (None, 16, 16, 12)   0           conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 16, 16, 188)  0           concatenate_118[0][0]            \n",
      "                                                                 dropout_243[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 16, 16, 188)  752         concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 16, 16, 188)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 16, 16, 48)   9072        activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_244 (Dropout)           (None, 16, 16, 48)   0           conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 16, 16, 48)   192         dropout_244[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 16, 16, 48)   0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 16, 16, 12)   5196        activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_245 (Dropout)           (None, 16, 16, 12)   0           conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 16, 16, 200)  0           concatenate_119[0][0]            \n",
      "                                                                 dropout_245[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 16, 16, 200)  800         concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 16, 16, 200)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 16, 16, 48)   9648        activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_246 (Dropout)           (None, 16, 16, 48)   0           conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 16, 16, 48)   192         dropout_246[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 16, 16, 48)   0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 16, 16, 12)   5196        activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_247 (Dropout)           (None, 16, 16, 12)   0           conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 16, 16, 212)  0           concatenate_120[0][0]            \n",
      "                                                                 dropout_247[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 16, 16, 212)  848         concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 16, 16, 212)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 16, 16, 48)   10224       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_248 (Dropout)           (None, 16, 16, 48)   0           conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 16, 16, 48)   192         dropout_248[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 16, 16, 48)   0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 16, 16, 12)   5196        activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_249 (Dropout)           (None, 16, 16, 12)   0           conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 16, 16, 224)  0           concatenate_121[0][0]            \n",
      "                                                                 dropout_249[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 16, 16, 224)  896         concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 16, 16, 224)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 16, 16, 48)   10800       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_250 (Dropout)           (None, 16, 16, 48)   0           conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 16, 16, 48)   192         dropout_250[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 16, 16, 48)   0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 16, 16, 12)   5196        activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_251 (Dropout)           (None, 16, 16, 12)   0           conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 16, 16, 236)  0           concatenate_122[0][0]            \n",
      "                                                                 dropout_251[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 16, 16, 236)  944         concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 16, 16, 236)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 16, 16, 48)   11376       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_252 (Dropout)           (None, 16, 16, 48)   0           conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 16, 16, 48)   192         dropout_252[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 16, 16, 48)   0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 16, 16, 12)   5196        activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_253 (Dropout)           (None, 16, 16, 12)   0           conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 16, 16, 248)  0           concatenate_123[0][0]            \n",
      "                                                                 dropout_253[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 16, 16, 248)  992         concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 16, 16, 248)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 16, 16, 48)   11952       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_254 (Dropout)           (None, 16, 16, 48)   0           conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 16, 16, 48)   192         dropout_254[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 16, 16, 48)   0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 16, 16, 12)   5196        activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_255 (Dropout)           (None, 16, 16, 12)   0           conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 16, 16, 260)  0           concatenate_124[0][0]            \n",
      "                                                                 dropout_255[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 16, 16, 260)  1040        concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 16, 16, 260)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 16, 16, 48)   12528       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_256 (Dropout)           (None, 16, 16, 48)   0           conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 16, 16, 48)   192         dropout_256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 16, 16, 48)   0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 16, 16, 12)   5196        activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_257 (Dropout)           (None, 16, 16, 12)   0           conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 16, 16, 272)  0           concatenate_125[0][0]            \n",
      "                                                                 dropout_257[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 16, 16, 272)  1088        concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 16, 16, 272)  0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 16, 16, 48)   13104       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_258 (Dropout)           (None, 16, 16, 48)   0           conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 16, 16, 48)   192         dropout_258[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 16, 16, 48)   0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 16, 16, 12)   5196        activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_259 (Dropout)           (None, 16, 16, 12)   0           conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 16, 16, 284)  0           concatenate_126[0][0]            \n",
      "                                                                 dropout_259[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 16, 16, 284)  1136        concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 16, 16, 284)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 16, 16, 48)   13680       activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_260 (Dropout)           (None, 16, 16, 48)   0           conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 16, 16, 48)   192         dropout_260[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 16, 16, 48)   0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 16, 16, 12)   5196        activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_261 (Dropout)           (None, 16, 16, 12)   0           conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 16, 16, 296)  0           concatenate_127[0][0]            \n",
      "                                                                 dropout_261[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 16, 16, 296)  1184        concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 16, 16, 296)  0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 16, 16, 148)  43956       activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_262 (Dropout)           (None, 16, 16, 148)  0           conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 8, 8, 148)    0           dropout_262[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 8, 8, 148)    592         average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 8, 8, 148)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 8, 8, 48)     7152        activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_263 (Dropout)           (None, 8, 8, 48)     0           conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 8, 8, 48)     192         dropout_263[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 8, 8, 48)     0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 8, 8, 12)     5196        activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_264 (Dropout)           (None, 8, 8, 12)     0           conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 8, 8, 160)    0           average_pooling2d_6[0][0]        \n",
      "                                                                 dropout_264[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 8, 8, 160)    640         concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 8, 8, 160)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 8, 8, 48)     7728        activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_265 (Dropout)           (None, 8, 8, 48)     0           conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 8, 8, 48)     192         dropout_265[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 8, 8, 48)     0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 8, 8, 12)     5196        activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_266 (Dropout)           (None, 8, 8, 12)     0           conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 8, 8, 172)    0           concatenate_129[0][0]            \n",
      "                                                                 dropout_266[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 8, 8, 172)    688         concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 8, 8, 172)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 8, 8, 48)     8304        activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_267 (Dropout)           (None, 8, 8, 48)     0           conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 8, 8, 48)     192         dropout_267[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 8, 8, 48)     0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 8, 8, 12)     5196        activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_268 (Dropout)           (None, 8, 8, 12)     0           conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 8, 8, 184)    0           concatenate_130[0][0]            \n",
      "                                                                 dropout_268[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 8, 8, 184)    736         concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 8, 8, 184)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 8, 8, 48)     8880        activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_269 (Dropout)           (None, 8, 8, 48)     0           conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 8, 8, 48)     192         dropout_269[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 8, 8, 48)     0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 8, 8, 12)     5196        activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_270 (Dropout)           (None, 8, 8, 12)     0           conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 8, 8, 196)    0           concatenate_131[0][0]            \n",
      "                                                                 dropout_270[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 8, 8, 196)    784         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 8, 8, 196)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 8, 8, 48)     9456        activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_271 (Dropout)           (None, 8, 8, 48)     0           conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 8, 8, 48)     192         dropout_271[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 8, 8, 48)     0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 8, 8, 12)     5196        activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_272 (Dropout)           (None, 8, 8, 12)     0           conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 8, 8, 208)    0           concatenate_132[0][0]            \n",
      "                                                                 dropout_272[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 8, 8, 208)    832         concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 8, 8, 208)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 8, 8, 48)     10032       activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_273 (Dropout)           (None, 8, 8, 48)     0           conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 8, 8, 48)     192         dropout_273[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 8, 8, 48)     0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 8, 8, 12)     5196        activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_274 (Dropout)           (None, 8, 8, 12)     0           conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 8, 8, 220)    0           concatenate_133[0][0]            \n",
      "                                                                 dropout_274[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 8, 8, 220)    880         concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 8, 8, 220)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 8, 8, 48)     10608       activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_275 (Dropout)           (None, 8, 8, 48)     0           conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 8, 8, 48)     192         dropout_275[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 8, 8, 48)     0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 8, 8, 12)     5196        activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_276 (Dropout)           (None, 8, 8, 12)     0           conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 8, 8, 232)    0           concatenate_134[0][0]            \n",
      "                                                                 dropout_276[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 8, 8, 232)    928         concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 8, 8, 232)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 8, 8, 48)     11184       activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_277 (Dropout)           (None, 8, 8, 48)     0           conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 8, 8, 48)     192         dropout_277[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 8, 8, 48)     0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 8, 8, 12)     5196        activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_278 (Dropout)           (None, 8, 8, 12)     0           conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 8, 8, 244)    0           concatenate_135[0][0]            \n",
      "                                                                 dropout_278[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 8, 8, 244)    976         concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 8, 8, 244)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 8, 8, 48)     11760       activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_279 (Dropout)           (None, 8, 8, 48)     0           conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 8, 8, 48)     192         dropout_279[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 8, 8, 48)     0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 8, 8, 12)     5196        activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_280 (Dropout)           (None, 8, 8, 12)     0           conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 8, 8, 256)    0           concatenate_136[0][0]            \n",
      "                                                                 dropout_280[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 8, 8, 256)    1024        concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 8, 8, 256)    0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 8, 8, 48)     12336       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_281 (Dropout)           (None, 8, 8, 48)     0           conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 8, 8, 48)     192         dropout_281[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 8, 8, 48)     0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 8, 8, 12)     5196        activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_282 (Dropout)           (None, 8, 8, 12)     0           conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 8, 8, 268)    0           concatenate_137[0][0]            \n",
      "                                                                 dropout_282[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 8, 8, 268)    1072        concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 8, 8, 268)    0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 8, 8, 48)     12912       activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_283 (Dropout)           (None, 8, 8, 48)     0           conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 8, 8, 48)     192         dropout_283[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 8, 8, 48)     0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 8, 8, 12)     5196        activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_284 (Dropout)           (None, 8, 8, 12)     0           conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 8, 8, 280)    0           concatenate_138[0][0]            \n",
      "                                                                 dropout_284[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 8, 8, 280)    1120        concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 8, 8, 280)    0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 8, 8, 48)     13488       activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_285 (Dropout)           (None, 8, 8, 48)     0           conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 8, 8, 48)     192         dropout_285[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 8, 8, 48)     0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 8, 8, 12)     5196        activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_286 (Dropout)           (None, 8, 8, 12)     0           conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 8, 8, 292)    0           concatenate_139[0][0]            \n",
      "                                                                 dropout_286[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 8, 8, 292)    1168        concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 8, 8, 292)    0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 8, 8, 48)     14064       activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_287 (Dropout)           (None, 8, 8, 48)     0           conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 8, 8, 48)     192         dropout_287[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 8, 8, 48)     0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 8, 8, 12)     5196        activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_288 (Dropout)           (None, 8, 8, 12)     0           conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 8, 8, 304)    0           concatenate_140[0][0]            \n",
      "                                                                 dropout_288[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 8, 8, 304)    1216        concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 8, 8, 304)    0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 8, 8, 48)     14640       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_289 (Dropout)           (None, 8, 8, 48)     0           conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 8, 8, 48)     192         dropout_289[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 8, 8, 48)     0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 8, 8, 12)     5196        activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_290 (Dropout)           (None, 8, 8, 12)     0           conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 8, 8, 316)    0           concatenate_141[0][0]            \n",
      "                                                                 dropout_290[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 8, 8, 316)    1264        concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 8, 8, 316)    0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 8, 8, 48)     15216       activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_291 (Dropout)           (None, 8, 8, 48)     0           conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 8, 8, 48)     192         dropout_291[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 8, 8, 48)     0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 8, 8, 12)     5196        activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_292 (Dropout)           (None, 8, 8, 12)     0           conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 8, 8, 328)    0           concatenate_142[0][0]            \n",
      "                                                                 dropout_292[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 8, 8, 328)    1312        concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 8, 8, 328)    0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 8, 8, 48)     15792       activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_293 (Dropout)           (None, 8, 8, 48)     0           conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 8, 8, 48)     192         dropout_293[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 8, 8, 48)     0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 8, 8, 12)     5196        activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_294 (Dropout)           (None, 8, 8, 12)     0           conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 8, 8, 340)    0           concatenate_143[0][0]            \n",
      "                                                                 dropout_294[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 8, 8, 340)    1360        concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 8, 8, 340)    0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 340)          0           activation_297[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 778,060\n",
      "Trainable params: 754,548\n",
      "Non-trainable params: 23,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_net.layers.pop()\n",
    "dense_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
