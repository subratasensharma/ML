{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = 10\n",
    "\n",
    "xs = np.random.uniform(low = -10, high = 10, size = (observations,1))\n",
    "zs = np.random.uniform(low = -10, high = 10, size = (observations,1))\n",
    "\n",
    "generated_inputs = np.column_stack((xs, zs))\n",
    "noise = np.random.uniform(low = -1, high = 1, size = (observations,1))\n",
    "\n",
    "generated_targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "# Now we want a format that can store the info in tensors. One of the way is to create .npz files. This is \\\n",
    "# good to save from a excell file or csv file, may not be required here where we have generated arrays\n",
    "\n",
    "np.savez('TF_intro_data', my_inputs = generated_inputs, my_targets = generated_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2689224  -9.75199274]\n",
      " [ 6.38644751 -7.54109515]\n",
      " [ 2.06626695  0.66216665]\n",
      " [ 4.23077192 -2.82074197]\n",
      " [ 1.1624892  -3.56214096]\n",
      " [ 2.33508934  1.06724794]\n",
      " [ 9.63307616  9.08846083]\n",
      " [-0.84646136 -7.71584586]\n",
      " [ 3.60830036 -2.80593004]\n",
      " [ 6.78579551  0.71308766]]\n",
      "(10, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "============================\n",
      "(10, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "[[-0.2689224  -9.75199274]\n",
      " [ 6.38644751 -7.54109515]\n",
      " [ 2.06626695  0.66216665]\n",
      " [ 4.23077192 -2.82074197]\n",
      " [ 1.1624892  -3.56214096]\n",
      " [ 2.33508934  1.06724794]\n",
      " [ 9.63307616  9.08846083]\n",
      " [-0.84646136 -7.71584586]\n",
      " [ 3.60830036 -2.80593004]\n",
      " [ 6.78579551  0.71308766]]\n"
     ]
    }
   ],
   "source": [
    "my_npzfile = np.load('TF_intro_data.npz') # pl. note that while loading(i.e. np.load), we should write the \\\n",
    "                                          # file name along with .npz\n",
    "print(my_npzfile['my_inputs'])\n",
    "print(my_npzfile['my_inputs'].shape)\n",
    "print(type(my_npzfile['my_inputs']))\n",
    "print('============================')\n",
    "\n",
    "print(generated_inputs.shape)\n",
    "print(type(generated_inputs))\n",
    "print(generated_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3]\n",
      " [4 5 6 7]]\n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# Below is just another example of how to save data in .npz file\n",
    "arr1 = np.arange(8).reshape(2,4)\n",
    "arr2 = np.arange(10).reshape(2,5)\n",
    "np.savez('mat', name1 = arr1, name2 = arr2)\n",
    "\n",
    "data = np.load('mat.npz')\n",
    "print(data['name1'])\n",
    "print(data['name2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = 1000\n",
    "\n",
    "xs = np.random.uniform(low = -10, high = 10, size = (observations,1))\n",
    "zs = np.random.uniform(low = -10, high = 10, size = (observations,1))\n",
    "\n",
    "generated_inputs = np.column_stack((xs, zs))\n",
    "noise = np.random.uniform(low = -1, high = 1, size = (observations,1))\n",
    "\n",
    "generated_targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "# Now we want a format that can store the info in tensors. One of the way is to create .npz files. This is \\\n",
    "# good to save from a excell file or csv file, may not be required here where we have generated arrays\n",
    "\n",
    "np.savez('TF_intro_data', my_inputs = generated_inputs, my_targets = generated_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_input_variable = 2  # xs and zs\n",
    "Number_output = 1  # generated_targets\n",
    "\n",
    "# INPUTS :\n",
    "\n",
    "x1 = tf.placeholder(tf.float32, [None, Number_input_variable]) #this creates a matrix x of size observations(due to \\\n",
    "                                                            # 'None') X Number_input_variables\n",
    "# my_inputs = tf.placeholder(tf.float32, [None, Number_input_variable])\n",
    "# my_targets = tf.placeholder(tf.float32, [None, Number_output])\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None, Number_output])\n",
    "\n",
    "# PARAMETERS :\n",
    "\n",
    "weights = tf.Variable(tf.random_uniform([Number_input_variable, Number_output], minval = -0.1, maxval = 0.1))\n",
    "biases = tf.Variable(tf.random_uniform([Number_output], minval = -0.1, maxval = 0.1))\n",
    "\n",
    "# OUTPUTS :\n",
    "\n",
    "y_hat = tf.matmul(x1, weights) + biases\n",
    "# y_hat = tf.matmul(my_inputs, weights) + biases\n",
    "\n",
    "# Objective Function :\n",
    "\n",
    "mean_loss = tf.losses.mean_squared_error(labels = y, predictions = y_hat) / 2.\n",
    "# mean_loss = tf.losses.mean_squared_error(labels = my_targets, predictions = y_hat) / 2.\n",
    "\n",
    "# Optimizer :\n",
    "\n",
    "optimize = tf.train.GradientDescentOptimizer(learning_rate = 0.05).minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "initializer = tf.global_variables_initializer()\n",
    "sess.run(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_20:0' shape=(2, 1) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_21:0' shape=(1,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.78993862  2.84629836]\n",
      " [ 2.46812871  4.41876478]\n",
      " [-7.40009082  5.78817723]\n",
      " ...\n",
      " [ 1.57951353  0.21396629]\n",
      " [ 4.38851842 -2.88746595]\n",
      " [ 4.30633729 -6.47753082]]\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load('TF_intro_data.npz')\n",
    "print(train_data['my_inputs'])\n",
    "x1 = train_data['my_inputs']\n",
    "y = train_data['my_targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-1e3f6d32e332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'my_inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'my_targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "\n",
    "for e in range(100):        \n",
    "        \n",
    "    _, curr_loss = sess.run([optimize, mean_loss], feed_dict = {x1:train_data['my_inputs'], y:train_data['my_targets']})\n",
    "    print(curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
