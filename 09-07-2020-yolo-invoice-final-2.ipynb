{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/models/research/object_detection\n"
     ]
    }
   ],
   "source": [
    "cd models/research/object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3e1b2f885786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tqdm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import *\n",
    "\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.applications import InceptionResNetV2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = [480, 480]\n",
    "target_w = 480 # target sizes of image in model input\n",
    "target_h = 480 #target sizes of image in model input\n",
    "\n",
    "grid_size = [15, 15]\n",
    "grid_y_axis = 15  # each image is to be segmented to 13 x 13 grid\n",
    "grid_x_axis = 15  # # each image is to be segmented to 13 x 13 grid\n",
    "\n",
    "grid_w = target_w / grid_x_axis  # grid cell width\n",
    "grid_h = target_h / grid_y_axis  # grid cell height\n",
    "\n",
    "channels = 3\n",
    "num_anchors = 3\n",
    "class_num = 5 # vendor, invoice, inv_date, po, buyer\n",
    "info = 5 + class_num    # pc, x, y, h, w, and class probabilities\n",
    "\n",
    "categories = ['vendor', 'invoice', 'inv_date', 'po', 'buyer'] # details of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images =  36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/scar3crow/Downloads/8-6-new-scan/50a.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a list of image path\n",
    "\n",
    "inv_directory = '/home/scar3crow/Downloads/8-6-new-scan'  ## 'invoices' is a zip file of jpg images in ...../Downloads \n",
    "                                                        \n",
    "inv_new_image = ['/home/scar3crow/Downloads/8-6-new-scan/{}'.format(i) for i in os.listdir(inv_directory)] # making the list\n",
    "inv_new_image.sort() # Sorting the list\n",
    "\n",
    "num_images = len(inv_new_image)\n",
    "\n",
    "print('Number of images = ', num_images)\n",
    "inv_new_image[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_serial</th>\n",
       "      <th>rows</th>\n",
       "      <th>columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/101a.jpg</td>\n",
       "      <td>160</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/102a.jpg</td>\n",
       "      <td>406</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/103a.jpg</td>\n",
       "      <td>260</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image_serial  rows  columns\n",
       "0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg   160      416\n",
       "1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg   406      870\n",
       "2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   260      416"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check sizes of exiting images & Create a Dataframe with image id and height(row) and width(column):\n",
    "\n",
    "rows = []\n",
    "columns = []\n",
    "image_sl = []\n",
    "df_new = pd.DataFrame()\n",
    "\n",
    "for i in range(len(inv_new_image)):\n",
    "    image = cv2.imread(inv_new_image[i]) ## Loading image\n",
    "    height, width, _ = image.shape\n",
    "    rows.append(height)\n",
    "    columns.append(width)\n",
    "    image_sl.append(inv_new_image[i])\n",
    "    \n",
    "row_values = pd.Series(rows)\n",
    "col_values = pd.Series(columns)\n",
    "image_num = pd.Series(image_sl)\n",
    "\n",
    "\n",
    "df_new.insert(loc=0, column='image_serial', value=image_num)\n",
    "df_new.insert(loc=1, column='rows', value=row_values)\n",
    "df_new.insert(loc=2, column='columns', value=col_values)\n",
    "\n",
    "df_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes =  5\n",
      "Number of unique images =  36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#filename</th>\n",
       "      <th>region_shape_attributes</th>\n",
       "      <th>region_attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>63a.jpg</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":211,\"y\":64,\"width\":76,\"heig...</td>\n",
       "      <td>{\"text\":\"po\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>63a.jpg</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":2,\"y\":68,\"width\":165,\"heigh...</td>\n",
       "      <td>{\"text\":\"buyer\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>101a.jpg</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":6,\"y\":23,\"width\":119,\"heigh...</td>\n",
       "      <td>{\"text\":\"vendor\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #filename                            region_shape_attributes  \\\n",
       "58   63a.jpg  {\"name\":\"rect\",\"x\":211,\"y\":64,\"width\":76,\"heig...   \n",
       "59   63a.jpg  {\"name\":\"rect\",\"x\":2,\"y\":68,\"width\":165,\"heigh...   \n",
       "60  101a.jpg  {\"name\":\"rect\",\"x\":6,\"y\":23,\"width\":119,\"heigh...   \n",
       "\n",
       "    region_attributes  \n",
       "58      {\"text\":\"po\"}  \n",
       "59   {\"text\":\"buyer\"}  \n",
       "60  {\"text\":\"vendor\"}  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading output of VGG Image Annotation tool and create a dataframe\n",
    "\n",
    "r_new_data = pd.read_csv('/home/scar3crow/Downloads/via_new_data.csv')\n",
    "num_obj = r_new_data['region_count'][0] # number of objects in each photo\n",
    "r_new_data.drop(r_new_data.columns[[1, 2, 3, 4]], axis=1, inplace=True) # reduce unnecessary columns\n",
    "r_new_data.sort_values(by=['#filename'], ascending=True) # Sorting based on image-id\n",
    "num_images = r_new_data[\"#filename\"].nunique() # Find out number of unique images\n",
    "\n",
    "print('Number of classes = ', num_obj)\n",
    "print('Number of unique images = ', num_images)\n",
    "r_new_data[58:61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>img_idx</th>\n",
       "      <th>i_path</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>obj_class</th>\n",
       "      <th>img_wd</th>\n",
       "      <th>img_ht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50a.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/50a.jpg</td>\n",
       "      <td>221</td>\n",
       "      <td>59</td>\n",
       "      <td>103</td>\n",
       "      <td>24</td>\n",
       "      <td>po</td>\n",
       "      <td>416</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50a.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/50a.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>206</td>\n",
       "      <td>56</td>\n",
       "      <td>buyer</td>\n",
       "      <td>416</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51a.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/51a.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>vendor</td>\n",
       "      <td>416</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    img_id  img_idx                                          i_path    x   y  \\\n",
       "3  50a.jpg       24  /home/scar3crow/Downloads/8-6-new-scan/50a.jpg  221  59   \n",
       "4  50a.jpg       24  /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5  57   \n",
       "5  51a.jpg       25  /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    5   0   \n",
       "\n",
       "   width  height obj_class  img_wd  img_ht  \n",
       "3    103      24        po     416     209  \n",
       "4    206      56     buyer     416     209  \n",
       "5    120      56    vendor     416     194  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a dataframe for Image_id, x, y, width, height, class, image_width and image_height\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "width = []\n",
    "height = []\n",
    "obj_class = []\n",
    "i_width = []\n",
    "i_height = []\n",
    "img_path = []\n",
    "img_index = []\n",
    "\n",
    "for i in range(len(r_new_data)):\n",
    "    \n",
    "    r_size = r_new_data.values[i, 1][1:(len(r_new_data.values[i, 1])-1)]\n",
    "    r_size_par = r_size.split(\",\")\n",
    "    \n",
    "    x.append(int(\"\".join(filter(str.isdigit, r_size_par[1]))))\n",
    "    y.append(int(\"\".join(filter(str.isdigit, r_size_par[2]))))\n",
    "    width.append(int(\"\".join(filter(str.isdigit, r_size_par[3]))))\n",
    "    height.append(int(\"\".join(filter(str.isdigit, r_size_par[4]))))\n",
    "    \n",
    "    r_attribs = r_new_data.values[i, 2][1:(len(r_new_data.values[i, 2])-1)]\n",
    "    r_attribs_par = r_attribs.split(':')[1]\n",
    "    obj_class.append(r_attribs_par[1:(len(r_attribs_par)-1)])\n",
    "    \n",
    "    foto_id = r_new_data['#filename'][i]\n",
    "    i_path = '/home/scar3crow/Downloads/8-6-new-scan/' + foto_id\n",
    "    foto_index = int(df_new[df_new['image_serial'] == i_path].index[0])\n",
    "    foto_width = df_new['columns'][foto_index]\n",
    "    foto_height = df_new['rows'][foto_index]\n",
    "    i_width.append(foto_width)\n",
    "    i_height.append(foto_height)\n",
    "    img_path.append(i_path)\n",
    "    img_index.append(foto_index)\n",
    "    \n",
    "x_values = pd.Series(x)\n",
    "y_values = pd.Series(y)\n",
    "width_values = pd.Series(width)\n",
    "height_values = pd.Series(height)\n",
    "class_values = pd.Series(obj_class)\n",
    "i_width_values = pd.Series(i_width)\n",
    "i_height_values = pd.Series(i_height)\n",
    "img_path_values = pd.Series(img_path)\n",
    "img_index_values = pd.Series(img_index)\n",
    "\n",
    "r_new_data.insert(loc=1, column='img_idx', value=img_index_values)\n",
    "r_new_data.insert(loc=2, column='i_path', value=img_path_values)\n",
    "r_new_data.insert(loc=3, column='x', value=x_values)\n",
    "r_new_data.insert(loc=4, column='y', value=y_values)\n",
    "r_new_data.insert(loc=5, column='width', value=width_values)\n",
    "r_new_data.insert(loc=6, column='height', value=height_values)\n",
    "r_new_data.insert(loc=7, column='obj_class', value=class_values)\n",
    "r_new_data.insert(loc=8, column='img_wd', value=i_width_values)\n",
    "r_new_data.insert(loc=9, column='img_ht', value=i_height_values)\n",
    "\n",
    "r_new_data.drop(r_new_data.columns[[10, 11]], axis=1, inplace=True) # reduce unnecessary columns\n",
    "\n",
    "r_new_data.rename({'#filename': 'img_id'}, axis=1, inplace=True) # changing column name\n",
    "\n",
    "r_new_data[3:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images =  36\n",
      "Number of classes in diff. categories =  buyer      38\n",
      "date       36\n",
      "vendor     36\n",
      "invoice    36\n",
      "po         33\n",
      "order       1\n",
      "Name: obj_class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique images = ', r_new_data['img_id'].nunique())  # print total no, of unique images\n",
    "print('Number of classes in diff. categories = ', r_new_data['obj_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[       img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ,\n",
       "        img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ,\n",
       "        img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ,\n",
       "        img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ,\n",
       "        img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ,\n",
       "        img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to correct above :\n",
    "\n",
    "# To find smallest width & height boxes in 'buyer' which should be 'po'\n",
    "gb = r_new_data.groupby('obj_class')    \n",
    "[gb.get_group('buyer') for x in gb.groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images =  36\n",
      "Number of unique classes =  5\n",
      "Number of classes in diff. categories =  buyer       36\n",
      "inv_date    36\n",
      "vendor      36\n",
      "invoice     36\n",
      "po          36\n",
      "Name: obj_class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Correcting above wrong spelling & converting buyer to po of object classes and rechecking\n",
    "\n",
    "id_1 = r_new_data.index[r_new_data['obj_class'] == 'order'] # Finding the index\n",
    "id_2 = r_new_data.index[r_new_data['obj_class'] == 'date'] # to change 'date' to 'inv_date' to be consistent with old data\n",
    "\n",
    "r_new_data.at[id_1, 'obj_class'] = 'po' # writing the correct spelling \n",
    "r_new_data.at[88, 'obj_class'] = 'po' # # 'buyer' to 'po'\n",
    "r_new_data.at[163, 'obj_class'] = 'po' # # 'buyer' to 'po'\n",
    "r_new_data.at[id_2, 'obj_class'] = 'inv_date' # # 'date' to 'inv_date'\n",
    "\n",
    "print('Number of unique images = ', r_new_data['img_id'].nunique())  # print total no, of unique images\n",
    "print('Number of unique classes = ', r_new_data['obj_class'].nunique())\n",
    "print('Number of classes in diff. categories = ', r_new_data['obj_class'].value_counts())\n",
    "\n",
    "# r_new_data.drop(r_new_data.columns[[0]], axis=1, inplace=True) # reduce unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each image, we have to find : (a) line_index = integer, (b) img_path = string, (c) boxes = shape [N, 4], \n",
    "## N is the ground truth count, elements in the second dimension are [x_min, y_min, x_max, y_max] (d) labels = shape\n",
    "## [N]. class index. (e) img_width = int.  =f) img_height = int\n",
    "\n",
    "def single_image_info(lines):\n",
    "    \n",
    "    ## lines will be a dataframe like, for i in range(num_images), lines = r_new_data[i*5:(i+1)*5]\n",
    "    \n",
    "    line_idx = lines.iat[0, 1]\n",
    "    pic_path = lines.iat[0, 2]\n",
    "    img_width = lines.iat[0, 8]\n",
    "    img_height = lines.iat[0, 9]\n",
    "    \n",
    "    boxes = []\n",
    "    labels = []\n",
    "    for i in range(len(lines)):\n",
    "        label, x_min, y_min, x_max, y_max = int(i), float(lines.iat[i,3]), float(lines.iat[i,4]), float(lines.iat[i,3]+lines.iat[i,5]), float(lines.iat[i,4]+lines.iat[i,6])\n",
    "        boxes.append([x_min, y_min, x_max, y_max])\n",
    "        labels.append(label)\n",
    "        \n",
    "    boxes = np.asarray(boxes, np.float32)\n",
    "    labels = np.asarray(labels, np.int64)\n",
    "    \n",
    "    return line_idx, pic_path, boxes, labels, img_width, img_height  ## boxes are in format xmin, ymin, xmax, ymax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "[25, '/home/scar3crow/Downloads/8-6-new-scan/51a.jpg', array([[  5.,   0., 125.,  56.],\n",
      "       [239.,   1., 279.,  20.],\n",
      "       [328.,   1., 382.,  21.],\n",
      "       [238.,  51., 302.,  74.],\n",
      "       [  4.,  53., 156., 117.]], dtype=float32), array([0, 1, 2, 3, 4]), 416, 194]\n"
     ]
    }
   ],
   "source": [
    "## Creating the complete data set :\n",
    "\n",
    "all_image_line = []\n",
    "for i in range(num_images):\n",
    "    image_line = []\n",
    "    limit_lower = i*5\n",
    "    limit_upper = limit_lower+5\n",
    "    lines = r_new_data[limit_lower:limit_upper]\n",
    "    line_idx, pic_path, boxes, labels, img_width, img_height = single_image_info(lines)\n",
    "    image_line.append(line_idx)\n",
    "    image_line.append(pic_path)\n",
    "    image_line.append(boxes)\n",
    "    image_line.append(labels)\n",
    "    image_line.append(img_width)\n",
    "    image_line.append(img_height)\n",
    "    all_image_line.append(image_line)\n",
    "    \n",
    "print(len(all_image_line))\n",
    "print(all_image_line[1])   ##  boxes are in format xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 140 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## Train and Test split\n",
    "\n",
    "data_train, data_val = train_test_split(all_image_line, train_size = 0.8 , shuffle = True)\n",
    "\n",
    "num_all_bbox = len(all_image_line) * len(all_image_line[0][2])\n",
    "num_bb_train = len(data_train) * len(data_train[0][2])\n",
    "num_bb_val = len(data_val) * len(data_val[0][2])\n",
    "print(num_all_bbox, num_bb_train, num_bb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating anchors from true boundary boxes :\n",
    "\n",
    "def iou_kmeans(box, clusters):\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) between a box and k clusters.\n",
    "    :param box: tuple or array, shifted to the origin (i. e. width and height)\n",
    "    :param clusters: numpy array of shape (k, 2) where k is the number of clusters\n",
    "    :return: numpy array of shape (k, 0) where k is the number of clusters\n",
    "    \"\"\"\n",
    "    x = np.minimum(clusters[:, 0], box[0])\n",
    "    y = np.minimum(clusters[:, 1], box[1])\n",
    "    if np.count_nonzero(x == 0) > 0 or np.count_nonzero(y == 0) > 0:\n",
    "        raise ValueError(\"Box has no area\")\n",
    "\n",
    "    intersection = x * y\n",
    "    box_area = box[0] * box[1]\n",
    "    cluster_area = clusters[:, 0] * clusters[:, 1]\n",
    "\n",
    "    iou = intersection / (box_area + cluster_area - intersection)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def kmeans(boxes, k, dist=np.median):\n",
    "    \"\"\"\n",
    "    Calculates k-means clustering with the Intersection over Union (IoU) metric.\n",
    "    :param boxes: numpy array of shape (r, 2), where r is the number of rows\n",
    "    :param k: number of clusters\n",
    "    :param dist: distance function\n",
    "    :return: numpy array of shape (k, 2)\n",
    "    \"\"\"\n",
    "    rows = boxes.shape[0]\n",
    "\n",
    "    distances = np.empty((rows, k))\n",
    "    last_clusters = np.zeros((rows,))\n",
    "\n",
    "    np.random.seed()\n",
    "\n",
    "    # the Forgy method will fail if the whole array contains the same rows\n",
    "    clusters = boxes[np.random.choice(rows, k, replace=False)]\n",
    "\n",
    "\n",
    "    while True:\n",
    "        for row in range(rows):\n",
    "            distances[row] = 1 - iou_kmeans(boxes[row], clusters)\n",
    "\n",
    "        nearest_clusters = np.argmin(distances, axis=1)\n",
    "\n",
    "        if (last_clusters == nearest_clusters).all():\n",
    "            break\n",
    "\n",
    "        for cluster in range(k):\n",
    "            clusters[cluster] = dist(boxes[nearest_clusters == cluster], axis=0)\n",
    "\n",
    "        last_clusters = nearest_clusters\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[129.23076923  37.92592593]\n",
      " [ 68.07692308  65.30612245]\n",
      " [189.80769231 160.36697248]]\n"
     ]
    }
   ],
   "source": [
    "## Finding out anchors :\n",
    "## Firstly, converting true boundary box width, height to width & height with respect to target image :\n",
    "## finaly find anchors. Anchors here are in absolute size w.r.t. target image but not as % of target image or \n",
    "## as multiple of unit grids.\n",
    "\n",
    "# num_all_bb = len(r_new_data) # if no. of bboxes varies for images, this formula should be used \n",
    "\n",
    "num_all_bb = len(all_image_line) * len(all_image_line[0][2])  ## from all image line data\n",
    "\n",
    "b_box_wrt_target = np.zeros((num_all_bb,2))\n",
    "\n",
    "for i in range(num_all_bb):\n",
    "    \n",
    "    image_w = r_new_data['img_wd'][i]\n",
    "    image_h = r_new_data['img_ht'][i]\n",
    "\n",
    "    x_ratio = target_w / image_w \n",
    "    y_ratio = target_h / image_h\n",
    "    \n",
    "    anchor_w = r_new_data['width'][i] * x_ratio\n",
    "    anchor_h = r_new_data['height'][i] * y_ratio\n",
    "    b_box_wrt_target[i, 0] = anchor_w\n",
    "    b_box_wrt_target[i, 1] = anchor_h\n",
    "    \n",
    "anchors_wrt_target = kmeans(b_box_wrt_target, num_anchors)\n",
    "\n",
    "print(anchors_wrt_target.shape)\n",
    "print(anchors_wrt_target)     ## anchors wrt target image in abs. value and in format width, height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-processing the original data to get y_true :\n",
    "\n",
    "def process_box(ori_boxes, ori_img_width, ori_img_height, labels, target_size, class_num, anchors):\n",
    "    '''\n",
    "    Generate the y_true label, i.e. the ground truth feature_map.\n",
    "    params:\n",
    "        boxes: [N, 5] shape, float32 dtype. `x_min, y_min, x_max, y_mix, mixup_weight`.\n",
    "        labels: [N] shape, int64 dtype.\n",
    "        class_num: int64 num.\n",
    "        anchors: [3,2] shape, float32 dtype.\n",
    "    '''\n",
    "    \n",
    "    img_width = ori_img_width\n",
    "    img_height = ori_img_height\n",
    "    boxes = ori_boxes           ## boxes in format xmin, ymin, xmax, ymax\n",
    "    \n",
    "    x_ratio = target_size[1] / img_width\n",
    "    y_ratio = target_size[0] / img_height\n",
    "    \n",
    "    boxes_wrt_target = np.zeros((5,4))\n",
    "    box_centers_target = np.zeros((5,2))\n",
    "\n",
    "    boxes_wrt_target[:,0] = boxes[:,0] * x_ratio  # xmin absolute value wrt target image\n",
    "    boxes_wrt_target[:,1] = boxes[:,1] * y_ratio  # ymin absolute value wrt target image\n",
    "    boxes_wrt_target[:,2] = boxes[:,2] * x_ratio  # xmax absolute value wrt target image\n",
    "    boxes_wrt_target[:,3] = boxes[:,3] * y_ratio  # ymax absolute value wrt target image\n",
    "    \n",
    "    # In above, boxes_wrt_target shape is (5, 4), now this will be taken to (5. 5) by adding 1 at end\n",
    "#    boxes_wrt_target = np.concatenate((boxes_wrt_target, np.full(shape=(boxes_wrt_target.shape[0], 1), fill_value=1., dtype=np.float32)), axis=-1)\n",
    "    box_centers_target = (boxes_wrt_target[:, 0:2] + boxes_wrt_target[:, 2:4]) / 2  ## centers wrt target, abs values\n",
    "    \n",
    "    box_sizes = boxes[:, 2:4] - boxes[:, 0:2]  #xmax-xmin = width and ymax-ymin = height wrt original image\n",
    "    box_sizes[:,0] = box_sizes[:,0] * x_ratio  # width w.r.t target image in absolute value\n",
    "    box_sizes[:,1] = box_sizes[:,1] * y_ratio  # width w.r.t target image in absolute value\n",
    "    \n",
    "#    y_true_13 = np.zeros((target_size[1] // 32, target_size[0] // 32, 3, 6 + class_num), np.float32)\n",
    "    y_true_13 = np.zeros((target_size[1] // 32, target_size[0] // 32, 3, 5 + class_num), np.float32)\n",
    "\n",
    "#    y_true = [y_true_13]\n",
    "    \n",
    "    box_sizes = np.expand_dims(box_sizes, 1)\n",
    "    mins = np.maximum(- box_sizes / 2, - anchors / 2)\n",
    "    maxs = np.minimum(box_sizes / 2, anchors / 2)\n",
    "    whs = maxs - mins\n",
    "\n",
    "    iou = (whs[:, :, 0] * whs[:, :, 1]) / (\n",
    "                box_sizes[:, :, 0] * box_sizes[:, :, 1] + anchors[:, 0] * anchors[:, 1] - whs[:, :, 0] * whs[:, :,\n",
    "                                                                                                         1] + 1e-10)\n",
    "    best_match_idx = np.argmax(iou, axis=1)\n",
    "\n",
    "    anchor_mask = np.zeros((target_size[1] // 32, target_size[0] // 32, 3))\n",
    "\n",
    "    cell_size = 32  ## = targetsize / no. of grid cells\n",
    "    \n",
    "    for i, idx in enumerate(best_match_idx):\n",
    "\n",
    "        x = int(np.floor(box_centers_target[i, 0] / cell_size))\n",
    "        y = int(np.floor(box_centers_target[i, 1] / cell_size))\n",
    "        k = int(idx)\n",
    "        c = int(labels[i])\n",
    "\n",
    "#        print(x, y, k, c)\n",
    "\n",
    "# Very Imp : Now preparing y_true: all values x_center, y_cemter, width & height are being taken to % of target image\n",
    "        \n",
    "        y_true_13[y, x, k, :2] = box_centers_target[i] / target_size[0] #since target_size[0] = target_size[1]\n",
    "        y_true_13[y, x, k, 2:4] = box_sizes[i] / target_size[0]\n",
    "        y_true_13[y, x, k, 4] = 1.\n",
    "        y_true_13[y, x, k, 5 + c] = 1.\n",
    "#        y_true[0][y, x, k, -1] = boxes_wrt_target[i, -1]\n",
    "        anchor_mask[y, x, k] = 1\n",
    "\n",
    "    return y_true_13, anchor_mask  ## all data are w.r.to target image in % of target image and NOT w,r,t, grid cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Single image-wise image/boundary box preprocessing:\n",
    "\n",
    "def parse_data(line, class_num, target_size, anchors):   ## (mode, letterbox_resize):\n",
    "    '''\n",
    "    param:\n",
    "        line: a line from the training/test txt file\n",
    "        class_num: totol class nums.\n",
    "        target_size: the size of image to be resized to. [width, height] format.\n",
    "        anchors: anchors.\n",
    "        mode: 'train' or 'val'. When set to 'train', data_augmentation will be applied.\n",
    "        letterbox_resize: whether to use the letterbox resize, i.e., keep the original aspect ratio in the resized image.\n",
    "    '''\n",
    "    \n",
    "    img_idx, pic_path, boxes, labels,img_width, img_height = line  # boxes in format xmin, ymin, xmax, ymax\n",
    "    img = cv2.imread(pic_path)\n",
    "    img_resized = cv2.resize(img,(target_size[0], target_size[1]))\n",
    "    \n",
    "    # expand the 2nd dimension, mix up weight default to 1.\n",
    "    boxes = np.concatenate((boxes, np.full(shape=(boxes.shape[0], 1), fill_value=1., dtype=np.float32)), axis=-1)\n",
    "\n",
    "    img_resized = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "\n",
    "    # the input of yolo_v3 should be in range 0~1, lets change to -0.5 to +0.5\n",
    "    img_resized = (img_resized - 127.5)/ 255.\n",
    "\n",
    "    y_true_13, anchor_mask = process_box(boxes, img_width, img_height, labels, target_size, class_num, anchors)\n",
    "\n",
    "    return img_idx, img_resized, y_true_13, anchor_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making the data ready for entering into network :\n",
    "\n",
    "anchors = anchors_wrt_target\n",
    "image_index = []\n",
    "image_resized = []\n",
    "image_y_true = []\n",
    "image_anchor_mask = []\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "\n",
    "    line = data_train[i]\n",
    "    \n",
    "    img_idx, img_resized, y_true, anchor_mask = parse_data(line, class_num, target_size, anchors)\n",
    "    \n",
    "    \n",
    "    image_index.append(img_idx)\n",
    "    image_resized.append(img_resized)\n",
    "    image_y_true.append(y_true)\n",
    "    image_anchor_mask.append(anchor_mask)\n",
    "    \n",
    "train_image_index = image_index\n",
    "X_train = np.array(image_resized)\n",
    "Y_train = np.array(image_y_true)\n",
    "train_anchor_mask = np.array(image_anchor_mask)\n",
    "\n",
    "image_index = []\n",
    "image_resized = []\n",
    "image_y_true = []\n",
    "image_anchor_mask = []\n",
    "\n",
    "for i in range(len(data_val)):\n",
    "    line = data_val[i]\n",
    "    \n",
    "    img_idx, img_resized, y_true, anchor_mask = parse_data(line, class_num, target_size, anchors)\n",
    "    image_index.append(img_idx)\n",
    "    image_resized.append(img_resized)\n",
    "    image_y_true.append(y_true)\n",
    "    image_anchor_mask.append(anchor_mask)\n",
    "val_image_index = image_index\n",
    "X_val = np.array(image_resized)\n",
    "Y_val = np.array(image_y_true)\n",
    "val_anchor_mask = np.array(image_anchor_mask)\n",
    "\n",
    "image_index = []\n",
    "image_resized = []\n",
    "image_y_true = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 28 28 8 8 8\n",
      "[26, 13, 9, 4, 35, 15, 20, 6, 24, 33, 29, 23, 0, 30, 5, 22, 3, 1, 18, 10, 14, 34, 2, 7, 27, 28, 19, 11]\n",
      "(28, 480, 480, 3) (28, 15, 15, 3, 10)\n",
      "26 (480, 480, 3) (15, 15, 3, 10)\n",
      "(28, 15, 15, 3) and (15, 15, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(Y_train), len(train_image_index), len(X_val), len(Y_val), len(val_image_index))\n",
    "print(train_image_index)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(train_image_index[0], X_train[0].shape, Y_train[0].shape)\n",
    "print(train_anchor_mask.shape, 'and', train_anchor_mask[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqd_index = int(r_new_data[r_new_data['img_idx'] == 18].index[0])\n",
    "reqd_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>img_idx</th>\n",
       "      <th>i_path</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>obj_class</th>\n",
       "      <th>img_wd</th>\n",
       "      <th>img_ht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>119a.jpg</td>\n",
       "      <td>18</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/119a.jpg</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>135</td>\n",
       "      <td>55</td>\n",
       "      <td>vendor</td>\n",
       "      <td>416</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>119a.jpg</td>\n",
       "      <td>18</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/119a.jpg</td>\n",
       "      <td>240</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>22</td>\n",
       "      <td>invoice</td>\n",
       "      <td>416</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>119a.jpg</td>\n",
       "      <td>18</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/119a.jpg</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>inv_date</td>\n",
       "      <td>416</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>119a.jpg</td>\n",
       "      <td>18</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/119a.jpg</td>\n",
       "      <td>240</td>\n",
       "      <td>36</td>\n",
       "      <td>63</td>\n",
       "      <td>24</td>\n",
       "      <td>po</td>\n",
       "      <td>416</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>119a.jpg</td>\n",
       "      <td>18</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/119a.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>169</td>\n",
       "      <td>78</td>\n",
       "      <td>buyer</td>\n",
       "      <td>416</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       img_id  img_idx                                           i_path    x  \\\n",
       "150  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg   56   \n",
       "151  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg  240   \n",
       "152  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg  333   \n",
       "153  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg  240   \n",
       "154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       "\n",
       "      y  width  height obj_class  img_wd  img_ht  \n",
       "150   6    135      55    vendor     416     146  \n",
       "151   3     73      22   invoice     416     146  \n",
       "152   1     50      21  inv_date     416     146  \n",
       "153  36     63      24        po     416     146  \n",
       "154  62    169      78     buyer     416     146  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_new_data[150:155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ethanyanjiali/deep-vision/blob/master/YOLO/tensorflow/utils.py\n",
    "\n",
    "def xywh_to_x1y1x2y2(box):\n",
    "    xy = box[..., 0:2]\n",
    "    wh = box[..., 2:4]\n",
    "\n",
    "    x1y1 = xy - wh / 2\n",
    "    x2y2 = xy + wh / 2\n",
    "\n",
    "    y_box = K.concatenate([x1y1, x2y2], axis=-1)\n",
    "    return y_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ethanyanjiali/deep-vision/blob/master/YOLO/tensorflow/utils.py\n",
    "\n",
    "def broadcast_iou(box_a, box_b):\n",
    "    \"\"\"\n",
    "    calculate iou between box_a and multiple box_b in a broadcast way\n",
    "    inputs: box_a: a tensor full of boxes, eg. (B, N, 4), box is in x1y1x2y2\n",
    "            box_b: another tensor full of boxes, eg. (B, M, 4)\n",
    "    \"\"\"\n",
    "\n",
    "    # (B, N, 1, 4)\n",
    "    box_a = tf.expand_dims(box_a, -2)\n",
    "    # (B, 1, M, 4)\n",
    "    box_b = tf.expand_dims(box_b, -3)\n",
    "    # (B, N, M, 4)\n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_a), tf.shape(box_b))\n",
    "\n",
    "    # (B, N, M, 4)\n",
    "    # (B, N, M, 4)\n",
    "    box_a = tf.broadcast_to(box_a, new_shape)\n",
    "    box_b = tf.broadcast_to(box_b, new_shape)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    al, at, ar, ab = tf.split(box_a, 4, -1)\n",
    "    bl, bt, br, bb = tf.split(box_b, 4, -1)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    left = tf.math.maximum(al, bl)\n",
    "    right = tf.math.minimum(ar, br)\n",
    "    top = tf.math.maximum(at, bt)\n",
    "    bot = tf.math.minimum(ab, bb)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    iw = tf.clip_by_value(right - left, 0, 1)\n",
    "    ih = tf.clip_by_value(bot - top, 0, 1)\n",
    "    i = iw * ih\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    area_a = (ar - al) * (ab - at)\n",
    "    area_b = (br - bl) * (bb - bt)\n",
    "    union = area_a + area_b - i\n",
    "\n",
    "    # (B, N, M)\n",
    "    iou = tf.squeeze(i / (union + 1e-7), axis=-1)\n",
    "\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/ethanyanjiali/deep-vision/blob/master/YOLO/tensorflow/yolov3.py#L213\n",
    "\n",
    "def calc_ignore_mask(ignore_thresh, true_box, pred_box):\n",
    "    \n",
    "        # YOLOv3:\n",
    "        # \"If the bounding box prior is not the best but does overlap a ground\n",
    "        # truth object by more than some threshold we ignore the prediction,\n",
    "        # following [17]. We use the threshold of .5.\"\n",
    "        # calculate the iou for each pair of pred bbox and true bbox, then find the best among them\n",
    "\n",
    "        # (None, 13, 13, 3, 4)\n",
    "        \n",
    "        true_box_reorganised = xywh_to_x1y1x2y2(true_box)  # reorganised to x1, y1, x2, y2\n",
    "        pred_box_reorganised = xywh_to_x1y1x2y2(pred_box)\n",
    "        \n",
    "        true_box_shape = tf.shape(true_box_reorganised)  \n",
    "        # (None, 13, 13, 3, 4)\n",
    "        pred_box_shape = tf.shape(pred_box_reorganised)  \n",
    "        # (None, 507, 4)\n",
    "        true_box_reorganised = tf.reshape(true_box_reorganised, [true_box_shape[0], -1, 4])\n",
    "        # sort true_box to have non-zero boxes rank first\n",
    "        true_box_reorganised = tf.sort(true_box_reorganised, axis=1, direction=\"DESCENDING\")\n",
    "        # (None, 100, 4)\n",
    "        # only use maximum 100 boxes per groundtruth to calcualte IOU, otherwise\n",
    "        # GPU emory comsumption would explode for a matrix like (16, 52*52*3, 52*52*3, 4)\n",
    "        true_box_reorganised = true_box_reorganised[:, 0:100, :]\n",
    "        # (None, 507, 4)\n",
    "        pred_box_reorganised = tf.reshape(pred_box_reorganised, [pred_box_shape[0], -1, 4])\n",
    "\n",
    "        # https://github.com/dmlc/gluon-cv/blob/06bb7ec2044cdf3f433721be9362ab84b02c5a90/gluoncv/model_zoo/yolo/yolo_target.py#L198\n",
    "        # (None, 507, 507)\n",
    "        iou = broadcast_iou(pred_box_reorganised, true_box_reorganised)\n",
    "        # (None, 507)\n",
    "        best_iou = tf.reduce_max(iou, axis=-1)\n",
    "        # (None, 13, 13, 3)\n",
    "        best_iou = tf.reshape(best_iou, [pred_box_shape[0], pred_box_shape[1], pred_box_shape[2], pred_box_shape[3]])\n",
    "        # ignore_mask = 1 => don't ignore\n",
    "        # ignore_mask = 0 => should ignore\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "        # (None, 13, 13, 3, 1)\n",
    "        ignore_mask = tf.expand_dims(ignore_mask, axis=-1)\n",
    "        \n",
    "        return ignore_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(logits, labels):\n",
    "    epsilon = 1e-7\n",
    "    logits = tf.clip_by_value(logits, epsilon, 1 - epsilon)\n",
    "    return -(labels * tf.math.log(logits) +\n",
    "             (1 - labels) * tf.math.log(1 - logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def yolo_my_loss(y_true, y_pred, anchors_wrt_target):\n",
    "def yolo_my_loss(y_true, y_pred):\n",
    "    \n",
    "    '''Return yolo_loss\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh ## w.r.t. target size\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "    '''\n",
    "    grid_size = [15., 15.]\n",
    "    ratio = 480./15.      ## ratio = 32\n",
    "    ignore_thresh = 0.5\n",
    "    Lambda_Coord = 5.0\n",
    "    Lambda_no_obj = 0.5\n",
    "    \n",
    "    grid_x = np.arange(grid_size[1])\n",
    "    grid_y = np.arange(grid_size[0])\n",
    "    grid_x, grid_y = np.meshgrid(grid_x, grid_y)\n",
    "    grid_1st = np.dstack((grid_x, grid_y))\n",
    "    grid_2nd = np.dstack((grid_1st, grid_x, grid_y))\n",
    "    grid_3rd = np.dstack((grid_2nd, grid_x, grid_y)) \n",
    "    grid_final = np.reshape(grid_3rd, [1,15,15,3,2])\n",
    "    \n",
    "    loss = tf.zeros(1, dtype='float32')\n",
    "    \n",
    "    \n",
    "#    m = y_true.shape[0]\n",
    "#    m = np.expand_dims(m, axis=-1)\n",
    "#    mf = K.cast(m, dtype='float32')\n",
    "\n",
    "    \n",
    "    obj_mask_y = y_true[..., 4:5]\n",
    "    obj_mask = K.cast(obj_mask_y, dtype='float32')\n",
    "    \n",
    "#    true_box_wh = y_true[..., 2:4]\n",
    "#    weight = 2 - true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "#    weight = np.expand_dims(weight, axis=-1)\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n",
    "    pred_box_xy = K.sigmoid(y_pred[..., :2]) + grid_final  # this gives x & y in no. of cells. x & y w.r.t. target\n",
    "                                                            # image = (x & y in no. of cells) / no. of cells\n",
    "        \n",
    "#    Lambda_Coord = K.cast(Lambda_Coord, dtype = 'float32')\n",
    "    pred_box_xy_wrt_target_image = pred_box_xy / grid_size[0]\n",
    "    true_box_xy_wrt_target_image = y_true[..., :2]\n",
    "    \n",
    "    pred_box_xy_wrt_ti = K.cast(pred_box_xy_wrt_target_image, dtype = 'float32')\n",
    "    true_box_xy_wrt_ti = K.cast(true_box_xy_wrt_target_image, dtype = 'float32')\n",
    "    \n",
    "    xy_arr = K.cast((true_box_xy_wrt_ti - pred_box_xy_wrt_ti), dtype='float32')\n",
    "    \n",
    "    xy_loss = K.cast(Lambda_Coord * tf.reduce_sum(tf.square(xy_arr) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "    \n",
    "#    xy_loss = (Lambda_Coord *np.sum(mean_squared_error(true_box_xy_wrt_ti, pred_box_xy_wrt_ti) * obj_mask*weight)) / m\n",
    "    \n",
    "#    xy_loss = (Lambda_Coord *np.sum(mean_squared_error(true_box_xy_wrt_ti, pred_box_xy_wrt_ti) * obj_mask*weight)) / m\n",
    "    \n",
    "#    xy_loss = (Lambda_Coord*tf.reduce_sum(tf.square(true_box_xy_wrt_ti - pred_box_xy_wrt_ti) *obj_mask))/m\n",
    "#    wh_loss = tf.reduce_sum(tf.square(true_tw_th - pred_tw_th) * object_mask * box_loss_scale * mix_w) / N\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n",
    "    pred_box_wdht = K.exp(y_pred[..., 2:4]) * (np.reshape(anchors_wrt_target, [1,1,1,3,2])/480.)\n",
    "    pred_box_wh = K.cast(pred_box_wdht, dtype = 'float32')\n",
    "    true_box_wdht = y_true[..., 2:4]\n",
    "    true_box_wh = K.cast(true_box_wdht, dtype = 'float32')\n",
    "    \n",
    "    wh_arr = K.cast((K.sqrt(true_box_wh) - K.sqrt(pred_box_wh)), dtype='float32')\n",
    "    \n",
    "    wh_loss = K.cast(Lambda_Coord * tf.reduce_sum(tf.square(wh_arr) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ \n",
    "\n",
    "    pred_obj_mask = K.cast(K.sigmoid(y_pred[..., 4:5]), dtype = 'float32')  # shape = 28, 15, 15, 3, 1\n",
    "       \n",
    "    true_box_wrt_ti = K.concatenate([true_box_xy_wrt_ti, true_box_wh], axis = -1)  ## in x,y,w,h format\n",
    "    pred_box_wrt_ti = K.concatenate([pred_box_xy_wrt_ti, pred_box_wh], axis = -1)  ## in x,y,w,h format\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    true_box_wrt_ti = xywh_to_x1y1x2y2(true_box_wrt_ti)  ## converted to x1,y1,x2,y2 format\n",
    "    pred_box_wrt_ti = xywh_to_x1y1x2y2(pred_box_wrt_ti)  ## converted to x1,y1,x2,y2 format\n",
    "    \n",
    "    ignore_mask = calc_ignore_mask(ignore_thresh, true_box_wrt_ti, pred_box_wrt_ti)\n",
    "    \n",
    "    ignore_mask = K.cast(ignore_mask, dtype = 'float32')                               \n",
    "\n",
    "    obj_loss = K.cast(K.sum(K.binary_crossentropy(obj_mask, pred_obj_mask) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "    no_obj_mask = 1. - obj_mask_y\n",
    "    no_obj_mask = K.cast(no_obj_mask, dtype  = 'float32')\n",
    "    \n",
    "    noobj_loss = K.cast(Lambda_no_obj * K.sum(binary_cross_entropy(obj_mask, pred_obj_mask) * no_obj_mask * ignore_mask), dtype='float32')\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    true_classes = K.cast(y_true[..., 5:10], dtype = 'float32')\n",
    "    \n",
    "    pred_classes = K.cast(y_pred[..., 5:10], dtype = 'float32')\n",
    "    \n",
    "    class_loss = K.cast(K.sum(binary_cross_entropy(true_classes, pred_classes) * obj_mask), dtype = 'float32')\n",
    "\n",
    "    loss = xy_loss + wh_loss + obj_loss + noobj_loss + class_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 480, 480, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1056 (Conv2D)            (None, 239, 239, 32) 864         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1051 (Batch (None, 239, 239, 32) 96          conv2d_1056[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1016 (Activation)    (None, 239, 239, 32) 0           batch_normalization_1051[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1057 (Conv2D)            (None, 237, 237, 32) 9216        activation_1016[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1052 (Batch (None, 237, 237, 32) 96          conv2d_1057[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1017 (Activation)    (None, 237, 237, 32) 0           batch_normalization_1052[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1058 (Conv2D)            (None, 237, 237, 64) 18432       activation_1017[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1053 (Batch (None, 237, 237, 64) 192         conv2d_1058[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1018 (Activation)    (None, 237, 237, 64) 0           batch_normalization_1053[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 118, 118, 64) 0           activation_1018[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1059 (Conv2D)            (None, 118, 118, 80) 5120        max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1054 (Batch (None, 118, 118, 80) 240         conv2d_1059[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1019 (Activation)    (None, 118, 118, 80) 0           batch_normalization_1054[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1060 (Conv2D)            (None, 116, 116, 192 138240      activation_1019[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1055 (Batch (None, 116, 116, 192 576         conv2d_1060[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1020 (Activation)    (None, 116, 116, 192 0           batch_normalization_1055[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 57, 57, 192)  0           activation_1020[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1064 (Conv2D)            (None, 57, 57, 64)   12288       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1059 (Batch (None, 57, 57, 64)   192         conv2d_1064[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1024 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1059[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1062 (Conv2D)            (None, 57, 57, 48)   9216        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1065 (Conv2D)            (None, 57, 57, 96)   55296       activation_1024[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1057 (Batch (None, 57, 57, 48)   144         conv2d_1062[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1060 (Batch (None, 57, 57, 96)   288         conv2d_1065[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1022 (Activation)    (None, 57, 57, 48)   0           batch_normalization_1057[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1025 (Activation)    (None, 57, 57, 96)   0           batch_normalization_1060[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 57, 57, 192)  0           max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1061 (Conv2D)            (None, 57, 57, 96)   18432       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1063 (Conv2D)            (None, 57, 57, 64)   76800       activation_1022[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1066 (Conv2D)            (None, 57, 57, 96)   82944       activation_1025[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1067 (Conv2D)            (None, 57, 57, 64)   12288       average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1056 (Batch (None, 57, 57, 96)   288         conv2d_1061[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1058 (Batch (None, 57, 57, 64)   192         conv2d_1063[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1061 (Batch (None, 57, 57, 96)   288         conv2d_1066[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1062 (Batch (None, 57, 57, 64)   192         conv2d_1067[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1021 (Activation)    (None, 57, 57, 96)   0           batch_normalization_1056[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1023 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1058[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1026 (Activation)    (None, 57, 57, 96)   0           batch_normalization_1061[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1027 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1062[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 57, 57, 320)  0           activation_1021[0][0]            \n",
      "                                                                 activation_1023[0][0]            \n",
      "                                                                 activation_1026[0][0]            \n",
      "                                                                 activation_1027[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1071 (Conv2D)            (None, 57, 57, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1066 (Batch (None, 57, 57, 32)   96          conv2d_1071[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1031 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1066[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1069 (Conv2D)            (None, 57, 57, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1072 (Conv2D)            (None, 57, 57, 48)   13824       activation_1031[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1064 (Batch (None, 57, 57, 32)   96          conv2d_1069[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1067 (Batch (None, 57, 57, 48)   144         conv2d_1072[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1029 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1064[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1032 (Activation)    (None, 57, 57, 48)   0           batch_normalization_1067[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1068 (Conv2D)            (None, 57, 57, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1070 (Conv2D)            (None, 57, 57, 32)   9216        activation_1029[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1073 (Conv2D)            (None, 57, 57, 64)   27648       activation_1032[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1063 (Batch (None, 57, 57, 32)   96          conv2d_1068[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1065 (Batch (None, 57, 57, 32)   96          conv2d_1070[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1068 (Batch (None, 57, 57, 64)   192         conv2d_1073[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1028 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1063[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1030 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1065[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1033 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1068[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_1028[0][0]            \n",
      "                                                                 activation_1030[0][0]            \n",
      "                                                                 activation_1033[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 57, 57, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 57, 57, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1077 (Conv2D)            (None, 57, 57, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1072 (Batch (None, 57, 57, 32)   96          conv2d_1077[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1037 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1072[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1075 (Conv2D)            (None, 57, 57, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1078 (Conv2D)            (None, 57, 57, 48)   13824       activation_1037[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1070 (Batch (None, 57, 57, 32)   96          conv2d_1075[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1073 (Batch (None, 57, 57, 48)   144         conv2d_1078[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1035 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1070[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1038 (Activation)    (None, 57, 57, 48)   0           batch_normalization_1073[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1074 (Conv2D)            (None, 57, 57, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1076 (Conv2D)            (None, 57, 57, 32)   9216        activation_1035[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1079 (Conv2D)            (None, 57, 57, 64)   27648       activation_1038[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1069 (Batch (None, 57, 57, 32)   96          conv2d_1074[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1071 (Batch (None, 57, 57, 32)   96          conv2d_1076[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1074 (Batch (None, 57, 57, 64)   192         conv2d_1079[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1034 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1069[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1036 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1071[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1039 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1074[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_1034[0][0]            \n",
      "                                                                 activation_1036[0][0]            \n",
      "                                                                 activation_1039[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 57, 57, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 57, 57, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1083 (Conv2D)            (None, 57, 57, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1078 (Batch (None, 57, 57, 32)   96          conv2d_1083[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1043 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1078[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1081 (Conv2D)            (None, 57, 57, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1084 (Conv2D)            (None, 57, 57, 48)   13824       activation_1043[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1076 (Batch (None, 57, 57, 32)   96          conv2d_1081[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1079 (Batch (None, 57, 57, 48)   144         conv2d_1084[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1041 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1076[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1044 (Activation)    (None, 57, 57, 48)   0           batch_normalization_1079[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1080 (Conv2D)            (None, 57, 57, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1082 (Conv2D)            (None, 57, 57, 32)   9216        activation_1041[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1085 (Conv2D)            (None, 57, 57, 64)   27648       activation_1044[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1075 (Batch (None, 57, 57, 32)   96          conv2d_1080[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1077 (Batch (None, 57, 57, 32)   96          conv2d_1082[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1080 (Batch (None, 57, 57, 64)   192         conv2d_1085[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1040 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1075[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1042 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1077[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1045 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1080[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_1040[0][0]            \n",
      "                                                                 activation_1042[0][0]            \n",
      "                                                                 activation_1045[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 57, 57, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 57, 57, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1089 (Conv2D)            (None, 57, 57, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1084 (Batch (None, 57, 57, 32)   96          conv2d_1089[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1049 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1084[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1087 (Conv2D)            (None, 57, 57, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1090 (Conv2D)            (None, 57, 57, 48)   13824       activation_1049[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1082 (Batch (None, 57, 57, 32)   96          conv2d_1087[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1085 (Batch (None, 57, 57, 48)   144         conv2d_1090[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1047 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1082[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1050 (Activation)    (None, 57, 57, 48)   0           batch_normalization_1085[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1086 (Conv2D)            (None, 57, 57, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1088 (Conv2D)            (None, 57, 57, 32)   9216        activation_1047[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1091 (Conv2D)            (None, 57, 57, 64)   27648       activation_1050[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1081 (Batch (None, 57, 57, 32)   96          conv2d_1086[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1083 (Batch (None, 57, 57, 32)   96          conv2d_1088[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1086 (Batch (None, 57, 57, 64)   192         conv2d_1091[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1046 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1081[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1048 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1083[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1051 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1086[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_1046[0][0]            \n",
      "                                                                 activation_1048[0][0]            \n",
      "                                                                 activation_1051[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 57, 57, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 57, 57, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1095 (Conv2D)            (None, 57, 57, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1090 (Batch (None, 57, 57, 32)   96          conv2d_1095[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1055 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1090[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1093 (Conv2D)            (None, 57, 57, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1096 (Conv2D)            (None, 57, 57, 48)   13824       activation_1055[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1088 (Batch (None, 57, 57, 32)   96          conv2d_1093[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1091 (Batch (None, 57, 57, 48)   144         conv2d_1096[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1053 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1088[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1056 (Activation)    (None, 57, 57, 48)   0           batch_normalization_1091[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1092 (Conv2D)            (None, 57, 57, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1094 (Conv2D)            (None, 57, 57, 32)   9216        activation_1053[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1097 (Conv2D)            (None, 57, 57, 64)   27648       activation_1056[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1087 (Batch (None, 57, 57, 32)   96          conv2d_1092[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1089 (Batch (None, 57, 57, 32)   96          conv2d_1094[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1092 (Batch (None, 57, 57, 64)   192         conv2d_1097[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1052 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1087[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1054 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1089[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1057 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1092[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_1052[0][0]            \n",
      "                                                                 activation_1054[0][0]            \n",
      "                                                                 activation_1057[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 57, 57, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 57, 57, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1101 (Conv2D)            (None, 57, 57, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1096 (Batch (None, 57, 57, 32)   96          conv2d_1101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1061 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1096[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1099 (Conv2D)            (None, 57, 57, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1102 (Conv2D)            (None, 57, 57, 48)   13824       activation_1061[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1094 (Batch (None, 57, 57, 32)   96          conv2d_1099[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1097 (Batch (None, 57, 57, 48)   144         conv2d_1102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1059 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1094[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1062 (Activation)    (None, 57, 57, 48)   0           batch_normalization_1097[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1098 (Conv2D)            (None, 57, 57, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1100 (Conv2D)            (None, 57, 57, 32)   9216        activation_1059[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1103 (Conv2D)            (None, 57, 57, 64)   27648       activation_1062[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1093 (Batch (None, 57, 57, 32)   96          conv2d_1098[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1095 (Batch (None, 57, 57, 32)   96          conv2d_1100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1098 (Batch (None, 57, 57, 64)   192         conv2d_1103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1058 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1093[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1060 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1095[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1063 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1098[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_1058[0][0]            \n",
      "                                                                 activation_1060[0][0]            \n",
      "                                                                 activation_1063[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 57, 57, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 57, 57, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1107 (Conv2D)            (None, 57, 57, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1102 (Batch (None, 57, 57, 32)   96          conv2d_1107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1067 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1102[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1105 (Conv2D)            (None, 57, 57, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1108 (Conv2D)            (None, 57, 57, 48)   13824       activation_1067[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1100 (Batch (None, 57, 57, 32)   96          conv2d_1105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1103 (Batch (None, 57, 57, 48)   144         conv2d_1108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1065 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1100[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1068 (Activation)    (None, 57, 57, 48)   0           batch_normalization_1103[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1104 (Conv2D)            (None, 57, 57, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1106 (Conv2D)            (None, 57, 57, 32)   9216        activation_1065[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1109 (Conv2D)            (None, 57, 57, 64)   27648       activation_1068[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1099 (Batch (None, 57, 57, 32)   96          conv2d_1104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1101 (Batch (None, 57, 57, 32)   96          conv2d_1106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1104 (Batch (None, 57, 57, 64)   192         conv2d_1109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1064 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1099[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1066 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1101[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1069 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1104[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_1064[0][0]            \n",
      "                                                                 activation_1066[0][0]            \n",
      "                                                                 activation_1069[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 57, 57, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 57, 57, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1113 (Conv2D)            (None, 57, 57, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1108 (Batch (None, 57, 57, 32)   96          conv2d_1113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1073 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1108[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1111 (Conv2D)            (None, 57, 57, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1114 (Conv2D)            (None, 57, 57, 48)   13824       activation_1073[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1106 (Batch (None, 57, 57, 32)   96          conv2d_1111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1109 (Batch (None, 57, 57, 48)   144         conv2d_1114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1071 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1106[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1074 (Activation)    (None, 57, 57, 48)   0           batch_normalization_1109[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1110 (Conv2D)            (None, 57, 57, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1112 (Conv2D)            (None, 57, 57, 32)   9216        activation_1071[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1115 (Conv2D)            (None, 57, 57, 64)   27648       activation_1074[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1105 (Batch (None, 57, 57, 32)   96          conv2d_1110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1107 (Batch (None, 57, 57, 32)   96          conv2d_1112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1110 (Batch (None, 57, 57, 64)   192         conv2d_1115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1070 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1105[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1072 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1107[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1075 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1110[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_1070[0][0]            \n",
      "                                                                 activation_1072[0][0]            \n",
      "                                                                 activation_1075[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 57, 57, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 57, 57, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1119 (Conv2D)            (None, 57, 57, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1114 (Batch (None, 57, 57, 32)   96          conv2d_1119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1079 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1114[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1117 (Conv2D)            (None, 57, 57, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1120 (Conv2D)            (None, 57, 57, 48)   13824       activation_1079[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1112 (Batch (None, 57, 57, 32)   96          conv2d_1117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1115 (Batch (None, 57, 57, 48)   144         conv2d_1120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1077 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1112[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1080 (Activation)    (None, 57, 57, 48)   0           batch_normalization_1115[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1116 (Conv2D)            (None, 57, 57, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1118 (Conv2D)            (None, 57, 57, 32)   9216        activation_1077[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1121 (Conv2D)            (None, 57, 57, 64)   27648       activation_1080[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1111 (Batch (None, 57, 57, 32)   96          conv2d_1116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1113 (Batch (None, 57, 57, 32)   96          conv2d_1118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1116 (Batch (None, 57, 57, 64)   192         conv2d_1121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1076 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1111[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1078 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1113[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1081 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1116[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_1076[0][0]            \n",
      "                                                                 activation_1078[0][0]            \n",
      "                                                                 activation_1081[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 57, 57, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 57, 57, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1125 (Conv2D)            (None, 57, 57, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1120 (Batch (None, 57, 57, 32)   96          conv2d_1125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1085 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1120[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1123 (Conv2D)            (None, 57, 57, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1126 (Conv2D)            (None, 57, 57, 48)   13824       activation_1085[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1118 (Batch (None, 57, 57, 32)   96          conv2d_1123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1121 (Batch (None, 57, 57, 48)   144         conv2d_1126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1083 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1118[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1086 (Activation)    (None, 57, 57, 48)   0           batch_normalization_1121[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1122 (Conv2D)            (None, 57, 57, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1124 (Conv2D)            (None, 57, 57, 32)   9216        activation_1083[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1127 (Conv2D)            (None, 57, 57, 64)   27648       activation_1086[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1117 (Batch (None, 57, 57, 32)   96          conv2d_1122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1119 (Batch (None, 57, 57, 32)   96          conv2d_1124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1122 (Batch (None, 57, 57, 64)   192         conv2d_1127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1082 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1117[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1084 (Activation)    (None, 57, 57, 32)   0           batch_normalization_1119[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1087 (Activation)    (None, 57, 57, 64)   0           batch_normalization_1122[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 57, 57, 128)  0           activation_1082[0][0]            \n",
      "                                                                 activation_1084[0][0]            \n",
      "                                                                 activation_1087[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 57, 57, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 57, 57, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 57, 57, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1129 (Conv2D)            (None, 57, 57, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1124 (Batch (None, 57, 57, 256)  768         conv2d_1129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1089 (Activation)    (None, 57, 57, 256)  0           batch_normalization_1124[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1130 (Conv2D)            (None, 57, 57, 256)  589824      activation_1089[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1125 (Batch (None, 57, 57, 256)  768         conv2d_1130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1090 (Activation)    (None, 57, 57, 256)  0           batch_normalization_1125[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1128 (Conv2D)            (None, 28, 28, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1131 (Conv2D)            (None, 28, 28, 384)  884736      activation_1090[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1123 (Batch (None, 28, 28, 384)  1152        conv2d_1128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1126 (Batch (None, 28, 28, 384)  1152        conv2d_1131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1088 (Activation)    (None, 28, 28, 384)  0           batch_normalization_1123[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1091 (Activation)    (None, 28, 28, 384)  0           batch_normalization_1126[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 28, 28, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 28, 28, 1088) 0           activation_1088[0][0]            \n",
      "                                                                 activation_1091[0][0]            \n",
      "                                                                 max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1133 (Conv2D)            (None, 28, 28, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1128 (Batch (None, 28, 28, 128)  384         conv2d_1133[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1093 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1128[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1134 (Conv2D)            (None, 28, 28, 160)  143360      activation_1093[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1129 (Batch (None, 28, 28, 160)  480         conv2d_1134[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1094 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1129[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1132 (Conv2D)            (None, 28, 28, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1135 (Conv2D)            (None, 28, 28, 192)  215040      activation_1094[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1127 (Batch (None, 28, 28, 192)  576         conv2d_1132[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1130 (Batch (None, 28, 28, 192)  576         conv2d_1135[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1092 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1127[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1095 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1130[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_1092[0][0]            \n",
      "                                                                 activation_1095[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 28, 28, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 28, 28, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1137 (Conv2D)            (None, 28, 28, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1132 (Batch (None, 28, 28, 128)  384         conv2d_1137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1097 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1132[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1138 (Conv2D)            (None, 28, 28, 160)  143360      activation_1097[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1133 (Batch (None, 28, 28, 160)  480         conv2d_1138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1098 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1133[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1136 (Conv2D)            (None, 28, 28, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1139 (Conv2D)            (None, 28, 28, 192)  215040      activation_1098[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1131 (Batch (None, 28, 28, 192)  576         conv2d_1136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1134 (Batch (None, 28, 28, 192)  576         conv2d_1139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1096 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1131[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1099 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1134[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_1096[0][0]            \n",
      "                                                                 activation_1099[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 28, 28, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 28, 28, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1141 (Conv2D)            (None, 28, 28, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1136 (Batch (None, 28, 28, 128)  384         conv2d_1141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1101 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1136[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1142 (Conv2D)            (None, 28, 28, 160)  143360      activation_1101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1137 (Batch (None, 28, 28, 160)  480         conv2d_1142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1102 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1137[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1140 (Conv2D)            (None, 28, 28, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1143 (Conv2D)            (None, 28, 28, 192)  215040      activation_1102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1135 (Batch (None, 28, 28, 192)  576         conv2d_1140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1138 (Batch (None, 28, 28, 192)  576         conv2d_1143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1100 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1135[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1103 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1138[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_1100[0][0]            \n",
      "                                                                 activation_1103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 28, 28, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 28, 28, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1145 (Conv2D)            (None, 28, 28, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1140 (Batch (None, 28, 28, 128)  384         conv2d_1145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1105 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1140[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1146 (Conv2D)            (None, 28, 28, 160)  143360      activation_1105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1141 (Batch (None, 28, 28, 160)  480         conv2d_1146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1106 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1141[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1144 (Conv2D)            (None, 28, 28, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1147 (Conv2D)            (None, 28, 28, 192)  215040      activation_1106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1139 (Batch (None, 28, 28, 192)  576         conv2d_1144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1142 (Batch (None, 28, 28, 192)  576         conv2d_1147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1104 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1139[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1107 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1142[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_1104[0][0]            \n",
      "                                                                 activation_1107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 28, 28, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 28, 28, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1149 (Conv2D)            (None, 28, 28, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1144 (Batch (None, 28, 28, 128)  384         conv2d_1149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1109 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1144[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1150 (Conv2D)            (None, 28, 28, 160)  143360      activation_1109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1145 (Batch (None, 28, 28, 160)  480         conv2d_1150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1110 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1145[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1148 (Conv2D)            (None, 28, 28, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1151 (Conv2D)            (None, 28, 28, 192)  215040      activation_1110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1143 (Batch (None, 28, 28, 192)  576         conv2d_1148[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1146 (Batch (None, 28, 28, 192)  576         conv2d_1151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1108 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1143[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1111 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1146[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_1108[0][0]            \n",
      "                                                                 activation_1111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 28, 28, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 28, 28, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1153 (Conv2D)            (None, 28, 28, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1148 (Batch (None, 28, 28, 128)  384         conv2d_1153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1113 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1148[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1154 (Conv2D)            (None, 28, 28, 160)  143360      activation_1113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1149 (Batch (None, 28, 28, 160)  480         conv2d_1154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1114 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1149[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1152 (Conv2D)            (None, 28, 28, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1155 (Conv2D)            (None, 28, 28, 192)  215040      activation_1114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1147 (Batch (None, 28, 28, 192)  576         conv2d_1152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1150 (Batch (None, 28, 28, 192)  576         conv2d_1155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1112 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1147[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1115 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1150[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_1112[0][0]            \n",
      "                                                                 activation_1115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 28, 28, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 28, 28, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1157 (Conv2D)            (None, 28, 28, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1152 (Batch (None, 28, 28, 128)  384         conv2d_1157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1117 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1152[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1158 (Conv2D)            (None, 28, 28, 160)  143360      activation_1117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1153 (Batch (None, 28, 28, 160)  480         conv2d_1158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1118 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1153[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1156 (Conv2D)            (None, 28, 28, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1159 (Conv2D)            (None, 28, 28, 192)  215040      activation_1118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1151 (Batch (None, 28, 28, 192)  576         conv2d_1156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1154 (Batch (None, 28, 28, 192)  576         conv2d_1159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1116 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1151[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1119 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1154[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_1116[0][0]            \n",
      "                                                                 activation_1119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 28, 28, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 28, 28, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1161 (Conv2D)            (None, 28, 28, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1156 (Batch (None, 28, 28, 128)  384         conv2d_1161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1121 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1156[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1162 (Conv2D)            (None, 28, 28, 160)  143360      activation_1121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1157 (Batch (None, 28, 28, 160)  480         conv2d_1162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1122 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1157[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1160 (Conv2D)            (None, 28, 28, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1163 (Conv2D)            (None, 28, 28, 192)  215040      activation_1122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1155 (Batch (None, 28, 28, 192)  576         conv2d_1160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1158 (Batch (None, 28, 28, 192)  576         conv2d_1163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1120 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1155[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1123 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1158[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_1120[0][0]            \n",
      "                                                                 activation_1123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 28, 28, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 28, 28, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1165 (Conv2D)            (None, 28, 28, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1160 (Batch (None, 28, 28, 128)  384         conv2d_1165[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1125 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1160[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1166 (Conv2D)            (None, 28, 28, 160)  143360      activation_1125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1161 (Batch (None, 28, 28, 160)  480         conv2d_1166[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1126 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1161[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1164 (Conv2D)            (None, 28, 28, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1167 (Conv2D)            (None, 28, 28, 192)  215040      activation_1126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1159 (Batch (None, 28, 28, 192)  576         conv2d_1164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1162 (Batch (None, 28, 28, 192)  576         conv2d_1167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1124 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1159[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1127 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1162[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_1124[0][0]            \n",
      "                                                                 activation_1127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 28, 28, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 28, 28, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1169 (Conv2D)            (None, 28, 28, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1164 (Batch (None, 28, 28, 128)  384         conv2d_1169[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1129 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1164[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1170 (Conv2D)            (None, 28, 28, 160)  143360      activation_1129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1165 (Batch (None, 28, 28, 160)  480         conv2d_1170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1130 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1165[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1168 (Conv2D)            (None, 28, 28, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1171 (Conv2D)            (None, 28, 28, 192)  215040      activation_1130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1163 (Batch (None, 28, 28, 192)  576         conv2d_1168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1166 (Batch (None, 28, 28, 192)  576         conv2d_1171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1128 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1163[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1131 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1166[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_1128[0][0]            \n",
      "                                                                 activation_1131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 28, 28, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 28, 28, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1173 (Conv2D)            (None, 28, 28, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1168 (Batch (None, 28, 28, 128)  384         conv2d_1173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1133 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1168[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1174 (Conv2D)            (None, 28, 28, 160)  143360      activation_1133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1169 (Batch (None, 28, 28, 160)  480         conv2d_1174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1134 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1169[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1172 (Conv2D)            (None, 28, 28, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1175 (Conv2D)            (None, 28, 28, 192)  215040      activation_1134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1167 (Batch (None, 28, 28, 192)  576         conv2d_1172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1170 (Batch (None, 28, 28, 192)  576         conv2d_1175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1132 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1167[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1135 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1170[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_1132[0][0]            \n",
      "                                                                 activation_1135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 28, 28, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 28, 28, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1177 (Conv2D)            (None, 28, 28, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1172 (Batch (None, 28, 28, 128)  384         conv2d_1177[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1137 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1172[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1178 (Conv2D)            (None, 28, 28, 160)  143360      activation_1137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1173 (Batch (None, 28, 28, 160)  480         conv2d_1178[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1138 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1173[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1176 (Conv2D)            (None, 28, 28, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1179 (Conv2D)            (None, 28, 28, 192)  215040      activation_1138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1171 (Batch (None, 28, 28, 192)  576         conv2d_1176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1174 (Batch (None, 28, 28, 192)  576         conv2d_1179[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1136 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1171[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1139 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1174[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_1136[0][0]            \n",
      "                                                                 activation_1139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 28, 28, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 28, 28, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1181 (Conv2D)            (None, 28, 28, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1176 (Batch (None, 28, 28, 128)  384         conv2d_1181[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1141 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1176[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1182 (Conv2D)            (None, 28, 28, 160)  143360      activation_1141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1177 (Batch (None, 28, 28, 160)  480         conv2d_1182[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1142 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1177[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1180 (Conv2D)            (None, 28, 28, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1183 (Conv2D)            (None, 28, 28, 192)  215040      activation_1142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1175 (Batch (None, 28, 28, 192)  576         conv2d_1180[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1178 (Batch (None, 28, 28, 192)  576         conv2d_1183[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1140 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1175[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1143 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1178[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_1140[0][0]            \n",
      "                                                                 activation_1143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 28, 28, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 28, 28, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1185 (Conv2D)            (None, 28, 28, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1180 (Batch (None, 28, 28, 128)  384         conv2d_1185[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1145 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1180[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1186 (Conv2D)            (None, 28, 28, 160)  143360      activation_1145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1181 (Batch (None, 28, 28, 160)  480         conv2d_1186[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1146 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1181[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1184 (Conv2D)            (None, 28, 28, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1187 (Conv2D)            (None, 28, 28, 192)  215040      activation_1146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1179 (Batch (None, 28, 28, 192)  576         conv2d_1184[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1182 (Batch (None, 28, 28, 192)  576         conv2d_1187[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1144 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1179[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1147 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1182[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_1144[0][0]            \n",
      "                                                                 activation_1147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 28, 28, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 28, 28, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1189 (Conv2D)            (None, 28, 28, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1184 (Batch (None, 28, 28, 128)  384         conv2d_1189[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1149 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1184[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1190 (Conv2D)            (None, 28, 28, 160)  143360      activation_1149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1185 (Batch (None, 28, 28, 160)  480         conv2d_1190[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1150 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1185[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1188 (Conv2D)            (None, 28, 28, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1191 (Conv2D)            (None, 28, 28, 192)  215040      activation_1150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1183 (Batch (None, 28, 28, 192)  576         conv2d_1188[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1186 (Batch (None, 28, 28, 192)  576         conv2d_1191[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1148 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1183[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1151 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1186[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_1148[0][0]            \n",
      "                                                                 activation_1151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 28, 28, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 28, 28, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1193 (Conv2D)            (None, 28, 28, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1188 (Batch (None, 28, 28, 128)  384         conv2d_1193[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1153 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1188[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1194 (Conv2D)            (None, 28, 28, 160)  143360      activation_1153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1189 (Batch (None, 28, 28, 160)  480         conv2d_1194[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1154 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1189[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1192 (Conv2D)            (None, 28, 28, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1195 (Conv2D)            (None, 28, 28, 192)  215040      activation_1154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1187 (Batch (None, 28, 28, 192)  576         conv2d_1192[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1190 (Batch (None, 28, 28, 192)  576         conv2d_1195[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1152 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1187[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1155 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1190[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_1152[0][0]            \n",
      "                                                                 activation_1155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 28, 28, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 28, 28, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1197 (Conv2D)            (None, 28, 28, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1192 (Batch (None, 28, 28, 128)  384         conv2d_1197[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1157 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1192[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1198 (Conv2D)            (None, 28, 28, 160)  143360      activation_1157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1193 (Batch (None, 28, 28, 160)  480         conv2d_1198[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1158 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1193[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1196 (Conv2D)            (None, 28, 28, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1199 (Conv2D)            (None, 28, 28, 192)  215040      activation_1158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1191 (Batch (None, 28, 28, 192)  576         conv2d_1196[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1194 (Batch (None, 28, 28, 192)  576         conv2d_1199[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1156 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1191[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1159 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1194[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_1156[0][0]            \n",
      "                                                                 activation_1159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 28, 28, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 28, 28, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1201 (Conv2D)            (None, 28, 28, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1196 (Batch (None, 28, 28, 128)  384         conv2d_1201[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1161 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1196[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1202 (Conv2D)            (None, 28, 28, 160)  143360      activation_1161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1197 (Batch (None, 28, 28, 160)  480         conv2d_1202[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1162 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1197[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1200 (Conv2D)            (None, 28, 28, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1203 (Conv2D)            (None, 28, 28, 192)  215040      activation_1162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1195 (Batch (None, 28, 28, 192)  576         conv2d_1200[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1198 (Batch (None, 28, 28, 192)  576         conv2d_1203[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1160 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1195[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1163 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1198[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_1160[0][0]            \n",
      "                                                                 activation_1163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 28, 28, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 28, 28, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1205 (Conv2D)            (None, 28, 28, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1200 (Batch (None, 28, 28, 128)  384         conv2d_1205[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1165 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1200[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1206 (Conv2D)            (None, 28, 28, 160)  143360      activation_1165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1201 (Batch (None, 28, 28, 160)  480         conv2d_1206[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1166 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1201[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1204 (Conv2D)            (None, 28, 28, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1207 (Conv2D)            (None, 28, 28, 192)  215040      activation_1166[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1199 (Batch (None, 28, 28, 192)  576         conv2d_1204[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1202 (Batch (None, 28, 28, 192)  576         conv2d_1207[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1164 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1199[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1167 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1202[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_1164[0][0]            \n",
      "                                                                 activation_1167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 28, 28, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 28, 28, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1209 (Conv2D)            (None, 28, 28, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1204 (Batch (None, 28, 28, 128)  384         conv2d_1209[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1169 (Activation)    (None, 28, 28, 128)  0           batch_normalization_1204[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1210 (Conv2D)            (None, 28, 28, 160)  143360      activation_1169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1205 (Batch (None, 28, 28, 160)  480         conv2d_1210[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1170 (Activation)    (None, 28, 28, 160)  0           batch_normalization_1205[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1208 (Conv2D)            (None, 28, 28, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1211 (Conv2D)            (None, 28, 28, 192)  215040      activation_1170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1203 (Batch (None, 28, 28, 192)  576         conv2d_1208[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1206 (Batch (None, 28, 28, 192)  576         conv2d_1211[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1168 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1203[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1171 (Activation)    (None, 28, 28, 192)  0           batch_normalization_1206[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_1168[0][0]            \n",
      "                                                                 activation_1171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 28, 28, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 28, 28, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1216 (Conv2D)            (None, 28, 28, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1211 (Batch (None, 28, 28, 256)  768         conv2d_1216[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1176 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1211[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1212 (Conv2D)            (None, 28, 28, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1214 (Conv2D)            (None, 28, 28, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1217 (Conv2D)            (None, 28, 28, 288)  663552      activation_1176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1207 (Batch (None, 28, 28, 256)  768         conv2d_1212[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1209 (Batch (None, 28, 28, 256)  768         conv2d_1214[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1212 (Batch (None, 28, 28, 288)  864         conv2d_1217[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1172 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1207[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1174 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1209[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1177 (Activation)    (None, 28, 28, 288)  0           batch_normalization_1212[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1213 (Conv2D)            (None, 13, 13, 384)  884736      activation_1172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1215 (Conv2D)            (None, 13, 13, 288)  663552      activation_1174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1218 (Conv2D)            (None, 13, 13, 320)  829440      activation_1177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1208 (Batch (None, 13, 13, 384)  1152        conv2d_1213[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1210 (Batch (None, 13, 13, 288)  864         conv2d_1215[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1213 (Batch (None, 13, 13, 320)  960         conv2d_1218[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1173 (Activation)    (None, 13, 13, 384)  0           batch_normalization_1208[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1175 (Activation)    (None, 13, 13, 288)  0           batch_normalization_1210[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1178 (Activation)    (None, 13, 13, 320)  0           batch_normalization_1213[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 13, 13, 1088) 0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 13, 13, 2080) 0           activation_1173[0][0]            \n",
      "                                                                 activation_1175[0][0]            \n",
      "                                                                 activation_1178[0][0]            \n",
      "                                                                 max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1220 (Conv2D)            (None, 13, 13, 192)  399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1215 (Batch (None, 13, 13, 192)  576         conv2d_1220[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1180 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1215[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1221 (Conv2D)            (None, 13, 13, 224)  129024      activation_1180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1216 (Batch (None, 13, 13, 224)  672         conv2d_1221[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1181 (Activation)    (None, 13, 13, 224)  0           batch_normalization_1216[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1219 (Conv2D)            (None, 13, 13, 192)  399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1222 (Conv2D)            (None, 13, 13, 256)  172032      activation_1181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1214 (Batch (None, 13, 13, 192)  576         conv2d_1219[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1217 (Batch (None, 13, 13, 256)  768         conv2d_1222[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1179 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1214[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1182 (Activation)    (None, 13, 13, 256)  0           batch_normalization_1217[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_1179[0][0]            \n",
      "                                                                 activation_1182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 13, 13, 2080) 0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 13, 13, 2080) 0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1224 (Conv2D)            (None, 13, 13, 192)  399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1219 (Batch (None, 13, 13, 192)  576         conv2d_1224[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1184 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1219[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1225 (Conv2D)            (None, 13, 13, 224)  129024      activation_1184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1220 (Batch (None, 13, 13, 224)  672         conv2d_1225[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1185 (Activation)    (None, 13, 13, 224)  0           batch_normalization_1220[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1223 (Conv2D)            (None, 13, 13, 192)  399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1226 (Conv2D)            (None, 13, 13, 256)  172032      activation_1185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1218 (Batch (None, 13, 13, 192)  576         conv2d_1223[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1221 (Batch (None, 13, 13, 256)  768         conv2d_1226[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1183 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1218[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1186 (Activation)    (None, 13, 13, 256)  0           batch_normalization_1221[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_1183[0][0]            \n",
      "                                                                 activation_1186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 13, 13, 2080) 0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 13, 13, 2080) 0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1228 (Conv2D)            (None, 13, 13, 192)  399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1223 (Batch (None, 13, 13, 192)  576         conv2d_1228[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1188 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1223[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1229 (Conv2D)            (None, 13, 13, 224)  129024      activation_1188[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1224 (Batch (None, 13, 13, 224)  672         conv2d_1229[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1189 (Activation)    (None, 13, 13, 224)  0           batch_normalization_1224[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1227 (Conv2D)            (None, 13, 13, 192)  399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1230 (Conv2D)            (None, 13, 13, 256)  172032      activation_1189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1222 (Batch (None, 13, 13, 192)  576         conv2d_1227[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1225 (Batch (None, 13, 13, 256)  768         conv2d_1230[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1187 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1222[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1190 (Activation)    (None, 13, 13, 256)  0           batch_normalization_1225[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_1187[0][0]            \n",
      "                                                                 activation_1190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 13, 13, 2080) 0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 13, 13, 2080) 0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1232 (Conv2D)            (None, 13, 13, 192)  399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1227 (Batch (None, 13, 13, 192)  576         conv2d_1232[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1192 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1227[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1233 (Conv2D)            (None, 13, 13, 224)  129024      activation_1192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1228 (Batch (None, 13, 13, 224)  672         conv2d_1233[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1193 (Activation)    (None, 13, 13, 224)  0           batch_normalization_1228[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1231 (Conv2D)            (None, 13, 13, 192)  399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1234 (Conv2D)            (None, 13, 13, 256)  172032      activation_1193[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1226 (Batch (None, 13, 13, 192)  576         conv2d_1231[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1229 (Batch (None, 13, 13, 256)  768         conv2d_1234[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1191 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1226[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1194 (Activation)    (None, 13, 13, 256)  0           batch_normalization_1229[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_1191[0][0]            \n",
      "                                                                 activation_1194[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 13, 13, 2080) 0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 13, 13, 2080) 0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1236 (Conv2D)            (None, 13, 13, 192)  399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1231 (Batch (None, 13, 13, 192)  576         conv2d_1236[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1196 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1231[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1237 (Conv2D)            (None, 13, 13, 224)  129024      activation_1196[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1232 (Batch (None, 13, 13, 224)  672         conv2d_1237[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1197 (Activation)    (None, 13, 13, 224)  0           batch_normalization_1232[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1235 (Conv2D)            (None, 13, 13, 192)  399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1238 (Conv2D)            (None, 13, 13, 256)  172032      activation_1197[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1230 (Batch (None, 13, 13, 192)  576         conv2d_1235[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1233 (Batch (None, 13, 13, 256)  768         conv2d_1238[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1195 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1230[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1198 (Activation)    (None, 13, 13, 256)  0           batch_normalization_1233[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_1195[0][0]            \n",
      "                                                                 activation_1198[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 13, 13, 2080) 0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 13, 13, 2080) 0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1240 (Conv2D)            (None, 13, 13, 192)  399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1235 (Batch (None, 13, 13, 192)  576         conv2d_1240[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1200 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1235[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1241 (Conv2D)            (None, 13, 13, 224)  129024      activation_1200[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1236 (Batch (None, 13, 13, 224)  672         conv2d_1241[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1201 (Activation)    (None, 13, 13, 224)  0           batch_normalization_1236[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1239 (Conv2D)            (None, 13, 13, 192)  399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1242 (Conv2D)            (None, 13, 13, 256)  172032      activation_1201[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1234 (Batch (None, 13, 13, 192)  576         conv2d_1239[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1237 (Batch (None, 13, 13, 256)  768         conv2d_1242[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1199 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1234[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1202 (Activation)    (None, 13, 13, 256)  0           batch_normalization_1237[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_1199[0][0]            \n",
      "                                                                 activation_1202[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 13, 13, 2080) 0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 13, 13, 2080) 0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1244 (Conv2D)            (None, 13, 13, 192)  399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1239 (Batch (None, 13, 13, 192)  576         conv2d_1244[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1204 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1239[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1245 (Conv2D)            (None, 13, 13, 224)  129024      activation_1204[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1240 (Batch (None, 13, 13, 224)  672         conv2d_1245[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1205 (Activation)    (None, 13, 13, 224)  0           batch_normalization_1240[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1243 (Conv2D)            (None, 13, 13, 192)  399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1246 (Conv2D)            (None, 13, 13, 256)  172032      activation_1205[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1238 (Batch (None, 13, 13, 192)  576         conv2d_1243[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1241 (Batch (None, 13, 13, 256)  768         conv2d_1246[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1203 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1238[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1206 (Activation)    (None, 13, 13, 256)  0           batch_normalization_1241[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_1203[0][0]            \n",
      "                                                                 activation_1206[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 13, 13, 2080) 0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 13, 13, 2080) 0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1248 (Conv2D)            (None, 13, 13, 192)  399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1243 (Batch (None, 13, 13, 192)  576         conv2d_1248[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1208 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1243[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1249 (Conv2D)            (None, 13, 13, 224)  129024      activation_1208[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1244 (Batch (None, 13, 13, 224)  672         conv2d_1249[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1209 (Activation)    (None, 13, 13, 224)  0           batch_normalization_1244[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1247 (Conv2D)            (None, 13, 13, 192)  399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1250 (Conv2D)            (None, 13, 13, 256)  172032      activation_1209[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1242 (Batch (None, 13, 13, 192)  576         conv2d_1247[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1245 (Batch (None, 13, 13, 256)  768         conv2d_1250[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1207 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1242[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1210 (Activation)    (None, 13, 13, 256)  0           batch_normalization_1245[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_1207[0][0]            \n",
      "                                                                 activation_1210[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 13, 13, 2080) 0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 13, 13, 2080) 0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1252 (Conv2D)            (None, 13, 13, 192)  399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1247 (Batch (None, 13, 13, 192)  576         conv2d_1252[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1212 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1247[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1253 (Conv2D)            (None, 13, 13, 224)  129024      activation_1212[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1248 (Batch (None, 13, 13, 224)  672         conv2d_1253[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1213 (Activation)    (None, 13, 13, 224)  0           batch_normalization_1248[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1251 (Conv2D)            (None, 13, 13, 192)  399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1254 (Conv2D)            (None, 13, 13, 256)  172032      activation_1213[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1246 (Batch (None, 13, 13, 192)  576         conv2d_1251[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1249 (Batch (None, 13, 13, 256)  768         conv2d_1254[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1211 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1246[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1214 (Activation)    (None, 13, 13, 256)  0           batch_normalization_1249[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_1211[0][0]            \n",
      "                                                                 activation_1214[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 13, 13, 2080) 0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 13, 13, 2080) 0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1256 (Conv2D)            (None, 13, 13, 192)  399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1251 (Batch (None, 13, 13, 192)  576         conv2d_1256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1216 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1251[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1257 (Conv2D)            (None, 13, 13, 224)  129024      activation_1216[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1252 (Batch (None, 13, 13, 224)  672         conv2d_1257[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1217 (Activation)    (None, 13, 13, 224)  0           batch_normalization_1252[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1255 (Conv2D)            (None, 13, 13, 192)  399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1258 (Conv2D)            (None, 13, 13, 256)  172032      activation_1217[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1250 (Batch (None, 13, 13, 192)  576         conv2d_1255[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1253 (Batch (None, 13, 13, 256)  768         conv2d_1258[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1215 (Activation)    (None, 13, 13, 192)  0           batch_normalization_1250[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1218 (Activation)    (None, 13, 13, 256)  0           batch_normalization_1253[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 13, 13, 448)  0           activation_1215[0][0]            \n",
      "                                                                 activation_1218[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 13, 13, 2080) 933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 13, 13, 2080) 0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 13, 13, 1536) 3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 13, 13, 1536) 4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 13, 13, 1536) 0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 26, 26, 1536) 0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1259 (Conv2D)            (None, 24, 24, 512)  7078400     up_sampling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 24, 24, 512)  0           conv2d_1259[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1254 (Batch (None, 24, 24, 512)  2048        dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 24, 24, 512)  0           batch_normalization_1254[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1260 (Conv2D)            (None, 22, 22, 256)  1179904     leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 22, 22, 256)  0           conv2d_1260[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1255 (Batch (None, 22, 22, 256)  1024        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 22, 22, 256)  0           batch_normalization_1255[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 44, 44, 256)  0           leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1261 (Conv2D)            (None, 42, 42, 256)  590080      up_sampling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 42, 42, 256)  0           conv2d_1261[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1256 (Batch (None, 42, 42, 256)  1024        dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 42, 42, 256)  0           batch_normalization_1256[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1262 (Conv2D)            (None, 40, 40, 256)  590080      leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 40, 40, 256)  0           conv2d_1262[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1257 (Batch (None, 40, 40, 256)  1024        dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 40, 40, 256)  0           batch_normalization_1257[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1263 (Conv2D)            (None, 19, 19, 128)  295040      leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 19, 19, 128)  0           conv2d_1263[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1258 (Batch (None, 19, 19, 128)  512         dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 19, 19, 128)  0           batch_normalization_1258[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1264 (Conv2D)            (None, 17, 17, 64)   73792       leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 17, 17, 64)   0           conv2d_1264[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1259 (Batch (None, 17, 17, 64)   256         dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 17, 17, 64)   0           batch_normalization_1259[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1265 (Conv2D)            (None, 15, 15, 64)   36928       leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 15, 15, 64)   0           conv2d_1265[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1260 (Batch (None, 15, 15, 64)   256         dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 15, 15, 64)   0           batch_normalization_1260[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1266 (Conv2D)            (None, 15, 15, 30)   1950        leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 15, 15, 3, 10 0           conv2d_1266[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 64,189,054\n",
      "Trainable params: 64,125,438\n",
      "Non-trainable params: 63,616\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def yolo_model(input_shape):\n",
    "    \n",
    "    \n",
    "    inp = Input(input_shape)\n",
    "   \n",
    "    model = InceptionResNetV2( input_tensor= inp , include_top=False, weights='imagenet')\n",
    "    last_layer = model.output\n",
    "    \n",
    "    new_last_layer = UpSampling2D(2)(last_layer)\n",
    "    \n",
    "    conv = Conv2D(512,(3,3) , padding='valid')(new_last_layer)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(256,(3,3) , padding='valid')(lr)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    another_up_layer = UpSampling2D(2)(lr)\n",
    "    \n",
    "    conv = Conv2D(256,(3,3) , padding='valid')(another_up_layer)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(256,(3,3) , padding='valid')(lr)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(128,(3,3) , strides = (2, 2), padding='valid')(lr)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(64,(3,3) , padding='valid')(lr)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(64,(3,3) , padding='valid')(lr)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(30,(1,1) , padding='same')(lr)\n",
    "#    conv = Dropout(0.4)(conv)\n",
    "#    bn = BatchNormalization()(conv)\n",
    "#    lr = LeakyRelu(alpha=0.1)(bn)\n",
    "\n",
    "    final = Reshape((grid_y_axis,grid_x_axis,num_anchors,info))(conv)\n",
    "\n",
    "    model = Model(inp,final)\n",
    "    features = model.output\n",
    "\n",
    "    return model, features\n",
    "\n",
    "input_size = (target_w, target_h, 3)\n",
    "my_yolo_invoice_model, features_1 = yolo_model(input_size)\n",
    "\n",
    "\n",
    "my_model_1, features_2 = yolo_model(input_size)\n",
    "my_model_2, features_3 = yolo_model(input_size)\n",
    "\n",
    "print(my_model_1.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "#opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "my_yolo_invoice_model.compile(optimizer= opt,loss=yolo_my_loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/5\n",
      "28/28 [==============================] - 217s 8s/step - loss: -19092.4835 - accuracy: 0.1885 - val_loss: nan - val_accuracy: 0.9926\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 125s 4s/step - loss: nan - accuracy: 0.7013 - val_loss: nan - val_accuracy: 0.9926\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 130s 5s/step - loss: nan - accuracy: 0.9926 - val_loss: nan - val_accuracy: 0.9926\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 128s 5s/step - loss: nan - accuracy: 0.9926 - val_loss: nan - val_accuracy: 0.9926\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 124s 4s/step - loss: nan - accuracy: 0.9926 - val_loss: nan - val_accuracy: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6c518c41d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_yolo_invoice_model.fit(X_train ,Y_train ,epochs= 5,batch_size = 4, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "my_model_1.compile(optimizer= opt,loss=yolo_my_loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = my_model_1(K.cast(X_train, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'model_6_4/reshape_6/Reshape:0' shape=(28, 15, 15, 3, 10) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/5\n",
      "28/28 [==============================] - 918s 33s/step - loss: 9394.0702 - accuracy: 0.2917 - val_loss: 9478.5361 - val_accuracy: 0.0776\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 163s 6s/step - loss: 9098.0688 - accuracy: 0.3067 - val_loss: 9348.0894 - val_accuracy: 0.1091\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 130s 5s/step - loss: 8930.1405 - accuracy: 0.3236 - val_loss: 9225.4761 - val_accuracy: 0.1906\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 135s 5s/step - loss: 8704.7838 - accuracy: 0.3325 - val_loss: 9070.7363 - val_accuracy: 0.2630\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 133s 5s/step - loss: 8751.2394 - accuracy: 0.3468 - val_loss: 8890.9492 - val_accuracy: 0.2402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fef3c373c18>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_1.fit(X_train ,Y_train ,epochs= 5,batch_size = 4, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/20\n",
      "28/28 [==============================] - 140s 5s/step - loss: 8511.7186 - accuracy: 0.3562 - val_loss: 8783.0176 - val_accuracy: 0.2919\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 135s 5s/step - loss: 8229.4413 - accuracy: 0.3592 - val_loss: 8653.1201 - val_accuracy: 0.3841\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 136s 5s/step - loss: 8071.1187 - accuracy: 0.3546 - val_loss: 8581.0859 - val_accuracy: 0.4254\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 137s 5s/step - loss: 8062.8636 - accuracy: 0.3758 - val_loss: 8510.5464 - val_accuracy: 0.4619\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 139s 5s/step - loss: 7805.0398 - accuracy: 0.3753 - val_loss: 8456.2837 - val_accuracy: 0.4756\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 133s 5s/step - loss: 7524.6754 - accuracy: 0.3767 - val_loss: 8387.5942 - val_accuracy: 0.4561\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 140s 5s/step - loss: 7391.3627 - accuracy: 0.3786 - val_loss: 8355.7378 - val_accuracy: 0.4220\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 134s 5s/step - loss: 7284.4335 - accuracy: 0.3818 - val_loss: 8391.1282 - val_accuracy: 0.4065\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 136s 5s/step - loss: 6981.4909 - accuracy: 0.3851 - val_loss: 8510.8291 - val_accuracy: 0.4059\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 137s 5s/step - loss: 6854.5492 - accuracy: 0.3819 - val_loss: 8422.9243 - val_accuracy: 0.3557\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 136s 5s/step - loss: 6538.9158 - accuracy: 0.3874 - val_loss: 8222.5728 - val_accuracy: 0.3120\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 139s 5s/step - loss: 6582.9782 - accuracy: 0.3839 - val_loss: 7954.0693 - val_accuracy: 0.2991\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 135s 5s/step - loss: 6188.5503 - accuracy: 0.3868 - val_loss: 7721.4502 - val_accuracy: 0.3069\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 137s 5s/step - loss: 5945.3947 - accuracy: 0.3907 - val_loss: 7521.1765 - val_accuracy: 0.2724\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 137s 5s/step - loss: 5572.1903 - accuracy: 0.3823 - val_loss: 7022.1768 - val_accuracy: 0.2404\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 135s 5s/step - loss: 5955.0690 - accuracy: 0.3832 - val_loss: 7777.0210 - val_accuracy: 0.1739\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 140s 5s/step - loss: 6677.0794 - accuracy: 0.3824 - val_loss: 7481.5046 - val_accuracy: 0.2074\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 137s 5s/step - loss: 5948.6084 - accuracy: 0.3850 - val_loss: 7334.7969 - val_accuracy: 0.2244\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 133s 5s/step - loss: 5761.5462 - accuracy: 0.3825 - val_loss: 7565.9504 - val_accuracy: 0.2320\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 132s 5s/step - loss: 5391.4431 - accuracy: 0.3813 - val_loss: 7204.5242 - val_accuracy: 0.2422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fef2020b710>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_1.fit(X_train ,Y_train ,epochs= 20,batch_size = 4, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 130s 5s/step - loss: 5156.8812 - accuracy: 0.3794 - val_loss: 6804.6787 - val_accuracy: 0.2307\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 131s 5s/step - loss: 4971.8205 - accuracy: 0.3723 - val_loss: 6516.6235 - val_accuracy: 0.2180\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 130s 5s/step - loss: 4866.8857 - accuracy: 0.3708 - val_loss: 6211.7239 - val_accuracy: 0.2174\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 134s 5s/step - loss: 4704.8507 - accuracy: 0.3657 - val_loss: 6072.5815 - val_accuracy: 0.2111\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 131s 5s/step - loss: 4513.3638 - accuracy: 0.3717 - val_loss: 5846.2275 - val_accuracy: 0.2196\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 131s 5s/step - loss: 4260.0818 - accuracy: 0.3604 - val_loss: 5787.7104 - val_accuracy: 0.2187\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 134s 5s/step - loss: 4148.9637 - accuracy: 0.3644 - val_loss: 5734.5623 - val_accuracy: 0.2178\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 131s 5s/step - loss: 4030.9855 - accuracy: 0.3598 - val_loss: 5619.0757 - val_accuracy: 0.2076\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 130s 5s/step - loss: 3782.4680 - accuracy: 0.3589 - val_loss: 5557.7183 - val_accuracy: 0.1950\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 131s 5s/step - loss: 3744.9552 - accuracy: 0.3515 - val_loss: 5520.2014 - val_accuracy: 0.1867\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 132s 5s/step - loss: 3454.3678 - accuracy: 0.3512 - val_loss: 5470.7168 - val_accuracy: 0.1722\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 135s 5s/step - loss: 3284.3777 - accuracy: 0.3512 - val_loss: 5395.9902 - val_accuracy: 0.1615\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 133s 5s/step - loss: 3064.4534 - accuracy: 0.3442 - val_loss: 5562.0305 - val_accuracy: 0.1304\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 137s 5s/step - loss: 2890.5329 - accuracy: 0.3456 - val_loss: 5583.0227 - val_accuracy: 0.1194\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 135s 5s/step - loss: 2810.3225 - accuracy: 0.3405 - val_loss: 5500.8000 - val_accuracy: 0.1063\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 139s 5s/step - loss: 2695.9611 - accuracy: 0.3448 - val_loss: 5497.6472 - val_accuracy: 0.0937\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 137s 5s/step - loss: 2639.4548 - accuracy: 0.3348 - val_loss: 5310.2605 - val_accuracy: 0.0881\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 140s 5s/step - loss: 2423.6132 - accuracy: 0.3457 - val_loss: 5126.5322 - val_accuracy: 0.0850\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 144s 5s/step - loss: 2262.8655 - accuracy: 0.3448 - val_loss: 5171.9275 - val_accuracy: 0.0813\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 140s 5s/step - loss: 2187.6399 - accuracy: 0.3426 - val_loss: 5505.5054 - val_accuracy: 0.0748\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 135s 5s/step - loss: 1895.8877 - accuracy: 0.3463 - val_loss: 5578.5156 - val_accuracy: 0.0659\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 137s 5s/step - loss: 1723.5825 - accuracy: 0.3415 - val_loss: 5520.2017 - val_accuracy: 0.0654\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 140s 5s/step - loss: 1626.0647 - accuracy: 0.3419 - val_loss: 5337.7559 - val_accuracy: 0.0730\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 140s 5s/step - loss: 1370.3263 - accuracy: 0.3370 - val_loss: 5280.1235 - val_accuracy: 0.0717\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 139s 5s/step - loss: 1405.0543 - accuracy: 0.3227 - val_loss: 5394.3569 - val_accuracy: 0.0639\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 138s 5s/step - loss: 1313.2244 - accuracy: 0.3316 - val_loss: 5486.9595 - val_accuracy: 0.0543\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 141s 5s/step - loss: 1128.2448 - accuracy: 0.3307 - val_loss: 5285.5186 - val_accuracy: 0.0506\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 144s 5s/step - loss: 857.5962 - accuracy: 0.3276 - val_loss: 5359.0112 - val_accuracy: 0.0504\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 139s 5s/step - loss: 655.3383 - accuracy: 0.3254 - val_loss: 5295.9731 - val_accuracy: 0.0494\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 137s 5s/step - loss: 656.5780 - accuracy: 0.3221 - val_loss: 4853.2297 - val_accuracy: 0.0406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fef201f98d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_1.fit(X_train ,Y_train ,epochs= 30,batch_size = 4, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 137s 5s/step - loss: 535.2450 - accuracy: 0.3273 - val_loss: 5181.5815 - val_accuracy: 0.0452\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 130s 5s/step - loss: 109.1204 - accuracy: 0.3214 - val_loss: 5280.4321 - val_accuracy: 0.0463\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 134s 5s/step - loss: -102.3944 - accuracy: 0.3137 - val_loss: 5433.0435 - val_accuracy: 0.0387\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 130s 5s/step - loss: -291.1480 - accuracy: 0.3239 - val_loss: 5434.8159 - val_accuracy: 0.0357\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 136s 5s/step - loss: -646.4450 - accuracy: 0.3190 - val_loss: 5580.3936 - val_accuracy: 0.0381\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 129s 5s/step - loss: -809.1694 - accuracy: 0.3106 - val_loss: 5782.7688 - val_accuracy: 0.0354\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 130s 5s/step - loss: -1249.4354 - accuracy: 0.3186 - val_loss: 5719.7239 - val_accuracy: 0.0309\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 124s 4s/step - loss: -1112.1932 - accuracy: 0.3092 - val_loss: 5566.7810 - val_accuracy: 0.0278\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 126s 4s/step - loss: -1605.4810 - accuracy: 0.3112 - val_loss: 5291.9427 - val_accuracy: 0.0328\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 128s 5s/step - loss: -1881.4256 - accuracy: 0.3113 - val_loss: 5106.4388 - val_accuracy: 0.0319\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 126s 4s/step - loss: -1852.1479 - accuracy: 0.3085 - val_loss: 5247.6841 - val_accuracy: 0.0309\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 128s 5s/step - loss: -2189.3607 - accuracy: 0.3058 - val_loss: 5121.7147 - val_accuracy: 0.0263\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 128s 5s/step - loss: -2517.4821 - accuracy: 0.3119 - val_loss: 4928.8165 - val_accuracy: 0.0287\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 126s 5s/step - loss: -2561.5094 - accuracy: 0.3092 - val_loss: 5644.1648 - val_accuracy: 0.0291\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 129s 5s/step - loss: -2900.0507 - accuracy: 0.3142 - val_loss: 5832.8271 - val_accuracy: 0.0276\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 129s 5s/step - loss: -3230.7966 - accuracy: 0.3174 - val_loss: 5201.6187 - val_accuracy: 0.0333\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 127s 5s/step - loss: 24622.9719 - accuracy: 0.2964 - val_loss: 4439.5347 - val_accuracy: 0.1146\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 129s 5s/step - loss: 695.2478 - accuracy: 0.2738 - val_loss: 2985.8232 - val_accuracy: 0.1909\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 128s 5s/step - loss: 110.3141 - accuracy: 0.2637 - val_loss: 2442.0737 - val_accuracy: 0.1981\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 129s 5s/step - loss: -649.6560 - accuracy: 0.2618 - val_loss: 2583.8494 - val_accuracy: 0.1848\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 130s 5s/step - loss: -1154.6733 - accuracy: 0.2721 - val_loss: 2955.1462 - val_accuracy: 0.1637\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 128s 5s/step - loss: -1696.7554 - accuracy: 0.2639 - val_loss: 3368.5747 - val_accuracy: 0.1426\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 127s 5s/step - loss: -2012.6160 - accuracy: 0.2673 - val_loss: 3590.0903 - val_accuracy: 0.1261\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 127s 5s/step - loss: -1981.5793 - accuracy: 0.2519 - val_loss: 3882.6804 - val_accuracy: 0.1093\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 128s 5s/step - loss: -2366.5397 - accuracy: 0.2586 - val_loss: 3965.2563 - val_accuracy: 0.1000\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 128s 5s/step - loss: -2867.6827 - accuracy: 0.2628 - val_loss: 4209.8281 - val_accuracy: 0.0939\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 133s 5s/step - loss: -2780.3667 - accuracy: 0.2596 - val_loss: 4438.3416 - val_accuracy: 0.0824\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 130s 5s/step - loss: -3062.2322 - accuracy: 0.2588 - val_loss: 4396.8533 - val_accuracy: 0.0744\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 126s 4s/step - loss: -3267.0266 - accuracy: 0.2617 - val_loss: 4432.7997 - val_accuracy: 0.0661\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 128s 5s/step - loss: -1983.5015 - accuracy: 0.2567 - val_loss: 4497.4214 - val_accuracy: 0.0667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fef2019be10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_1.fit(X_train ,Y_train ,epochs= 30,batch_size = 4, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/5\n",
      "28/28 [==============================] - 382s 14s/step - loss: 8811.4082 - accuracy: 0.0901 - val_loss: 8984.5151 - val_accuracy: 0.0031\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 136s 5s/step - loss: 8491.1466 - accuracy: 0.0925 - val_loss: 9065.9468 - val_accuracy: 0.0233\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 143s 5s/step - loss: 8321.8136 - accuracy: 0.0874 - val_loss: 9070.8750 - val_accuracy: 0.0348\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 144s 5s/step - loss: 8033.6103 - accuracy: 0.0933 - val_loss: 9077.6299 - val_accuracy: 0.0248\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 143s 5s/step - loss: 7824.0460 - accuracy: 0.0918 - val_loss: 9047.2627 - val_accuracy: 0.0269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6bca30c630>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_1.fit(X_train ,Y_train ,epochs= 5,batch_size = 4, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "\n",
    "#opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "my_yolo_invoice_model.compile(optimizer= opt,loss=yolo_my_loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/5\n",
      "28/28 [==============================] - 572s 20s/step - loss: 1266.8813 - accuracy: 0.1751 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 136s 5s/step - loss: -9979.0062 - accuracy: 0.3103 - val_loss: -6546343518535680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 133s 5s/step - loss: -44420.4068 - accuracy: 0.3247 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 129s 5s/step - loss: -261599.7868 - accuracy: 0.2849 - val_loss: -13014438504262129812504576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 137s 5s/step - loss: nan - accuracy: 0.4024 - val_loss: nan - val_accuracy: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6bb0d44b70>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_yolo_invoice_model.fit(X_train ,Y_train ,epochs= 5,batch_size = 4, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [0 1 2 3 4]\n",
      "[[[0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]]\n",
      "\n",
      " [[0 0 0 0 0]\n",
      "  [1 1 1 1 1]\n",
      "  [2 2 2 2 2]\n",
      "  [3 3 3 3 3]\n",
      "  [4 4 4 4 4]]]\n",
      "(2, 5, 5)\n",
      "(6, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "grid_x = np.arange(5)\n",
    "grid_y = np.arange(5)\n",
    "print(grid_x, grid_y)\n",
    "\n",
    "#grid_x, grid_y = np.meshgrid(grid_x, grid_y)\n",
    "a = np.array(np.meshgrid(grid_x, grid_y))\n",
    "b = np.array(np.meshgrid(grid_x, grid_y))\n",
    "c = np.array(np.meshgrid(grid_x, grid_y))\n",
    "d = np.concatenate((a,b,c), axis = 0)\n",
    "#print(grid_x, grid_y)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "#b = 5 + a\n",
    "#print(d)\n",
    "print(d.shape)\n",
    "#print(b[0,0,4])\n",
    "#print(b[1,0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 6)\n",
      "[[[0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]]\n",
      "\n",
      " [[0 0 0 0 0]\n",
      "  [1 1 1 1 1]\n",
      "  [2 2 2 2 2]\n",
      "  [3 3 3 3 3]\n",
      "  [4 4 4 4 4]]\n",
      "\n",
      " [[0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]]\n",
      "\n",
      " [[0 0 0 0 0]\n",
      "  [1 1 1 1 1]\n",
      "  [2 2 2 2 2]\n",
      "  [3 3 3 3 3]\n",
      "  [4 4 4 4 4]]\n",
      "\n",
      " [[0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]\n",
      "  [0 1 2 3 4]]\n",
      "\n",
      " [[0 0 0 0 0]\n",
      "  [1 1 1 1 1]\n",
      "  [2 2 2 2 2]\n",
      "  [3 3 3 3 3]\n",
      "  [4 4 4 4 4]]]\n",
      "===============================================\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]] [[0 1]\n",
      " [0 1]\n",
      " [0 1]] [[0 2]\n",
      " [0 2]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "e = d.transpose(2, 1, 0)\n",
    "f = np.reshape(e,[5,5,3,2])\n",
    "print(e.shape)\n",
    "print(d)\n",
    "print('===============================================')\n",
    "print(f[0,0],f[0,1],f[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 3, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.ones((5,30))\n",
    "Y = np.reshape(Y,[5,5,3,2])\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 2.],\n",
       "         [1., 2.],\n",
       "         [1., 2.]],\n",
       "\n",
       "        [[1., 3.],\n",
       "         [1., 3.],\n",
       "         [1., 3.]],\n",
       "\n",
       "        [[1., 4.],\n",
       "         [1., 4.],\n",
       "         [1., 4.]],\n",
       "\n",
       "        [[1., 5.],\n",
       "         [1., 5.],\n",
       "         [1., 5.]]],\n",
       "\n",
       "\n",
       "       [[[2., 1.],\n",
       "         [2., 1.],\n",
       "         [2., 1.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[2., 3.],\n",
       "         [2., 3.],\n",
       "         [2., 3.]],\n",
       "\n",
       "        [[2., 4.],\n",
       "         [2., 4.],\n",
       "         [2., 4.]],\n",
       "\n",
       "        [[2., 5.],\n",
       "         [2., 5.],\n",
       "         [2., 5.]]],\n",
       "\n",
       "\n",
       "       [[[3., 1.],\n",
       "         [3., 1.],\n",
       "         [3., 1.]],\n",
       "\n",
       "        [[3., 2.],\n",
       "         [3., 2.],\n",
       "         [3., 2.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.],\n",
       "         [3., 3.]],\n",
       "\n",
       "        [[3., 4.],\n",
       "         [3., 4.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[3., 5.],\n",
       "         [3., 5.],\n",
       "         [3., 5.]]],\n",
       "\n",
       "\n",
       "       [[[4., 1.],\n",
       "         [4., 1.],\n",
       "         [4., 1.]],\n",
       "\n",
       "        [[4., 2.],\n",
       "         [4., 2.],\n",
       "         [4., 2.]],\n",
       "\n",
       "        [[4., 3.],\n",
       "         [4., 3.],\n",
       "         [4., 3.]],\n",
       "\n",
       "        [[4., 4.],\n",
       "         [4., 4.],\n",
       "         [4., 4.]],\n",
       "\n",
       "        [[4., 5.],\n",
       "         [4., 5.],\n",
       "         [4., 5.]]],\n",
       "\n",
       "\n",
       "       [[[5., 1.],\n",
       "         [5., 1.],\n",
       "         [5., 1.]],\n",
       "\n",
       "        [[5., 2.],\n",
       "         [5., 2.],\n",
       "         [5., 2.]],\n",
       "\n",
       "        [[5., 3.],\n",
       "         [5., 3.],\n",
       "         [5., 3.]],\n",
       "\n",
       "        [[5., 4.],\n",
       "         [5., 4.],\n",
       "         [5., 4.]],\n",
       "\n",
       "        [[5., 5.],\n",
       "         [5., 5.],\n",
       "         [5., 5.]]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y+f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[2., 1.],\n",
       "         [2., 1.],\n",
       "         [2., 1.]],\n",
       "\n",
       "        [[3., 1.],\n",
       "         [3., 1.],\n",
       "         [3., 1.]],\n",
       "\n",
       "        [[4., 1.],\n",
       "         [4., 1.],\n",
       "         [4., 1.]],\n",
       "\n",
       "        [[5., 1.],\n",
       "         [5., 1.],\n",
       "         [5., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 2.],\n",
       "         [1., 2.],\n",
       "         [1., 2.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[3., 2.],\n",
       "         [3., 2.],\n",
       "         [3., 2.]],\n",
       "\n",
       "        [[4., 2.],\n",
       "         [4., 2.],\n",
       "         [4., 2.]],\n",
       "\n",
       "        [[5., 2.],\n",
       "         [5., 2.],\n",
       "         [5., 2.]]],\n",
       "\n",
       "\n",
       "       [[[1., 3.],\n",
       "         [1., 3.],\n",
       "         [1., 3.]],\n",
       "\n",
       "        [[2., 3.],\n",
       "         [2., 3.],\n",
       "         [2., 3.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.],\n",
       "         [3., 3.]],\n",
       "\n",
       "        [[4., 3.],\n",
       "         [4., 3.],\n",
       "         [4., 3.]],\n",
       "\n",
       "        [[5., 3.],\n",
       "         [5., 3.],\n",
       "         [5., 3.]]],\n",
       "\n",
       "\n",
       "       [[[1., 4.],\n",
       "         [1., 4.],\n",
       "         [1., 4.]],\n",
       "\n",
       "        [[2., 4.],\n",
       "         [2., 4.],\n",
       "         [2., 4.]],\n",
       "\n",
       "        [[3., 4.],\n",
       "         [3., 4.],\n",
       "         [3., 4.]],\n",
       "\n",
       "        [[4., 4.],\n",
       "         [4., 4.],\n",
       "         [4., 4.]],\n",
       "\n",
       "        [[5., 4.],\n",
       "         [5., 4.],\n",
       "         [5., 4.]]],\n",
       "\n",
       "\n",
       "       [[[1., 5.],\n",
       "         [1., 5.],\n",
       "         [1., 5.]],\n",
       "\n",
       "        [[2., 5.],\n",
       "         [2., 5.],\n",
       "         [2., 5.]],\n",
       "\n",
       "        [[3., 5.],\n",
       "         [3., 5.],\n",
       "         [3., 5.]],\n",
       "\n",
       "        [[4., 5.],\n",
       "         [4., 5.],\n",
       "         [4., 5.]],\n",
       "\n",
       "        [[5., 5.],\n",
       "         [5., 5.],\n",
       "         [5., 5.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = np.arange(5)\n",
    "h = np.arange(5)\n",
    "g,h = np.meshgrid(g, h)\n",
    "grid_1st = np.dstack((g, h))\n",
    "grid_2nd = np.dstack((grid_1st, g, h))\n",
    "grid_3rd = np.dstack((grid_2nd, g, h)) \n",
    "grid_final = np.reshape(grid_3rd, [5,5,3,2])\n",
    "Y+grid_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_my_loss(y_true, y_pred):\n",
    "    \n",
    "    '''Return yolo_loss\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh ## w.r.t. target size\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "    '''\n",
    "    grid_size = [15., 15.]\n",
    "    ratio = 480./15.      ## ratio = 32\n",
    "    ignore_thresh = 0.5\n",
    "    Lambda_Coord = 5.0\n",
    "    Lambda_no_obj = 0.5\n",
    "    \n",
    "    grid_x = np.arange(grid_size[1])\n",
    "    grid_y = np.arange(grid_size[0])\n",
    "    grid_x, grid_y = np.meshgrid(grid_x, grid_y)\n",
    "    grid_1st = np.dstack((grid_x, grid_y))\n",
    "    grid_2nd = np.dstack((grid_1st, grid_x, grid_y))\n",
    "    grid_3rd = np.dstack((grid_2nd, grid_x, grid_y)) \n",
    "    grid_final = np.reshape(grid_3rd, [1,15,15,3,2])\n",
    "    \n",
    "    loss = tf.zeros(1, dtype='float32')\n",
    "    \n",
    "    \n",
    "#    m = y_true.shape[0]\n",
    "#    m = np.expand_dims(m, axis=-1)\n",
    "#    mf = K.cast(m, dtype='float32')\n",
    "\n",
    "    \n",
    "    obj_mask_y = y_true[..., 4:5]\n",
    "    obj_mask = K.cast(obj_mask_y, dtype='float32')\n",
    "    \n",
    "#    true_box_wh = y_true[..., 2:4]\n",
    "#    weight = 2 - true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "#    weight = np.expand_dims(weight, axis=-1)\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n",
    "    pred_box_xy = K.sigmoid(y_pred[..., :2]) + grid_final  # this gives x & y in no. of cells. x & y w.r.t. target\n",
    "                                                            # image = (x & y in no. of cells) / no. of cells\n",
    "        \n",
    "#    Lambda_Coord = K.cast(Lambda_Coord, dtype = 'float32')\n",
    "    pred_box_xy_wrt_target_image = pred_box_xy / grid_size[0]\n",
    "    true_box_xy_wrt_target_image = y_true[..., :2]\n",
    "    \n",
    "    pred_box_xy_wrt_ti = K.cast(pred_box_xy_wrt_target_image, dtype = 'float32')\n",
    "    true_box_xy_wrt_ti = K.cast(true_box_xy_wrt_target_image, dtype = 'float32')\n",
    "    \n",
    "    xy_arr = K.cast((true_box_xy_wrt_ti - pred_box_xy_wrt_ti), dtype='float32')\n",
    "    \n",
    "    xy_loss = K.cast(Lambda_Coord * tf.reduce_sum(tf.square(xy_arr) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "    \n",
    "#    xy_loss = (Lambda_Coord *np.sum(mean_squared_error(true_box_xy_wrt_ti, pred_box_xy_wrt_ti) * obj_mask*weight)) / m\n",
    "    \n",
    "#    xy_loss = (Lambda_Coord *np.sum(mean_squared_error(true_box_xy_wrt_ti, pred_box_xy_wrt_ti) * obj_mask*weight)) / m\n",
    "    \n",
    "#    xy_loss = (Lambda_Coord*tf.reduce_sum(tf.square(true_box_xy_wrt_ti - pred_box_xy_wrt_ti) *obj_mask))/m\n",
    "#    wh_loss = tf.reduce_sum(tf.square(true_tw_th - pred_tw_th) * object_mask * box_loss_scale * mix_w) / N\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n",
    "    pred_box_wdht = K.exp(y_pred[..., 2:4]) * (np.reshape(anchors_wrt_target, [1,1,1,3,2])/480.)\n",
    "    pred_box_wh = K.cast(pred_box_wdht, dtype = 'float32')\n",
    "    true_box_wdht = y_true[..., 2:4]\n",
    "    true_box_wh = K.cast(true_box_wdht, dtype = 'float32')\n",
    "    \n",
    "    wh_arr = K.cast((K.sqrt(true_box_wh) - K.sqrt(pred_box_wh)), dtype='float32')\n",
    "    \n",
    "    wh_loss = K.cast(Lambda_Coord * tf.reduce_sum(tf.square(wh_arr) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ \n",
    "\n",
    "    pred_obj_mask = K.cast(K.sigmoid(y_pred[..., 4:5]), dtype = 'float32')  # shape = 28, 15, 15, 3, 1\n",
    "       \n",
    "    true_box_wrt_ti = K.concatenate([true_box_xy_wrt_ti, true_box_wh], axis = -1)  ## in x,y,w,h format\n",
    "    pred_box_wrt_ti = K.concatenate([pred_box_xy_wrt_ti, pred_box_wh], axis = -1)  ## in x,y,w,h format\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    true_box_wrt_ti = xywh_to_x1y1x2y2(true_box_wrt_ti)  ## converted to x1,y1,x2,y2 format\n",
    "    pred_box_wrt_ti = xywh_to_x1y1x2y2(pred_box_wrt_ti)  ## converted to x1,y1,x2,y2 format\n",
    "    \n",
    "    ignore_mask = calc_ignore_mask(ignore_thresh, true_box_wrt_ti, pred_box_wrt_ti)\n",
    "    \n",
    "    ignore_mask = K.cast(ignore_mask, dtype = 'float32')                               \n",
    "\n",
    "    obj_loss = K.cast(K.sum(K.binary_crossentropy(obj_mask, pred_obj_mask) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "    no_obj_mask = 1. - obj_mask_y\n",
    "    no_obj_mask = K.cast(no_obj_mask, dtype  = 'float32')\n",
    "    \n",
    "    noobj_loss = K.cast(Lambda_no_obj * K.sum(binary_cross_entropy(obj_mask, pred_obj_mask) * no_obj_mask * ignore_mask), dtype='float32')\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    true_classes = K.cast(y_true[..., 5:10], dtype = 'float32')\n",
    "    \n",
    "    pred_classes = K.cast(y_pred[..., 5:10], dtype = 'float32')\n",
    "    \n",
    "    class_loss = K.cast(K.sum(binary_cross_entropy(true_classes, pred_classes) * obj_mask), dtype = 'float32')\n",
    "\n",
    "    loss = xy_loss + wh_loss + obj_loss + noobj_loss + class_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_box_reorganised = xywh_to_x1y1x2y2(true_box) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ignore_mask(ignore_thresh, true_box, pred_box):\n",
    "    \n",
    "        # YOLOv3:\n",
    "        # \"If the bounding box prior is not the best but does overlap a ground\n",
    "        # truth object by more than some threshold we ignore the prediction,\n",
    "        # following [17]. We use the threshold of .5.\"\n",
    "        # calculate the iou for each pair of pred bbox and true bbox, then find the best among them\n",
    "\n",
    "        # (None, 13, 13, 3, 4)\n",
    "        \n",
    "        true_box_reorganised = xywh_to_x1y1x2y2(true_box)  # reorganised to x1, y1, x2, y2\n",
    "        pred_box_reorganised = xywh_to_x1y1x2y2(pred_box)\n",
    "        \n",
    "        true_box_shape = tf.shape(true_box_reorganised)  \n",
    "        # (None, 13, 13, 3, 4)\n",
    "        pred_box_shape = tf.shape(pred_box_reorganised)  \n",
    "        # (None, 507, 4)\n",
    "        true_box_reorganised = tf.reshape(true_box_reorganised, [true_box_shape[0], -1, 4])\n",
    "        # sort true_box to have non-zero boxes rank first\n",
    "        true_box_reorganised = tf.sort(true_box_reorganised, axis=1, direction=\"DESCENDING\")\n",
    "        # (None, 100, 4)\n",
    "        # only use maximum 100 boxes per groundtruth to calcualte IOU, otherwise\n",
    "        # GPU emory comsumption would explode for a matrix like (16, 52*52*3, 52*52*3, 4)\n",
    "        true_box_reorganised = true_box_reorganised[:, 0:100, :]\n",
    "        # (None, 507, 4)\n",
    "        pred_box_reorganised = tf.reshape(pred_box_reorganised, [pred_box_shape[0], -1, 4])\n",
    "\n",
    "        # https://github.com/dmlc/gluon-cv/blob/06bb7ec2044cdf3f433721be9362ab84b02c5a90/gluoncv/model_zoo/yolo/yolo_target.py#L198\n",
    "        # (None, 507, 507)\n",
    "        iou = broadcast_iou(pred_box_reorganised, true_box_reorganised)\n",
    "        # (None, 507)\n",
    "        best_iou = tf.reduce_max(iou, axis=-1)\n",
    "        # (None, 13, 13, 3)\n",
    "        best_iou = tf.reshape(best_iou, [pred_box_shape[0], pred_box_shape[1], pred_box_shape[2], pred_box_shape[3]])\n",
    "        # ignore_mask = 1 => don't ignore\n",
    "        # ignore_mask = 0 => should ignore\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "        # (None, 13, 13, 3, 1)\n",
    "        ignore_mask = tf.expand_dims(ignore_mask, axis=-1)\n",
    "        \n",
    "        return ignore_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
