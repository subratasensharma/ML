{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9\n",
    "# https://medium.com/@jonathan_hui/image-segmentation-with-mask-r-cnn-ebe6d793272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding widow :\n",
    "\n",
    "for window in windows\n",
    "    patch = get_patch(image, window)\n",
    "    results = detector(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-CNN :\n",
    "\n",
    "ROIs = region_proposal(image)\n",
    "for ROI in ROIs\n",
    "    patch = get_patch(image, ROI)\n",
    "    results = detector(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAST R-CNN :\n",
    "\n",
    "feature_maps = process(image)\n",
    "ROIs = region_proposal(image)\n",
    "for ROI in ROIs\n",
    "    patch = roi_pooling(feature_maps, ROI)\n",
    "    results = detector2(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTER R-CNN :\n",
    "\n",
    "feature_maps = process(image)\n",
    "ROIs = region_proposal(feature_maps)\n",
    "for ROI in ROIs\n",
    "    patch = roi_pooling(feature_maps, ROI)\n",
    "    results = detector2(patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/using-object-detection-for-complex-image-classification-scenarios-part-4-3e5da160d272"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letâ€™s look at how to use our Custom Pretrained Object Detection Model - RetinaNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# since training RetinaNet requires access to N-Series GPU machines, for the purpose of time and to ensure that this tutorial is CPU only, I have taken the liberty of pretraining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras_retinanet\n",
    "import keras\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "# load image\n",
    "def evaluate_single_image(model, img_path):\n",
    "    image = read_image_bgr(img_path)\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "    # process image\n",
    "    start = time.time()\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    print(\"processing time: \", time.time() - start)\n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "    \n",
    "    return (boxes[0], scores[0], labels[0])\n",
    "def visualize_detection(img_path, model_results):\n",
    "    image = read_image_bgr(img_path)\n",
    "    boxes, scores, labels = model_results\n",
    "    # visualize detections\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        # scores are sorted so we can break\n",
    "        if score < 0.5:\n",
    "            break\n",
    "        color = label_color(label)\n",
    "        b = box.astype(int)\n",
    "        draw_box(draw, b, color=color)\n",
    "        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "        draw_caption(draw, b, caption)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(draw)\n",
    "    plt.show()\n",
    "# load retinanet model\n",
    "soda_model = models.load_model('models/retina_net_soda.h5', backbone_name='resnet50')\n",
    "labels_to_names = {0: 'shelf1', 1: 'shelf2', 2: 'shelf3'}\n",
    "valid_example_path = 'dataset/Beverages/Test/Valid/IMG_4187.JPG'\n",
    "detection_results = evaluate_single_image(soda_model, valid_example_path)\n",
    "visualize_detection(valid_example_path, detection_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
