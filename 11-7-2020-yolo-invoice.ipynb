{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/models/research/object_detection\n"
     ]
    }
   ],
   "source": [
    "cd models/research/object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tqdm\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import *\n",
    "\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.applications import InceptionResNetV2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = [480, 480]\n",
    "target_w = 480 # target sizes of image in model input\n",
    "target_h = 480 #target sizes of image in model input\n",
    "\n",
    "grid_size = [15, 15]\n",
    "grid_y_axis = 15  # each image is to be segmented to 13 x 13 grid\n",
    "grid_x_axis = 15  # # each image is to be segmented to 13 x 13 grid\n",
    "\n",
    "grid_w = target_w / grid_x_axis  # grid cell width\n",
    "grid_h = target_h / grid_y_axis  # grid cell height\n",
    "\n",
    "channels = 3\n",
    "num_anchors = 3\n",
    "class_num = 5 # vendor, invoice, inv_date, po, buyer\n",
    "info = 5 + class_num    # pc, x, y, h, w, and class probabilities\n",
    "\n",
    "categories = ['vendor', 'invoice', 'inv_date', 'po', 'buyer'] # details of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images =  36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/scar3crow/Downloads/8-6-new-scan/50a.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a list of image path\n",
    "\n",
    "inv_directory = '/home/scar3crow/Downloads/8-6-new-scan'  ## 'invoices' is a zip file of jpg images in ...../Downloads \n",
    "                                                        \n",
    "inv_new_image = ['/home/scar3crow/Downloads/8-6-new-scan/{}'.format(i) for i in os.listdir(inv_directory)] # making the list\n",
    "inv_new_image.sort() # Sorting the list\n",
    "\n",
    "num_images = len(inv_new_image)\n",
    "\n",
    "print('Number of images = ', num_images)\n",
    "inv_new_image[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_serial</th>\n",
       "      <th>rows</th>\n",
       "      <th>columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/101a.jpg</td>\n",
       "      <td>160</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/102a.jpg</td>\n",
       "      <td>406</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/103a.jpg</td>\n",
       "      <td>260</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image_serial  rows  columns\n",
       "0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg   160      416\n",
       "1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg   406      870\n",
       "2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   260      416"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check sizes of exiting images & Create a Dataframe with image id and height(row) and width(column):\n",
    "\n",
    "rows = []\n",
    "columns = []\n",
    "image_sl = []\n",
    "df_new = pd.DataFrame()\n",
    "\n",
    "for i in range(len(inv_new_image)):\n",
    "    image = cv2.imread(inv_new_image[i]) ## Loading image\n",
    "    height, width, _ = image.shape\n",
    "    rows.append(height)\n",
    "    columns.append(width)\n",
    "    image_sl.append(inv_new_image[i])\n",
    "    \n",
    "row_values = pd.Series(rows)\n",
    "col_values = pd.Series(columns)\n",
    "image_num = pd.Series(image_sl)\n",
    "\n",
    "\n",
    "df_new.insert(loc=0, column='image_serial', value=image_num)\n",
    "df_new.insert(loc=1, column='rows', value=row_values)\n",
    "df_new.insert(loc=2, column='columns', value=col_values)\n",
    "\n",
    "df_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes =  5\n",
      "Number of unique images =  36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#filename</th>\n",
       "      <th>region_shape_attributes</th>\n",
       "      <th>region_attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>63a.jpg</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":211,\"y\":64,\"width\":76,\"heig...</td>\n",
       "      <td>{\"text\":\"po\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>63a.jpg</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":2,\"y\":68,\"width\":165,\"heigh...</td>\n",
       "      <td>{\"text\":\"buyer\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>101a.jpg</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":6,\"y\":23,\"width\":119,\"heigh...</td>\n",
       "      <td>{\"text\":\"vendor\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #filename                            region_shape_attributes  \\\n",
       "58   63a.jpg  {\"name\":\"rect\",\"x\":211,\"y\":64,\"width\":76,\"heig...   \n",
       "59   63a.jpg  {\"name\":\"rect\",\"x\":2,\"y\":68,\"width\":165,\"heigh...   \n",
       "60  101a.jpg  {\"name\":\"rect\",\"x\":6,\"y\":23,\"width\":119,\"heigh...   \n",
       "\n",
       "    region_attributes  \n",
       "58      {\"text\":\"po\"}  \n",
       "59   {\"text\":\"buyer\"}  \n",
       "60  {\"text\":\"vendor\"}  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading output of VGG Image Annotation tool and create a dataframe\n",
    "\n",
    "r_new_data = pd.read_csv('/home/scar3crow/Downloads/via_new_data.csv')\n",
    "num_obj = r_new_data['region_count'][0] # number of objects in each photo\n",
    "r_new_data.drop(r_new_data.columns[[1, 2, 3, 4]], axis=1, inplace=True) # reduce unnecessary columns\n",
    "r_new_data.sort_values(by=['#filename'], ascending=True) # Sorting based on image-id\n",
    "num_images = r_new_data[\"#filename\"].nunique() # Find out number of unique images\n",
    "\n",
    "print('Number of classes = ', num_obj)\n",
    "print('Number of unique images = ', num_images)\n",
    "r_new_data[58:61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>img_idx</th>\n",
       "      <th>i_path</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>obj_class</th>\n",
       "      <th>img_wd</th>\n",
       "      <th>img_ht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50a.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/50a.jpg</td>\n",
       "      <td>221</td>\n",
       "      <td>59</td>\n",
       "      <td>103</td>\n",
       "      <td>24</td>\n",
       "      <td>po</td>\n",
       "      <td>416</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50a.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/50a.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>206</td>\n",
       "      <td>56</td>\n",
       "      <td>buyer</td>\n",
       "      <td>416</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51a.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/51a.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>vendor</td>\n",
       "      <td>416</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    img_id  img_idx                                          i_path    x   y  \\\n",
       "3  50a.jpg       24  /home/scar3crow/Downloads/8-6-new-scan/50a.jpg  221  59   \n",
       "4  50a.jpg       24  /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5  57   \n",
       "5  51a.jpg       25  /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    5   0   \n",
       "\n",
       "   width  height obj_class  img_wd  img_ht  \n",
       "3    103      24        po     416     209  \n",
       "4    206      56     buyer     416     209  \n",
       "5    120      56    vendor     416     194  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a dataframe for Image_id, x, y, width, height, class, image_width and image_height\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "width = []\n",
    "height = []\n",
    "obj_class = []\n",
    "i_width = []\n",
    "i_height = []\n",
    "img_path = []\n",
    "img_index = []\n",
    "\n",
    "for i in range(len(r_new_data)):\n",
    "    \n",
    "    r_size = r_new_data.values[i, 1][1:(len(r_new_data.values[i, 1])-1)]\n",
    "    r_size_par = r_size.split(\",\")\n",
    "    \n",
    "    x.append(int(\"\".join(filter(str.isdigit, r_size_par[1]))))\n",
    "    y.append(int(\"\".join(filter(str.isdigit, r_size_par[2]))))\n",
    "    width.append(int(\"\".join(filter(str.isdigit, r_size_par[3]))))\n",
    "    height.append(int(\"\".join(filter(str.isdigit, r_size_par[4]))))\n",
    "    \n",
    "    r_attribs = r_new_data.values[i, 2][1:(len(r_new_data.values[i, 2])-1)]\n",
    "    r_attribs_par = r_attribs.split(':')[1]\n",
    "    obj_class.append(r_attribs_par[1:(len(r_attribs_par)-1)])\n",
    "    \n",
    "    foto_id = r_new_data['#filename'][i]\n",
    "    i_path = '/home/scar3crow/Downloads/8-6-new-scan/' + foto_id\n",
    "    foto_index = int(df_new[df_new['image_serial'] == i_path].index[0])\n",
    "    foto_width = df_new['columns'][foto_index]\n",
    "    foto_height = df_new['rows'][foto_index]\n",
    "    i_width.append(foto_width)\n",
    "    i_height.append(foto_height)\n",
    "    img_path.append(i_path)\n",
    "    img_index.append(foto_index)\n",
    "    \n",
    "x_values = pd.Series(x)\n",
    "y_values = pd.Series(y)\n",
    "width_values = pd.Series(width)\n",
    "height_values = pd.Series(height)\n",
    "class_values = pd.Series(obj_class)\n",
    "i_width_values = pd.Series(i_width)\n",
    "i_height_values = pd.Series(i_height)\n",
    "img_path_values = pd.Series(img_path)\n",
    "img_index_values = pd.Series(img_index)\n",
    "\n",
    "r_new_data.insert(loc=1, column='img_idx', value=img_index_values)\n",
    "r_new_data.insert(loc=2, column='i_path', value=img_path_values)\n",
    "r_new_data.insert(loc=3, column='x', value=x_values)\n",
    "r_new_data.insert(loc=4, column='y', value=y_values)\n",
    "r_new_data.insert(loc=5, column='width', value=width_values)\n",
    "r_new_data.insert(loc=6, column='height', value=height_values)\n",
    "r_new_data.insert(loc=7, column='obj_class', value=class_values)\n",
    "r_new_data.insert(loc=8, column='img_wd', value=i_width_values)\n",
    "r_new_data.insert(loc=9, column='img_ht', value=i_height_values)\n",
    "\n",
    "r_new_data.drop(r_new_data.columns[[10, 11]], axis=1, inplace=True) # reduce unnecessary columns\n",
    "\n",
    "r_new_data.rename({'#filename': 'img_id'}, axis=1, inplace=True) # changing column name\n",
    "\n",
    "r_new_data[3:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images =  36\n",
      "Number of classes in diff. categories =  buyer      38\n",
      "vendor     36\n",
      "date       36\n",
      "invoice    36\n",
      "po         33\n",
      "order       1\n",
      "Name: obj_class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique images = ', r_new_data['img_id'].nunique())  # print total no, of unique images\n",
    "print('Number of classes in diff. categories = ', r_new_data['obj_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[       img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ,\n",
       "        img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ,\n",
       "        img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ,\n",
       "        img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ,\n",
       "        img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ,\n",
       "        img_id  img_idx                                           i_path    x  \\\n",
       " 4     50a.jpg       24   /home/scar3crow/Downloads/8-6-new-scan/50a.jpg    5   \n",
       " 9     51a.jpg       25   /home/scar3crow/Downloads/8-6-new-scan/51a.jpg    4   \n",
       " 14    52a.jpg       26   /home/scar3crow/Downloads/8-6-new-scan/52a.jpg    1   \n",
       " 19    53a.jpg       27   /home/scar3crow/Downloads/8-6-new-scan/53a.jpg    0   \n",
       " 24    54a.jpg       28   /home/scar3crow/Downloads/8-6-new-scan/54a.jpg   31   \n",
       " 29    55a.jpg       29   /home/scar3crow/Downloads/8-6-new-scan/55a.jpg    1   \n",
       " 34    56a.jpg       30   /home/scar3crow/Downloads/8-6-new-scan/56a.jpg    1   \n",
       " 39    59a.jpg       31   /home/scar3crow/Downloads/8-6-new-scan/59a.jpg    3   \n",
       " 44    60a.jpg       32   /home/scar3crow/Downloads/8-6-new-scan/60a.jpg    0   \n",
       " 49    61a.jpg       33   /home/scar3crow/Downloads/8-6-new-scan/61a.jpg    1   \n",
       " 54    62a.jpg       34   /home/scar3crow/Downloads/8-6-new-scan/62a.jpg    4   \n",
       " 59    63a.jpg       35   /home/scar3crow/Downloads/8-6-new-scan/63a.jpg    2   \n",
       " 64   101a.jpg        0  /home/scar3crow/Downloads/8-6-new-scan/101a.jpg    6   \n",
       " 69   102a.jpg        1  /home/scar3crow/Downloads/8-6-new-scan/102a.jpg  431   \n",
       " 74   103a.jpg        2  /home/scar3crow/Downloads/8-6-new-scan/103a.jpg   12   \n",
       " 79   104a.jpg        3  /home/scar3crow/Downloads/8-6-new-scan/104a.jpg   21   \n",
       " 84   105a.jpg        4  /home/scar3crow/Downloads/8-6-new-scan/105a.jpg    4   \n",
       " 88   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       " 89   106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       " 94   107a.jpg        6  /home/scar3crow/Downloads/8-6-new-scan/107a.jpg    2   \n",
       " 99   108a.jpg        7  /home/scar3crow/Downloads/8-6-new-scan/108a.jpg  219   \n",
       " 104  109a.jpg        8  /home/scar3crow/Downloads/8-6-new-scan/109a.jpg  220   \n",
       " 109  110a.jpg        9  /home/scar3crow/Downloads/8-6-new-scan/110a.jpg   22   \n",
       " 114  111a.jpg       10  /home/scar3crow/Downloads/8-6-new-scan/111a.jpg    8   \n",
       " 119  112a.jpg       11  /home/scar3crow/Downloads/8-6-new-scan/112a.jpg    2   \n",
       " 124  113a.jpg       12  /home/scar3crow/Downloads/8-6-new-scan/113a.jpg    4   \n",
       " 129  114a.jpg       13  /home/scar3crow/Downloads/8-6-new-scan/114a.jpg    6   \n",
       " 134  115a.jpg       14  /home/scar3crow/Downloads/8-6-new-scan/115a.jpg    2   \n",
       " 139  116a.jpg       15  /home/scar3crow/Downloads/8-6-new-scan/116a.jpg    4   \n",
       " 144  117a.jpg       16  /home/scar3crow/Downloads/8-6-new-scan/117a.jpg    2   \n",
       " 149  118a.jpg       17  /home/scar3crow/Downloads/8-6-new-scan/118a.jpg    1   \n",
       " 154  119a.jpg       18  /home/scar3crow/Downloads/8-6-new-scan/119a.jpg    0   \n",
       " 159  120a.jpg       19  /home/scar3crow/Downloads/8-6-new-scan/120a.jpg    1   \n",
       " 163  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg  211   \n",
       " 164  121a.jpg       20  /home/scar3crow/Downloads/8-6-new-scan/121a.jpg    1   \n",
       " 169  122a.jpg       21  /home/scar3crow/Downloads/8-6-new-scan/122a.jpg   25   \n",
       " 174  123a.jpg       22  /home/scar3crow/Downloads/8-6-new-scan/123a.jpg    1   \n",
       " 179  124a.jpg       23  /home/scar3crow/Downloads/8-6-new-scan/124a.jpg    1   \n",
       " \n",
       "        y  width  height obj_class  img_wd  img_ht  \n",
       " 4     57    206      56     buyer     416     209  \n",
       " 9     53    152      64     buyer     416     194  \n",
       " 14    50    161      74     buyer     416     188  \n",
       " 19    50    177      76     buyer     416     194  \n",
       " 24   103    186      61     buyer     416     168  \n",
       " 29    56    183      74     buyer     416     144  \n",
       " 34    56    166      62     buyer     416     123  \n",
       " 39    58    175      62     buyer     416     200  \n",
       " 44    44    165      52     buyer     416     106  \n",
       " 49    56    155      63     buyer     416     121  \n",
       " 54    58    163      61     buyer     416     123  \n",
       " 59    68    165      55     buyer     416     191  \n",
       " 64    66    142      47     buyer     416     160  \n",
       " 69   140    307     164     buyer     870     406  \n",
       " 74   126    154      68     buyer     416     260  \n",
       " 79   249    431     152     buyer     911     405  \n",
       " 84    53    158      80     buyer     416     147  \n",
       " 88    63     89      22     buyer     416     134  \n",
       " 89    53    154      72     buyer     416     134  \n",
       " 94    47    144      50     buyer     416     140  \n",
       " 99   155    141      71     buyer     416     228  \n",
       " 104  142    153      73     buyer     416     218  \n",
       " 109  144    188      60     buyer     416     211  \n",
       " 114   87    206      76     buyer     416     166  \n",
       " 119   59    177      62     buyer     416     206  \n",
       " 124  112    190      40     buyer     416     201  \n",
       " 129   83    189      46     buyer     416     138  \n",
       " 134   57    191      65     buyer     416     190  \n",
       " 139   59    175      71     buyer     416     145  \n",
       " 144   52    172      72     buyer     416     191  \n",
       " 149   56    188      65     buyer     416     168  \n",
       " 154   62    169      78     buyer     416     146  \n",
       " 159   59    171      78     buyer     416     147  \n",
       " 163   66     79      26     buyer     416     192  \n",
       " 164   68    168      58     buyer     416     192  \n",
       " 169   98    192      74     buyer     416     174  \n",
       " 174   57    171      64     buyer     416     121  \n",
       " 179  117    190      42     buyer     416     203  ]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to correct above :\n",
    "\n",
    "# To find smallest width & height boxes in 'buyer' which should be 'po'\n",
    "gb = r_new_data.groupby('obj_class')    \n",
    "[gb.get_group('buyer') for x in gb.groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images =  36\n",
      "Number of unique classes =  5\n",
      "Number of classes in diff. categories =  vendor      36\n",
      "inv_date    36\n",
      "po          36\n",
      "invoice     36\n",
      "buyer       36\n",
      "Name: obj_class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Correcting above wrong spelling & converting buyer to po of object classes and rechecking\n",
    "\n",
    "id_1 = r_new_data.index[r_new_data['obj_class'] == 'order'] # Finding the index\n",
    "id_2 = r_new_data.index[r_new_data['obj_class'] == 'date'] # to change 'date' to 'inv_date' to be consistent with old data\n",
    "\n",
    "r_new_data.at[id_1, 'obj_class'] = 'po' # writing the correct spelling \n",
    "r_new_data.at[88, 'obj_class'] = 'po' # # 'buyer' to 'po'\n",
    "r_new_data.at[163, 'obj_class'] = 'po' # # 'buyer' to 'po'\n",
    "r_new_data.at[id_2, 'obj_class'] = 'inv_date' # # 'date' to 'inv_date'\n",
    "\n",
    "print('Number of unique images = ', r_new_data['img_id'].nunique())  # print total no, of unique images\n",
    "print('Number of unique classes = ', r_new_data['obj_class'].nunique())\n",
    "print('Number of classes in diff. categories = ', r_new_data['obj_class'].value_counts())\n",
    "\n",
    "# r_new_data.drop(r_new_data.columns[[0]], axis=1, inplace=True) # reduce unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each image, we have to find : (a) line_index = integer, (b) img_path = string, (c) boxes = shape [N, 4], \n",
    "## N is the ground truth count, elements in the second dimension are [x_min, y_min, x_max, y_max] (d) labels = shape\n",
    "## [N]. class index. (e) img_width = int.  =f) img_height = int\n",
    "\n",
    "def single_image_info(lines):\n",
    "    \n",
    "    ## lines will be a dataframe like, for i in range(num_images), lines = r_new_data[i*5:(i+1)*5]\n",
    "    \n",
    "    line_idx = lines.iat[0, 1]\n",
    "    pic_path = lines.iat[0, 2]\n",
    "    img_width = lines.iat[0, 8]\n",
    "    img_height = lines.iat[0, 9]\n",
    "    \n",
    "    boxes = []\n",
    "    labels = []\n",
    "    for i in range(len(lines)):\n",
    "        label, x_min, y_min, x_max, y_max = int(i), float(lines.iat[i,3]), float(lines.iat[i,4]), float(lines.iat[i,3]+lines.iat[i,5]), float(lines.iat[i,4]+lines.iat[i,6])\n",
    "        boxes.append([x_min, y_min, x_max, y_max])\n",
    "        labels.append(label)\n",
    "        \n",
    "    boxes = np.asarray(boxes, np.float32)\n",
    "    labels = np.asarray(labels, np.int64)\n",
    "    \n",
    "    return line_idx, pic_path, boxes, labels, img_width, img_height  ## boxes are in format xmin, ymin, xmax, ymax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "[25, '/home/scar3crow/Downloads/8-6-new-scan/51a.jpg', array([[  5.,   0., 125.,  56.],\n",
      "       [239.,   1., 279.,  20.],\n",
      "       [328.,   1., 382.,  21.],\n",
      "       [238.,  51., 302.,  74.],\n",
      "       [  4.,  53., 156., 117.]], dtype=float32), array([0, 1, 2, 3, 4]), 416, 194]\n"
     ]
    }
   ],
   "source": [
    "## Creating the complete data set :\n",
    "\n",
    "all_image_line = []\n",
    "for i in range(num_images):\n",
    "    image_line = []\n",
    "    limit_lower = i*5\n",
    "    limit_upper = limit_lower+5\n",
    "    lines = r_new_data[limit_lower:limit_upper]\n",
    "    line_idx, pic_path, boxes, labels, img_width, img_height = single_image_info(lines)\n",
    "    image_line.append(line_idx)\n",
    "    image_line.append(pic_path)\n",
    "    image_line.append(boxes)\n",
    "    image_line.append(labels)\n",
    "    image_line.append(img_width)\n",
    "    image_line.append(img_height)\n",
    "    all_image_line.append(image_line)\n",
    "    \n",
    "print(len(all_image_line))\n",
    "print(all_image_line[1])   ##  boxes are in format xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 140 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## Train and Test split\n",
    "\n",
    "data_train, data_val = train_test_split(all_image_line, train_size = 0.8 , shuffle = True)\n",
    "\n",
    "num_all_bbox = len(all_image_line) * len(all_image_line[0][2])\n",
    "num_bb_train = len(data_train) * len(data_train[0][2])\n",
    "num_bb_val = len(data_val) * len(data_val[0][2])\n",
    "print(num_all_bbox, num_bb_train, num_bb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating anchors from true boundary boxes :\n",
    "\n",
    "def iou_kmeans(box, clusters):\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) between a box and k clusters.\n",
    "    :param box: tuple or array, shifted to the origin (i. e. width and height)\n",
    "    :param clusters: numpy array of shape (k, 2) where k is the number of clusters\n",
    "    :return: numpy array of shape (k, 0) where k is the number of clusters\n",
    "    \"\"\"\n",
    "    x = np.minimum(clusters[:, 0], box[0])\n",
    "    y = np.minimum(clusters[:, 1], box[1])\n",
    "    if np.count_nonzero(x == 0) > 0 or np.count_nonzero(y == 0) > 0:\n",
    "        raise ValueError(\"Box has no area\")\n",
    "\n",
    "    intersection = x * y\n",
    "    box_area = box[0] * box[1]\n",
    "    cluster_area = clusters[:, 0] * clusters[:, 1]\n",
    "\n",
    "    iou = intersection / (box_area + cluster_area - intersection)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def kmeans(boxes, k, dist=np.median):\n",
    "    \"\"\"\n",
    "    Calculates k-means clustering with the Intersection over Union (IoU) metric.\n",
    "    :param boxes: numpy array of shape (r, 2), where r is the number of rows\n",
    "    :param k: number of clusters\n",
    "    :param dist: distance function\n",
    "    :return: numpy array of shape (k, 2)\n",
    "    \"\"\"\n",
    "    rows = boxes.shape[0]\n",
    "\n",
    "    distances = np.empty((rows, k))\n",
    "    last_clusters = np.zeros((rows,))\n",
    "\n",
    "    np.random.seed()\n",
    "\n",
    "    # the Forgy method will fail if the whole array contains the same rows\n",
    "    clusters = boxes[np.random.choice(rows, k, replace=False)]\n",
    "\n",
    "\n",
    "    while True:\n",
    "        for row in range(rows):\n",
    "            distances[row] = 1 - iou_kmeans(boxes[row], clusters)\n",
    "\n",
    "        nearest_clusters = np.argmin(distances, axis=1)\n",
    "\n",
    "        if (last_clusters == nearest_clusters).all():\n",
    "            break\n",
    "\n",
    "        for cluster in range(k):\n",
    "            clusters[cluster] = dist(boxes[nearest_clusters == cluster], axis=0)\n",
    "\n",
    "        last_clusters = nearest_clusters\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[189.80769231 160.36697248]\n",
      " [ 68.07692308  65.30612245]\n",
      " [129.23076923  37.92592593]]\n"
     ]
    }
   ],
   "source": [
    "## Finding out anchors :\n",
    "## Firstly, converting true boundary box width, height to width & height with respect to target image :\n",
    "## finaly find anchors. Anchors here are in absolute size w.r.t. target image but not as % of target image or \n",
    "## as multiple of unit grids.\n",
    "\n",
    "# num_all_bb = len(r_new_data) # if no. of bboxes varies for images, this formula should be used \n",
    "\n",
    "anchors_wrt_target = np.zeros((3,2))\n",
    "\n",
    "num_all_bb = len(all_image_line) * len(all_image_line[0][2])  ## from all image line data\n",
    "\n",
    "b_box_wrt_target = np.zeros((num_all_bb,2))\n",
    "\n",
    "for i in range(num_all_bb):\n",
    "    \n",
    "    image_w = r_new_data['img_wd'][i]\n",
    "    image_h = r_new_data['img_ht'][i]\n",
    "\n",
    "    x_ratio = target_w / image_w \n",
    "    y_ratio = target_h / image_h\n",
    "    \n",
    "    anchor_w = r_new_data['width'][i] * x_ratio\n",
    "    anchor_h = r_new_data['height'][i] * y_ratio\n",
    "    b_box_wrt_target[i, 0] = anchor_w\n",
    "    b_box_wrt_target[i, 1] = anchor_h\n",
    "    \n",
    "anchors_wrt_target = kmeans(b_box_wrt_target, num_anchors)\n",
    "\n",
    "print(anchors_wrt_target.shape)\n",
    "print(anchors_wrt_target)     ## anchors wrt target image in abs. value and in format width, height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-processing the original data to get y_true :\n",
    "\n",
    "def process_box(ori_boxes, ori_img_width, ori_img_height, labels, target_size, class_num, anchors):\n",
    "    '''\n",
    "    Generate the y_true label, i.e. the ground truth feature_map.\n",
    "    params:\n",
    "        boxes: [N, 5] shape, float32 dtype. `x_min, y_min, x_max, y_mix, mixup_weight`.\n",
    "        labels: [N] shape, int64 dtype.\n",
    "        class_num: int64 num.\n",
    "        anchors: [3,2] shape, float32 dtype.\n",
    "    '''\n",
    "    \n",
    "    img_width = ori_img_width\n",
    "    img_height = ori_img_height\n",
    "    boxes = ori_boxes           ## boxes in format xmin, ymin, xmax, ymax\n",
    "    \n",
    "    x_ratio = target_size[1] / img_width\n",
    "    y_ratio = target_size[0] / img_height\n",
    "    \n",
    "    boxes_wrt_target = np.zeros((5,4))\n",
    "    box_centers_target = np.zeros((5,2))\n",
    "\n",
    "    boxes_wrt_target[:,0] = boxes[:,0] * x_ratio  # xmin absolute value wrt target image\n",
    "    boxes_wrt_target[:,1] = boxes[:,1] * y_ratio  # ymin absolute value wrt target image\n",
    "    boxes_wrt_target[:,2] = boxes[:,2] * x_ratio  # xmax absolute value wrt target image\n",
    "    boxes_wrt_target[:,3] = boxes[:,3] * y_ratio  # ymax absolute value wrt target image\n",
    "    \n",
    "    # In above, boxes_wrt_target shape is (5, 4), now this will be taken to (5. 5) by adding 1 at end\n",
    "#    boxes_wrt_target = np.concatenate((boxes_wrt_target, np.full(shape=(boxes_wrt_target.shape[0], 1), fill_value=1., dtype=np.float32)), axis=-1)\n",
    "    box_centers_target = (boxes_wrt_target[:, 0:2] + boxes_wrt_target[:, 2:4]) / 2  ## centers wrt target, abs values\n",
    "    \n",
    "    box_sizes = boxes[:, 2:4] - boxes[:, 0:2]  #xmax-xmin = width and ymax-ymin = height wrt original image\n",
    "    box_sizes[:,0] = box_sizes[:,0] * x_ratio  # width w.r.t target image in absolute value\n",
    "    box_sizes[:,1] = box_sizes[:,1] * y_ratio  # width w.r.t target image in absolute value\n",
    "    \n",
    "#    y_true_13 = np.zeros((target_size[1] // 32, target_size[0] // 32, 3, 6 + class_num), np.float32)\n",
    "    y_true_13 = np.zeros((target_size[1] // 32, target_size[0] // 32, 3, 5 + class_num), np.float32)\n",
    "\n",
    "#    y_true = [y_true_13]\n",
    "    \n",
    "    box_sizes = np.expand_dims(box_sizes, 1)\n",
    "    mins = np.maximum(- box_sizes / 2, - anchors / 2)\n",
    "    maxs = np.minimum(box_sizes / 2, anchors / 2)\n",
    "    whs = maxs - mins\n",
    "\n",
    "    iou = (whs[:, :, 0] * whs[:, :, 1]) / (\n",
    "                box_sizes[:, :, 0] * box_sizes[:, :, 1] + anchors[:, 0] * anchors[:, 1] - whs[:, :, 0] * whs[:, :,\n",
    "                                                                                                         1] + 1e-10)\n",
    "    best_match_idx = np.argmax(iou, axis=1)\n",
    "\n",
    "    anchor_mask = np.zeros((target_size[1] // 32, target_size[0] // 32, 3))\n",
    "\n",
    "    cell_size = 32  ## = targetsize / no. of grid cells\n",
    "    \n",
    "    for i, idx in enumerate(best_match_idx):\n",
    "\n",
    "        x = int(np.floor(box_centers_target[i, 0] / cell_size))\n",
    "        y = int(np.floor(box_centers_target[i, 1] / cell_size))\n",
    "        k = int(idx)\n",
    "        c = int(labels[i])\n",
    "\n",
    "        print(x, y, k, c)\n",
    "\n",
    "# Very Imp : Now preparing y_true: all values x_center, y_cemter, width & height are being taken to % of target image\n",
    "        \n",
    "        y_true_13[y, x, k, :2] = box_centers_target[i] / target_size[0] #since target_size[0] = target_size[1]\n",
    "        y_true_13[y, x, k, 2:4] = box_sizes[i] / target_size[0]\n",
    "        y_true_13[y, x, k, 4] = 1.\n",
    "        y_true_13[y, x, k, 5 + c] = 1.\n",
    "#        y_true[0][y, x, k, -1] = boxes_wrt_target[i, -1]\n",
    "        anchor_mask[y, x, k] = 1\n",
    "\n",
    "    return y_true_13, anchor_mask  ## all data are w.r.to target image in % of target image and NOT w,r,t, grid cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Single image-wise image/boundary box preprocessing:\n",
    "\n",
    "def parse_data(line, class_num, target_size, anchors):   ## (mode, letterbox_resize):\n",
    "    '''\n",
    "    param:\n",
    "        line: a line from the training/test txt file\n",
    "        class_num: totol class nums.\n",
    "        target_size: the size of image to be resized to. [width, height] format.\n",
    "        anchors: anchors.\n",
    "        mode: 'train' or 'val'. When set to 'train', data_augmentation will be applied.\n",
    "        letterbox_resize: whether to use the letterbox resize, i.e., keep the original aspect ratio in the resized image.\n",
    "    '''\n",
    "    \n",
    "    img_idx, pic_path, boxes, labels,img_width, img_height = line  # boxes in format xmin, ymin, xmax, ymax\n",
    "    img = cv2.imread(pic_path)\n",
    "    img_resized = cv2.resize(img,(target_size[0], target_size[1]))\n",
    "    \n",
    "    # expand the 2nd dimension, mix up weight default to 1.\n",
    "    boxes = np.concatenate((boxes, np.full(shape=(boxes.shape[0], 1), fill_value=1., dtype=np.float32)), axis=-1)\n",
    "\n",
    "    img_resized = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "\n",
    "    # the input of yolo_v3 should be in range 0~1, lets change to -0.5 to +0.5\n",
    "    img_resized = (img_resized - 127.5)/ 255.\n",
    "\n",
    "    y_true_13, anchor_mask = process_box(boxes, img_width, img_height, labels, target_size, class_num, anchors)\n",
    "\n",
    "    return img_idx, img_resized, y_true_13, anchor_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 2 0\n",
      "9 2 0 1\n",
      "12 2 0 2\n",
      "9 8 0 3\n",
      "2 9 2 4\n",
      "5 2 1 0\n",
      "2 5 0 1\n",
      "2 4 0 2\n",
      "2 7 0 3\n",
      "10 12 2 4\n",
      "3 2 2 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "9 5 0 3\n",
      "2 6 2 4\n",
      "7 5 1 0\n",
      "10 10 0 1\n",
      "10 11 0 2\n",
      "11 13 0 3\n",
      "4 12 1 4\n",
      "2 2 2 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "9 6 0 3\n",
      "2 9 2 4\n",
      "2 3 2 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "9 8 0 3\n",
      "3 10 2 4\n",
      "3 2 2 0\n",
      "9 0 0 1\n",
      "12 0 0 2\n",
      "10 5 0 3\n",
      "3 6 2 4\n",
      "2 3 2 0\n",
      "9 5 0 1\n",
      "9 7 0 2\n",
      "9 12 0 3\n",
      "3 9 1 4\n",
      "7 3 1 0\n",
      "10 9 0 1\n",
      "11 11 0 2\n",
      "11 12 0 3\n",
      "4 11 2 4\n",
      "2 2 2 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "9 5 0 3\n",
      "3 7 2 4\n",
      "11 3 2 0\n",
      "9 9 0 1\n",
      "13 9 0 2\n",
      "10 12 0 3\n",
      "4 11 2 4\n",
      "11 4 2 0\n",
      "9 9 0 1\n",
      "13 9 0 2\n",
      "9 12 0 3\n",
      "3 12 2 4\n",
      "2 5 2 0\n",
      "8 3 0 1\n",
      "12 3 0 2\n",
      "9 8 0 3\n",
      "3 11 2 4\n",
      "2 2 2 0\n",
      "9 1 0 1\n",
      "12 0 0 2\n",
      "9 5 0 3\n",
      "3 6 2 4\n",
      "7 2 1 0\n",
      "11 9 0 1\n",
      "11 10 0 2\n",
      "11 12 0 3\n",
      "4 11 2 4\n",
      "2 2 2 0\n",
      "8 1 0 1\n",
      "12 1 0 2\n",
      "8 6 0 3\n",
      "3 7 2 4\n",
      "2 3 2 0\n",
      "8 1 0 1\n",
      "12 1 0 2\n",
      "9 7 0 3\n",
      "2 10 2 4\n",
      "6 2 1 0\n",
      "2 11 0 1\n",
      "2 12 0 2\n",
      "7 11 0 3\n",
      "10 8 2 4\n",
      "2 3 2 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "10 7 0 3\n",
      "3 9 2 4\n",
      "2 2 2 0\n",
      "9 1 0 1\n",
      "12 2 0 2\n",
      "10 7 0 3\n",
      "2 7 2 4\n",
      "2 3 2 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "10 7 0 3\n",
      "3 11 2 4\n",
      "4 2 2 0\n",
      "9 1 0 1\n",
      "12 0 0 2\n",
      "10 4 0 3\n",
      "3 7 2 4\n",
      "2 2 2 0\n",
      "9 0 0 1\n",
      "12 0 0 2\n",
      "9 3 0 3\n",
      "3 6 2 4\n",
      "3 2 1 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "9 5 0 3\n",
      "3 6 2 4\n",
      "2 3 0 0\n",
      "9 5 0 1\n",
      "9 7 0 2\n",
      "9 12 0 3\n",
      "3 10 1 4\n",
      "2 2 2 0\n",
      "8 1 0 1\n",
      "12 1 0 2\n",
      "9 6 0 3\n",
      "3 7 2 4\n",
      "4 3 2 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "9 5 0 3\n",
      "3 10 2 4\n",
      "2 3 2 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "10 7 0 3\n",
      "3 10 2 4\n",
      "2 4 2 0\n",
      "9 3 0 1\n",
      "12 2 0 2\n",
      "10 7 0 3\n",
      "2 8 2 4\n",
      "4 3 2 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "9 4 0 3\n",
      "3 10 2 4\n",
      "2 3 2 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "10 8 0 3\n",
      "2 9 2 4\n",
      "3 6 2 0\n",
      "9 5 0 1\n",
      "12 5 0 2\n",
      "9 8 0 3\n",
      "3 9 2 4\n",
      "2 2 2 0\n",
      "9 0 0 1\n",
      "12 0 0 2\n",
      "9 4 0 3\n",
      "2 6 2 4\n",
      "3 2 1 0\n",
      "9 1 0 1\n",
      "12 1 0 2\n",
      "9 5 0 3\n",
      "3 6 1 4\n",
      "5 1 1 0\n",
      "2 4 0 1\n",
      "2 4 0 2\n",
      "2 6 0 3\n",
      "10 12 2 4\n",
      "2 3 2 0\n",
      "9 1 0 1\n",
      "12 0 0 2\n",
      "9 6 0 3\n",
      "3 9 2 4\n"
     ]
    }
   ],
   "source": [
    "## Making the data ready for entering into network :\n",
    "\n",
    "anchors = anchors_wrt_target\n",
    "image_index = []\n",
    "image_resized = []\n",
    "image_y_true = []\n",
    "image_anchor_mask = []\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "\n",
    "    line = data_train[i]\n",
    "    \n",
    "    img_idx, img_resized, y_true, anchor_mask = parse_data(line, class_num, target_size, anchors)\n",
    "    \n",
    "    \n",
    "    image_index.append(img_idx)\n",
    "    image_resized.append(img_resized)\n",
    "    image_y_true.append(y_true)\n",
    "    image_anchor_mask.append(anchor_mask)\n",
    "    \n",
    "train_image_index = image_index\n",
    "X_train = np.array(image_resized)\n",
    "Y_train = np.array(image_y_true)\n",
    "train_anchor_mask = np.array(image_anchor_mask)\n",
    "\n",
    "image_index = []\n",
    "image_resized = []\n",
    "image_y_true = []\n",
    "image_anchor_mask = []\n",
    "\n",
    "for i in range(len(data_val)):\n",
    "    line = data_val[i]\n",
    "    \n",
    "    img_idx, img_resized, y_true, anchor_mask = parse_data(line, class_num, target_size, anchors)\n",
    "    image_index.append(img_idx)\n",
    "    image_resized.append(img_resized)\n",
    "    image_y_true.append(y_true)\n",
    "    image_anchor_mask.append(anchor_mask)\n",
    "val_image_index = image_index\n",
    "X_val = np.array(image_resized)\n",
    "Y_val = np.array(image_y_true)\n",
    "val_anchor_mask = np.array(image_anchor_mask)\n",
    "\n",
    "image_index = []\n",
    "image_resized = []\n",
    "image_y_true = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 28 28 8 8 8\n",
      "[5, 7, 26, 9, 4, 34, 27, 12, 28, 14, 10, 3, 13, 16, 21, 35, 33, 1, 29, 6, 22, 17, 31, 11, 23, 20, 19, 30]\n",
      "(28, 480, 480, 3) (28, 15, 15, 3, 10)\n",
      "5 (480, 480, 3) (15, 15, 3, 10)\n",
      "(28, 15, 15, 3) and (15, 15, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(Y_train), len(train_image_index), len(X_val), len(Y_val), len(val_image_index))\n",
    "print(train_image_index)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(train_image_index[0], X_train[0].shape, Y_train[0].shape)\n",
    "print(train_anchor_mask.shape, 'and', train_anchor_mask[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ethanyanjiali/deep-vision/blob/master/YOLO/tensorflow/utils.py\n",
    "\n",
    "def xywh_to_x1y1x2y2(box):\n",
    "    xy = box[..., 0:2]\n",
    "    wh = box[..., 2:4]\n",
    "\n",
    "    x1y1 = xy - wh / 2\n",
    "    x2y2 = xy + wh / 2\n",
    "\n",
    "    y_box = K.concatenate([x1y1, x2y2], axis=-1)\n",
    "    return y_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ethanyanjiali/deep-vision/blob/master/YOLO/tensorflow/utils.py\n",
    "\n",
    "def broadcast_iou(box_a, box_b):\n",
    "    \"\"\"\n",
    "    calculate iou between box_a and multiple box_b in a broadcast way\n",
    "    inputs: box_a: a tensor full of boxes, eg. (B, N, 4), box is in x1y1x2y2\n",
    "            box_b: another tensor full of boxes, eg. (B, M, 4)\n",
    "    \"\"\"\n",
    "\n",
    "    # (B, N, 1, 4)\n",
    "    box_a = tf.expand_dims(box_a, -2)\n",
    "    # (B, 1, M, 4)\n",
    "    box_b = tf.expand_dims(box_b, -3)\n",
    "    # (B, N, M, 4)\n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_a), tf.shape(box_b))\n",
    "\n",
    "    # (B, N, M, 4)\n",
    "    # (B, N, M, 4)\n",
    "    box_a = tf.broadcast_to(box_a, new_shape)\n",
    "    box_b = tf.broadcast_to(box_b, new_shape)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    al, at, ar, ab = tf.split(box_a, 4, -1)\n",
    "    bl, bt, br, bb = tf.split(box_b, 4, -1)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    left = tf.math.maximum(al, bl)\n",
    "    right = tf.math.minimum(ar, br)\n",
    "    top = tf.math.maximum(at, bt)\n",
    "    bot = tf.math.minimum(ab, bb)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    iw = tf.clip_by_value(right - left, 0, 1)\n",
    "    ih = tf.clip_by_value(bot - top, 0, 1)\n",
    "    i = iw * ih\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    area_a = (ar - al) * (ab - at)\n",
    "    area_b = (br - bl) * (bb - bt)\n",
    "    union = area_a + area_b - i\n",
    "\n",
    "    # (B, N, M)\n",
    "    iou = tf.squeeze(i / (union + 1e-7), axis=-1)\n",
    "\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/ethanyanjiali/deep-vision/blob/master/YOLO/tensorflow/yolov3.py#L213\n",
    "\n",
    "def calc_ignore_mask(ignore_thresh, true_box, pred_box):\n",
    "    \n",
    "        # YOLOv3:\n",
    "        # \"If the bounding box prior is not the best but does overlap a ground\n",
    "        # truth object by more than some threshold we ignore the prediction,\n",
    "        # following [17]. We use the threshold of .5.\"\n",
    "        # calculate the iou for each pair of pred bbox and true bbox, then find the best among them\n",
    "\n",
    "        # (None, 13, 13, 3, 4)\n",
    "        \n",
    "        true_box_reorganised = xywh_to_x1y1x2y2(true_box)  # reorganised to x1, y1, x2, y2\n",
    "        pred_box_reorganised = xywh_to_x1y1x2y2(pred_box)\n",
    "        \n",
    "        true_box_shape = tf.shape(true_box_reorganised)  \n",
    "        # (None, 13, 13, 3, 4)\n",
    "        pred_box_shape = tf.shape(pred_box_reorganised)  \n",
    "        # (None, 507, 4)\n",
    "        true_box_reorganised = tf.reshape(true_box_reorganised, [true_box_shape[0], -1, 4])\n",
    "        # sort true_box to have non-zero boxes rank first\n",
    "        true_box_reorganised = tf.sort(true_box_reorganised, axis=1, direction=\"DESCENDING\")\n",
    "        # (None, 100, 4)\n",
    "        # only use maximum 100 boxes per groundtruth to calcualte IOU, otherwise\n",
    "        # GPU emory comsumption would explode for a matrix like (16, 52*52*3, 52*52*3, 4)\n",
    "        true_box_reorganised = true_box_reorganised[:, 0:100, :]\n",
    "        # (None, 507, 4)\n",
    "        pred_box_reorganised = tf.reshape(pred_box_reorganised, [pred_box_shape[0], -1, 4])\n",
    "\n",
    "        # https://github.com/dmlc/gluon-cv/blob/06bb7ec2044cdf3f433721be9362ab84b02c5a90/gluoncv/model_zoo/yolo/yolo_target.py#L198\n",
    "        # (None, 507, 507)\n",
    "        iou = broadcast_iou(pred_box_reorganised, true_box_reorganised)\n",
    "        # (None, 507)\n",
    "        best_iou = tf.reduce_max(iou, axis=-1)\n",
    "        # (None, 13, 13, 3)\n",
    "        best_iou = tf.reshape(best_iou, [pred_box_shape[0], pred_box_shape[1], pred_box_shape[2], pred_box_shape[3]])\n",
    "        # ignore_mask = 1 => don't ignore\n",
    "        # ignore_mask = 0 => should ignore\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "        # (None, 13, 13, 3, 1)\n",
    "        ignore_mask = tf.expand_dims(ignore_mask, axis=-1)\n",
    "        \n",
    "        return ignore_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(logits, labels):\n",
    "    epsilon = 1e-7\n",
    "    logits = tf.clip_by_value(logits, epsilon, 1 - epsilon)\n",
    "    return -(labels * tf.math.log(logits) +\n",
    "             (1 - labels) * tf.math.log(1 - logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def yolo_my_loss(y_true, y_pred, anchors_wrt_target):\n",
    "def yolo_my_loss(y_true, y_pred):\n",
    "    \n",
    "    '''Return yolo_loss\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh ## w.r.t. target size\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "    '''\n",
    "    grid_size = [15., 15.]\n",
    "    ratio = 480./15.      ## ratio = 32\n",
    "    ignore_thresh = 0.5\n",
    "    Lambda_Coord = 5.0\n",
    "    Lambda_no_obj = 0.5\n",
    "    \n",
    "    grid_x = np.arange(grid_size[1])\n",
    "    grid_y = np.arange(grid_size[0])\n",
    "    \n",
    "    a = np.array(np.meshgrid(grid_x, grid_y))\n",
    "    b = np.array(np.meshgrid(grid_x, grid_y))\n",
    "    c = np.array(np.meshgrid(grid_x, grid_y))\n",
    "    d = np.concatenate((a,b,c), axis = 0)\n",
    "    e = d.transpose(2, 1, 0)\n",
    "    grid_final = np.reshape(e,[15,15,3,2])\n",
    "    \n",
    "#    grid_x = np.arange(grid_size[1])\n",
    "#    grid_y = np.arange(grid_size[0])\n",
    "#    grid_x, grid_y = np.meshgrid(grid_x, grid_y)\n",
    "#    grid_1st = np.dstack((grid_x, grid_y))\n",
    "#    grid_2nd = np.dstack((grid_1st, grid_x, grid_y))\n",
    "#    grid_3rd = np.dstack((grid_2nd, grid_x, grid_y)) \n",
    "#    grid_final = np.reshape(grid_3rd, [1,15,15,3,2])\n",
    "    \n",
    "    loss = tf.zeros(1, dtype='float32')\n",
    "    \n",
    "    \n",
    "#    m = y_true.shape[0]\n",
    "#    m = np.expand_dims(m, axis=-1)\n",
    "#    mf = K.cast(m, dtype='float32')\n",
    "\n",
    "    \n",
    "    obj_mask_y = y_true[..., 4:5]\n",
    "#    obj_mask = K.cast(obj_mask_y, dtype='float32')\n",
    "    \n",
    "#    true_box_wh = y_true[..., 2:4]\n",
    "#    weight = 2 - true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "#    weight = np.expand_dims(weight, axis=-1)\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n",
    "#    pred_box_xy = K.sigmoid(y_pred[..., :2]) + grid_final  # this gives x & y in no. of cells. x & y w.r.t. target\n",
    "                                                            # image = (x & y in no. of cells) / no. of cells\n",
    "    pred_box_xy = my_sigmoid(y_pred[..., :2]) + grid_final  # this gives x & y in no. of cells. x & y w.r.t. target\n",
    "                                                            # image = (x & y in no. of cells) / no. of cells\n",
    "        \n",
    "        \n",
    "        \n",
    "#    Lambda_Coord = K.cast(Lambda_Coord, dtype = 'float32')\n",
    "    pred_box_xy_wrt_target_image = (pred_box_xy * ratio) / 480.\n",
    "    true_box_xy_wrt_target_image = y_true[..., :2]\n",
    "    \n",
    "#    pred_box_xy_wrt_ti = K.cast(pred_box_xy_wrt_target_image, dtype = 'float32')\n",
    "#    true_box_xy_wrt_ti = K.cast(true_box_xy_wrt_target_image, dtype = 'float32')\n",
    "    \n",
    "#    xy_arr = K.cast((true_box_xy_wrt_ti - pred_box_xy_wrt_ti), dtype='float32')\n",
    "\n",
    "    xy_arr = np.power((true_box_xy_wrt_ti - pred_box_xy_wrt_ti), 2)\n",
    "    \n",
    "    xy_loss = Lambda_Coord * np.sum(xy_arr * obj_mask_y)\n",
    "    \n",
    "#    xy_loss = K.cast(Lambda_Coord * tf.reduce_sum(tf.square(xy_arr) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "#    xy_loss = (Lambda_Coord *np.sum(mean_squared_error(true_box_xy_wrt_ti, pred_box_xy_wrt_ti) * obj_mask*weight)) / m\n",
    "    \n",
    "#    xy_loss = (Lambda_Coord *np.sum(mean_squared_error(true_box_xy_wrt_ti, pred_box_xy_wrt_ti) * obj_mask*weight)) / m\n",
    "    \n",
    "#    xy_loss = (Lambda_Coord*tf.reduce_sum(tf.square(true_box_xy_wrt_ti - pred_box_xy_wrt_ti) *obj_mask))/m\n",
    "#    wh_loss = tf.reduce_sum(tf.square(true_tw_th - pred_tw_th) * object_mask * box_loss_scale * mix_w) / N\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n",
    "#    pred_box_wdht = K.exp(y_pred[..., 2:4]) * (np.reshape(anchors_wrt_target, [1,1,1,3,2])/480.)\n",
    "    \n",
    "    pred_box_wdht = np.exp(y_pred[..., 2:4]) * (anchors_wrt_target / 480.)\n",
    "    \n",
    "#    pred_box_wh = K.cast(pred_box_wdht, dtype = 'float32')\n",
    "    true_box_wdht = y_true[..., 2:4]\n",
    "#    true_box_wh = K.cast(true_box_wdht, dtype = 'float32')\n",
    "    \n",
    "#    wh_arr = K.cast((K.sqrt(true_box_wh) - K.sqrt(pred_box_wh)), dtype='float32')\n",
    "    \n",
    "    wh_arr = np.power((true_box_wdht - pred_box_wdht), 2)\n",
    "    \n",
    "    wh_loss = Lambda_Coord * np.sum(wh_arr * obj_mask_y)\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ \n",
    "\n",
    "    pred_obj_mask = K.cast(K.sigmoid(y_pred[..., 4:5]), dtype = 'float32')  # shape = 28, 15, 15, 3, 1\n",
    "       \n",
    "    true_box_wrt_ti = K.concatenate([true_box_xy_wrt_ti, true_box_wh], axis = -1)  ## in x,y,w,h format\n",
    "    pred_box_wrt_ti = K.concatenate([pred_box_xy_wrt_ti, pred_box_wh], axis = -1)  ## in x,y,w,h format\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    true_box_wrt_ti = xywh_to_x1y1x2y2(true_box_wrt_ti)  ## converted to x1,y1,x2,y2 format\n",
    "    pred_box_wrt_ti = xywh_to_x1y1x2y2(pred_box_wrt_ti)  ## converted to x1,y1,x2,y2 format\n",
    "    \n",
    "    ignore_mask = calc_ignore_mask(ignore_thresh, true_box_wrt_ti, pred_box_wrt_ti)\n",
    "    \n",
    "    ignore_mask = K.cast(ignore_mask, dtype = 'float32')                               \n",
    "\n",
    "    obj_loss = K.cast(K.sum(K.binary_crossentropy(obj_mask, pred_obj_mask) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "    no_obj_mask = 1. - obj_mask_y\n",
    "    no_obj_mask = K.cast(no_obj_mask, dtype  = 'float32')\n",
    "    \n",
    "    noobj_loss = K.cast(Lambda_no_obj * K.sum(binary_cross_entropy(obj_mask, pred_obj_mask) * no_obj_mask * ignore_mask), dtype='float32')\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "    true_classes = K.cast(y_true[..., 5:10], dtype = 'float32')\n",
    "    \n",
    "    pred_classes = K.cast(y_pred[..., 5:10], dtype = 'float32')\n",
    "    \n",
    "    class_loss = K.cast(K.sum(binary_cross_entropy(true_classes, pred_classes) * obj_mask), dtype = 'float32')\n",
    "\n",
    "    loss = xy_loss + wh_loss + obj_loss + noobj_loss + class_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 480, 480, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 239, 239, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 239, 239, 32) 96          conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 239, 239, 32) 0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 237, 237, 32) 9216        activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 237, 237, 32) 96          conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 237, 237, 32) 0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 237, 237, 64) 18432       activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 237, 237, 64) 192         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 237, 237, 64) 0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 118, 118, 64) 0           activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 118, 118, 80) 5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 118, 118, 80) 240         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 118, 118, 80) 0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 116, 116, 192 138240      activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 116, 116, 192 576         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 116, 116, 192 0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 57, 57, 192)  0           activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 57, 57, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 57, 57, 64)   192         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 57, 57, 64)   0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 57, 57, 48)   9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 57, 57, 96)   55296       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 57, 57, 48)   144         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 57, 57, 96)   288         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 57, 57, 48)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 57, 57, 96)   0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 57, 57, 192)  0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 57, 57, 96)   18432       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 57, 57, 64)   76800       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 57, 57, 96)   82944       activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 57, 57, 64)   12288       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 57, 57, 96)   288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 57, 57, 64)   192         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 57, 57, 96)   288         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 57, 57, 64)   192         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 57, 57, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 57, 57, 64)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 57, 57, 96)   0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 57, 57, 64)   0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 57, 57, 320)  0           activation_209[0][0]             \n",
      "                                                                 activation_211[0][0]             \n",
      "                                                                 activation_214[0][0]             \n",
      "                                                                 activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 57, 57, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 57, 57, 32)   96          conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 57, 57, 32)   0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 57, 57, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 57, 57, 48)   13824       activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 57, 57, 32)   96          conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 57, 57, 48)   144         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 57, 57, 32)   0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 57, 57, 48)   0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 57, 57, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 57, 57, 32)   9216        activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 57, 57, 64)   27648       activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 57, 57, 32)   96          conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 57, 57, 32)   96          conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 57, 57, 64)   192         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 57, 57, 32)   0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 57, 57, 32)   0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 57, 57, 64)   0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_216[0][0]             \n",
      "                                                                 activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 57, 57, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 57, 57, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 57, 57, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 57, 57, 32)   96          conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 57, 57, 32)   0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 57, 57, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 57, 57, 48)   13824       activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 57, 57, 32)   96          conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 57, 57, 48)   144         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 57, 57, 32)   0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 57, 57, 48)   0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 57, 57, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 57, 57, 32)   9216        activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 57, 57, 64)   27648       activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 57, 57, 32)   96          conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 57, 57, 32)   96          conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 57, 57, 64)   192         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 57, 57, 32)   0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 57, 57, 32)   0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 57, 57, 64)   0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_222[0][0]             \n",
      "                                                                 activation_224[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 57, 57, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 57, 57, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 57, 57, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 57, 57, 32)   96          conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 57, 57, 32)   0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 57, 57, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 57, 57, 48)   13824       activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 57, 57, 32)   96          conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 57, 57, 48)   144         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 57, 57, 32)   0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 57, 57, 48)   0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 57, 57, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 57, 57, 32)   9216        activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 57, 57, 64)   27648       activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 57, 57, 32)   96          conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 57, 57, 32)   96          conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 57, 57, 64)   192         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 57, 57, 32)   0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 57, 57, 32)   0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 57, 57, 64)   0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_228[0][0]             \n",
      "                                                                 activation_230[0][0]             \n",
      "                                                                 activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 57, 57, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 57, 57, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 57, 57, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 57, 57, 32)   96          conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 57, 57, 32)   0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 57, 57, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 57, 57, 48)   13824       activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 57, 57, 32)   96          conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 57, 57, 48)   144         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 57, 57, 32)   0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 57, 57, 48)   0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 57, 57, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 57, 57, 32)   9216        activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 57, 57, 64)   27648       activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 57, 57, 32)   96          conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 57, 57, 32)   96          conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 57, 57, 64)   192         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 57, 57, 32)   0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 57, 57, 32)   0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 57, 57, 64)   0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_234[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 57, 57, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 57, 57, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 57, 57, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 57, 57, 32)   96          conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 57, 57, 32)   0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 57, 57, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 57, 57, 48)   13824       activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 57, 57, 32)   96          conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 57, 57, 48)   144         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 57, 57, 32)   0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 57, 57, 48)   0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 57, 57, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 57, 57, 32)   9216        activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 57, 57, 64)   27648       activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 57, 57, 32)   96          conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 57, 57, 32)   96          conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 57, 57, 64)   192         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 57, 57, 32)   0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 57, 57, 32)   0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 57, 57, 64)   0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_240[0][0]             \n",
      "                                                                 activation_242[0][0]             \n",
      "                                                                 activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 57, 57, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 57, 57, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 57, 57, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 57, 57, 32)   96          conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 57, 57, 32)   0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 57, 57, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 57, 57, 48)   13824       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 57, 57, 32)   96          conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 57, 57, 48)   144         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 57, 57, 32)   0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 57, 57, 48)   0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 57, 57, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 57, 57, 32)   9216        activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 57, 57, 64)   27648       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 57, 57, 32)   96          conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 57, 57, 32)   96          conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 57, 57, 64)   192         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 57, 57, 32)   0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 57, 57, 32)   0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 57, 57, 64)   0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_246[0][0]             \n",
      "                                                                 activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 57, 57, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 57, 57, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 57, 57, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 57, 57, 32)   96          conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 57, 57, 32)   0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 57, 57, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 57, 57, 48)   13824       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 57, 57, 32)   96          conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 57, 57, 48)   144         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 57, 57, 32)   0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 57, 57, 48)   0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 57, 57, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 57, 57, 32)   9216        activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 57, 57, 64)   27648       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 57, 57, 32)   96          conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 57, 57, 32)   96          conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 57, 57, 64)   192         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 57, 57, 32)   0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 57, 57, 32)   0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 57, 57, 64)   0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_252[0][0]             \n",
      "                                                                 activation_254[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 57, 57, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 57, 57, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 57, 57, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 57, 57, 32)   96          conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 57, 57, 32)   0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 57, 57, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 57, 57, 48)   13824       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 57, 57, 32)   96          conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 57, 57, 48)   144         conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 57, 57, 32)   0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 57, 57, 48)   0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 57, 57, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 57, 57, 32)   9216        activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 57, 57, 64)   27648       activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 57, 57, 32)   96          conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 57, 57, 32)   96          conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 57, 57, 64)   192         conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 57, 57, 32)   0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 57, 57, 32)   0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 57, 57, 64)   0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_258[0][0]             \n",
      "                                                                 activation_260[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 57, 57, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 57, 57, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 57, 57, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 57, 57, 32)   96          conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 57, 57, 32)   0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 57, 57, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 57, 57, 48)   13824       activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 57, 57, 32)   96          conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 57, 57, 48)   144         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 57, 57, 32)   0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 57, 57, 48)   0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 57, 57, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 57, 57, 32)   9216        activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 57, 57, 64)   27648       activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 57, 57, 32)   96          conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 57, 57, 32)   96          conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 57, 57, 64)   192         conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 57, 57, 32)   0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 57, 57, 32)   0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 57, 57, 64)   0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 57, 57, 128)  0           activation_264[0][0]             \n",
      "                                                                 activation_266[0][0]             \n",
      "                                                                 activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 57, 57, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 57, 57, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 57, 57, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 57, 57, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 57, 57, 32)   96          conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 57, 57, 32)   0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 57, 57, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 57, 57, 48)   13824       activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 57, 57, 32)   96          conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 57, 57, 48)   144         conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 57, 57, 32)   0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 57, 57, 48)   0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 57, 57, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 57, 57, 32)   9216        activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 57, 57, 64)   27648       activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 57, 57, 32)   96          conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 57, 57, 32)   96          conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 57, 57, 64)   192         conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 57, 57, 32)   0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 57, 57, 32)   0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 57, 57, 64)   0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 57, 57, 128)  0           activation_270[0][0]             \n",
      "                                                                 activation_272[0][0]             \n",
      "                                                                 activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 57, 57, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 57, 57, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 57, 57, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 57, 57, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 57, 57, 256)  768         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 57, 57, 256)  0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 57, 57, 256)  589824      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 57, 57, 256)  768         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 57, 57, 256)  0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 28, 28, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 28, 28, 384)  884736      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 28, 28, 384)  1152        conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 28, 28, 384)  1152        conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 28, 28, 384)  0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 28, 28, 384)  0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 28, 28, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 28, 28, 1088) 0           activation_276[0][0]             \n",
      "                                                                 activation_279[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 28, 28, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 28, 28, 128)  384         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 28, 28, 128)  0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 28, 28, 160)  143360      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 28, 28, 160)  480         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 28, 28, 160)  0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 28, 28, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 28, 28, 192)  215040      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 28, 28, 192)  576         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 28, 28, 192)  576         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 28, 28, 192)  0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 28, 28, 192)  0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_280[0][0]             \n",
      "                                                                 activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 28, 28, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 28, 28, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 28, 28, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 28, 28, 128)  384         conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 28, 28, 128)  0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 28, 28, 160)  143360      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 28, 28, 160)  480         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 28, 28, 160)  0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 28, 28, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 28, 28, 192)  215040      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 28, 28, 192)  576         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 28, 28, 192)  576         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 28, 28, 192)  0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 28, 28, 192)  0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_284[0][0]             \n",
      "                                                                 activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 28, 28, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 28, 28, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 28, 28, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 28, 28, 128)  384         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 28, 28, 128)  0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 28, 28, 160)  143360      activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 28, 28, 160)  480         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 28, 28, 160)  0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 28, 28, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 28, 28, 192)  215040      activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 28, 28, 192)  576         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 28, 28, 192)  576         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 28, 28, 192)  0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 28, 28, 192)  0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_288[0][0]             \n",
      "                                                                 activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 28, 28, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 28, 28, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 28, 28, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 28, 28, 128)  384         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 28, 28, 128)  0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 28, 28, 160)  143360      activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 28, 28, 160)  480         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 28, 28, 160)  0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 28, 28, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 28, 28, 192)  215040      activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 28, 28, 192)  576         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 28, 28, 192)  576         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 28, 28, 192)  0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 28, 28, 192)  0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_292[0][0]             \n",
      "                                                                 activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 28, 28, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 28, 28, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 28, 28, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 28, 28, 128)  384         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 28, 28, 128)  0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 28, 28, 160)  143360      activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 28, 28, 160)  480         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 28, 28, 160)  0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 28, 28, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 28, 28, 192)  215040      activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 28, 28, 192)  576         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 28, 28, 192)  576         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 28, 28, 192)  0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 28, 28, 192)  0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_296[0][0]             \n",
      "                                                                 activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 28, 28, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 28, 28, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 28, 28, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 28, 28, 128)  384         conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 28, 28, 128)  0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 28, 28, 160)  143360      activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 28, 28, 160)  480         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 28, 28, 160)  0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 28, 28, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 28, 28, 192)  215040      activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 28, 28, 192)  576         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 28, 28, 192)  576         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 28, 28, 192)  0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 28, 28, 192)  0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_300[0][0]             \n",
      "                                                                 activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 28, 28, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 28, 28, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 28, 28, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 28, 28, 128)  384         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 28, 28, 128)  0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 28, 28, 160)  143360      activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 28, 28, 160)  480         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 28, 28, 160)  0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 28, 28, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 28, 28, 192)  215040      activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 28, 28, 192)  576         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 28, 28, 192)  576         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 28, 28, 192)  0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 28, 28, 192)  0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_304[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 28, 28, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 28, 28, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 28, 28, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 28, 28, 128)  384         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 28, 28, 128)  0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 28, 28, 160)  143360      activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 28, 28, 160)  480         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 28, 28, 160)  0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 28, 28, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 28, 28, 192)  215040      activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 28, 28, 192)  576         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 28, 28, 192)  576         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 28, 28, 192)  0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 28, 28, 192)  0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_308[0][0]             \n",
      "                                                                 activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 28, 28, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 28, 28, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 28, 28, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 28, 28, 128)  384         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 28, 28, 128)  0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 28, 28, 160)  143360      activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 28, 28, 160)  480         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 28, 28, 160)  0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 28, 28, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 28, 28, 192)  215040      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 28, 28, 192)  576         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 28, 28, 192)  576         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 28, 28, 192)  0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 28, 28, 192)  0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 28, 28, 384)  0           activation_312[0][0]             \n",
      "                                                                 activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 28, 28, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 28, 28, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 28, 28, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 28, 28, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 28, 28, 128)  384         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 28, 28, 128)  0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 28, 28, 160)  143360      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 28, 28, 160)  480         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 28, 28, 160)  0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 28, 28, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 28, 28, 192)  215040      activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 28, 28, 192)  576         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 28, 28, 192)  576         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 28, 28, 192)  0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 28, 28, 192)  0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_316[0][0]             \n",
      "                                                                 activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 28, 28, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 28, 28, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 28, 28, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 28, 28, 128)  384         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 28, 28, 128)  0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 28, 28, 160)  143360      activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 28, 28, 160)  480         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 28, 28, 160)  0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 28, 28, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 28, 28, 192)  215040      activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 28, 28, 192)  576         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 28, 28, 192)  576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 28, 28, 192)  0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 28, 28, 192)  0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_320[0][0]             \n",
      "                                                                 activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 28, 28, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 28, 28, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 28, 28, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 28, 28, 128)  384         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 28, 28, 128)  0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 28, 28, 160)  143360      activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 28, 28, 160)  480         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 28, 28, 160)  0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 28, 28, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 28, 28, 192)  215040      activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 28, 28, 192)  576         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 28, 28, 192)  576         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 28, 28, 192)  0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 28, 28, 192)  0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_324[0][0]             \n",
      "                                                                 activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 28, 28, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 28, 28, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 28, 28, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 28, 28, 128)  384         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 28, 28, 128)  0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 28, 28, 160)  143360      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 28, 28, 160)  480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 28, 28, 160)  0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 28, 28, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 28, 28, 192)  215040      activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 28, 28, 192)  576         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 28, 28, 192)  576         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 28, 28, 192)  0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 28, 28, 192)  0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_328[0][0]             \n",
      "                                                                 activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 28, 28, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 28, 28, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 28, 28, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 28, 28, 128)  384         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 28, 28, 128)  0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 28, 28, 160)  143360      activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 28, 28, 160)  480         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 28, 28, 160)  0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 28, 28, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 28, 28, 192)  215040      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 28, 28, 192)  576         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 28, 28, 192)  576         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 28, 28, 192)  0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 28, 28, 192)  0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_332[0][0]             \n",
      "                                                                 activation_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 28, 28, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 28, 28, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 28, 28, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 28, 28, 128)  384         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 28, 28, 128)  0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 28, 28, 160)  143360      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 28, 28, 160)  480         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 28, 28, 160)  0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 28, 28, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 28, 28, 192)  215040      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 28, 28, 192)  576         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 28, 28, 192)  576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 28, 28, 192)  0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 28, 28, 192)  0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_336[0][0]             \n",
      "                                                                 activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 28, 28, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 28, 28, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 28, 28, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 28, 28, 128)  384         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 28, 28, 128)  0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 28, 28, 160)  143360      activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 28, 28, 160)  480         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 28, 28, 160)  0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 28, 28, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 28, 28, 192)  215040      activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 28, 28, 192)  576         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 28, 28, 192)  576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 28, 28, 192)  0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 28, 28, 192)  0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_340[0][0]             \n",
      "                                                                 activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 28, 28, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 28, 28, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 28, 28, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 28, 28, 128)  384         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 28, 28, 128)  0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 28, 28, 160)  143360      activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 28, 28, 160)  480         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 28, 28, 160)  0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 28, 28, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 28, 28, 192)  215040      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 28, 28, 192)  576         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 28, 28, 192)  576         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 28, 28, 192)  0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 28, 28, 192)  0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_344[0][0]             \n",
      "                                                                 activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 28, 28, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 28, 28, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 28, 28, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 28, 28, 128)  384         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 28, 28, 128)  0           batch_normalization_356[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 28, 28, 160)  143360      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 28, 28, 160)  480         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 28, 28, 160)  0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 28, 28, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 28, 28, 192)  215040      activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 28, 28, 192)  576         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 28, 28, 192)  576         conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 28, 28, 192)  0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 28, 28, 192)  0           batch_normalization_358[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_348[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 28, 28, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 28, 28, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 28, 28, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 28, 28, 128)  384         conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 28, 28, 128)  0           batch_normalization_360[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 28, 28, 160)  143360      activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 28, 28, 160)  480         conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 28, 28, 160)  0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 28, 28, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 28, 28, 192)  215040      activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 28, 28, 192)  576         conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 28, 28, 192)  576         conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 28, 28, 192)  0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 28, 28, 192)  0           batch_normalization_362[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_352[0][0]             \n",
      "                                                                 activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 28, 28, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 28, 28, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 28, 28, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 28, 28, 128)  384         conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 28, 28, 128)  0           batch_normalization_364[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 28, 28, 160)  143360      activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 28, 28, 160)  480         conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 28, 28, 160)  0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 28, 28, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 28, 28, 192)  215040      activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 28, 28, 192)  576         conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 28, 28, 192)  576         conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 28, 28, 192)  0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 28, 28, 192)  0           batch_normalization_366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 28, 28, 384)  0           activation_356[0][0]             \n",
      "                                                                 activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 28, 28, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 28, 28, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 28, 28, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 28, 28, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 28, 28, 256)  768         conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 28, 28, 256)  0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 28, 28, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 28, 28, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 28, 28, 288)  663552      activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 28, 28, 256)  768         conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 28, 28, 256)  768         conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 28, 28, 288)  864         conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 28, 28, 256)  0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 28, 28, 256)  0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 28, 28, 288)  0           batch_normalization_372[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 13, 13, 384)  884736      activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 13, 13, 288)  663552      activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 13, 13, 320)  829440      activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 13, 13, 384)  1152        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 13, 13, 288)  864         conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 13, 13, 320)  960         conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 13, 13, 384)  0           batch_normalization_368[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 13, 13, 288)  0           batch_normalization_370[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 13, 13, 320)  0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 13, 13, 1088) 0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 13, 13, 2080) 0           activation_361[0][0]             \n",
      "                                                                 activation_363[0][0]             \n",
      "                                                                 activation_366[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 13, 13, 192)  399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 13, 13, 192)  576         conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 13, 13, 192)  0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 13, 13, 224)  129024      activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 13, 13, 224)  672         conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 13, 13, 224)  0           batch_normalization_376[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 13, 13, 192)  399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 13, 13, 256)  172032      activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 13, 13, 192)  576         conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, 13, 13, 256)  768         conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 13, 13, 192)  0           batch_normalization_374[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 13, 13, 256)  0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_367[0][0]             \n",
      "                                                                 activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 13, 13, 2080) 0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 13, 13, 2080) 0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 13, 13, 192)  399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, 13, 13, 192)  576         conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 13, 13, 192)  0           batch_normalization_379[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 13, 13, 224)  129024      activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_380 (BatchN (None, 13, 13, 224)  672         conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 13, 13, 224)  0           batch_normalization_380[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 13, 13, 192)  399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 13, 13, 256)  172032      activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, 13, 13, 192)  576         conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_381 (BatchN (None, 13, 13, 256)  768         conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 13, 13, 192)  0           batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 13, 13, 256)  0           batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_371[0][0]             \n",
      "                                                                 activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 13, 13, 2080) 0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 13, 13, 2080) 0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 13, 13, 192)  399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_383 (BatchN (None, 13, 13, 192)  576         conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 13, 13, 192)  0           batch_normalization_383[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 13, 13, 224)  129024      activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_384 (BatchN (None, 13, 13, 224)  672         conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 13, 13, 224)  0           batch_normalization_384[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 13, 13, 192)  399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 13, 13, 256)  172032      activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_382 (BatchN (None, 13, 13, 192)  576         conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchN (None, 13, 13, 256)  768         conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 13, 13, 192)  0           batch_normalization_382[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 13, 13, 256)  0           batch_normalization_385[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_375[0][0]             \n",
      "                                                                 activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 13, 13, 2080) 0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 13, 13, 2080) 0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, 13, 13, 192)  399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_387 (BatchN (None, 13, 13, 192)  576         conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 13, 13, 192)  0           batch_normalization_387[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 13, 13, 224)  129024      activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, 13, 13, 224)  672         conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 13, 13, 224)  0           batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 13, 13, 192)  399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 13, 13, 256)  172032      activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchN (None, 13, 13, 192)  576         conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, 13, 13, 256)  768         conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 13, 13, 192)  0           batch_normalization_386[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 13, 13, 256)  0           batch_normalization_389[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_379[0][0]             \n",
      "                                                                 activation_382[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 13, 13, 2080) 0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 13, 13, 2080) 0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, 13, 13, 192)  399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 13, 13, 192)  576         conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 13, 13, 192)  0           batch_normalization_391[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, 13, 13, 224)  129024      activation_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, 13, 13, 224)  672         conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 13, 13, 224)  0           batch_normalization_392[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, 13, 13, 192)  399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 13, 13, 256)  172032      activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 13, 13, 192)  576         conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, 13, 13, 256)  768         conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 13, 13, 192)  0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 13, 13, 256)  0           batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_383[0][0]             \n",
      "                                                                 activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 13, 13, 2080) 0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 13, 13, 2080) 0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 13, 13, 192)  399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_395 (BatchN (None, 13, 13, 192)  576         conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 13, 13, 192)  0           batch_normalization_395[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 13, 13, 224)  129024      activation_388[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_396 (BatchN (None, 13, 13, 224)  672         conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 13, 13, 224)  0           batch_normalization_396[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 13, 13, 192)  399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 13, 13, 256)  172032      activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, 13, 13, 192)  576         conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_397 (BatchN (None, 13, 13, 256)  768         conv2d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 13, 13, 192)  0           batch_normalization_394[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 13, 13, 256)  0           batch_normalization_397[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_387[0][0]             \n",
      "                                                                 activation_390[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 13, 13, 2080) 0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 13, 13, 2080) 0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, 13, 13, 192)  399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, 13, 13, 192)  576         conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 13, 13, 192)  0           batch_normalization_399[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, 13, 13, 224)  129024      activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, 13, 13, 224)  672         conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, 13, 13, 224)  0           batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, 13, 13, 192)  399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, 13, 13, 256)  172032      activation_393[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, 13, 13, 192)  576         conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, 13, 13, 256)  768         conv2d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 13, 13, 192)  0           batch_normalization_398[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, 13, 13, 256)  0           batch_normalization_401[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_391[0][0]             \n",
      "                                                                 activation_394[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 13, 13, 2080) 0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 13, 13, 2080) 0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, 13, 13, 192)  399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 13, 13, 192)  576         conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, 13, 13, 192)  0           batch_normalization_403[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 13, 13, 224)  129024      activation_396[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 13, 13, 224)  672         conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, 13, 13, 224)  0           batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, 13, 13, 192)  399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 13, 13, 256)  172032      activation_397[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 13, 13, 192)  576         conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 13, 13, 256)  768         conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_395 (Activation)     (None, 13, 13, 192)  0           batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_398 (Activation)     (None, 13, 13, 256)  0           batch_normalization_405[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_395[0][0]             \n",
      "                                                                 activation_398[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 13, 13, 2080) 0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 13, 13, 2080) 0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 13, 13, 192)  399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 13, 13, 192)  576         conv2d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_400 (Activation)     (None, 13, 13, 192)  0           batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, 13, 13, 224)  129024      activation_400[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 13, 13, 224)  672         conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_401 (Activation)     (None, 13, 13, 224)  0           batch_normalization_408[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 13, 13, 192)  399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, 13, 13, 256)  172032      activation_401[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 13, 13, 192)  576         conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, 13, 13, 256)  768         conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_399 (Activation)     (None, 13, 13, 192)  0           batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_402 (Activation)     (None, 13, 13, 256)  0           batch_normalization_409[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 13, 13, 448)  0           activation_399[0][0]             \n",
      "                                                                 activation_402[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 13, 13, 2080) 933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 13, 13, 2080) 0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 13, 13, 2080) 0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, 13, 13, 192)  399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, 13, 13, 192)  576         conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_404 (Activation)     (None, 13, 13, 192)  0           batch_normalization_411[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, 13, 13, 224)  129024      activation_404[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, 13, 13, 224)  672         conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_405 (Activation)     (None, 13, 13, 224)  0           batch_normalization_412[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_411 (Conv2D)             (None, 13, 13, 192)  399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, 13, 13, 256)  172032      activation_405[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, 13, 13, 192)  576         conv2d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, 13, 13, 256)  768         conv2d_414[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_403 (Activation)     (None, 13, 13, 192)  0           batch_normalization_410[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, 13, 13, 256)  0           batch_normalization_413[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 13, 13, 448)  0           activation_403[0][0]             \n",
      "                                                                 activation_406[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 13, 13, 2080) 933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 13, 13, 2080) 0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 13, 13, 1536) 3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 13, 13, 1536) 4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 13, 13, 1536) 0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 26, 26, 1536) 0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, 24, 24, 512)  7078400     up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 24, 24, 512)  0           conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, 24, 24, 512)  2048        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 24, 24, 512)  0           batch_normalization_414[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, 22, 22, 256)  1179904     leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 22, 22, 256)  0           conv2d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, 22, 22, 256)  1024        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 22, 22, 256)  0           batch_normalization_415[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 44, 44, 256)  0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, 42, 42, 256)  590080      up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 42, 42, 256)  0           conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, 42, 42, 256)  1024        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 42, 42, 256)  0           batch_normalization_416[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, 40, 40, 256)  590080      leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 40, 40, 256)  0           conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, 40, 40, 256)  1024        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 40, 40, 256)  0           batch_normalization_417[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, 19, 19, 128)  295040      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 19, 19, 128)  0           conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, 19, 19, 128)  512         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 19, 19, 128)  0           batch_normalization_418[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, 17, 17, 64)   73792       leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 17, 17, 64)   0           conv2d_420[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, 17, 17, 64)   256         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 17, 17, 64)   0           batch_normalization_419[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, 15, 15, 64)   36928       leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 15, 15, 64)   0           conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, 15, 15, 64)   256         dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 15, 15, 64)   0           batch_normalization_420[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, 15, 15, 30)   1950        leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 15, 15, 3, 10 0           conv2d_422[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 64,189,054\n",
      "Trainable params: 64,125,438\n",
      "Non-trainable params: 63,616\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def yolo_model(input_shape):\n",
    "    \n",
    "    \n",
    "    inp = Input(input_shape)\n",
    "   \n",
    "    model = InceptionResNetV2( input_tensor= inp , include_top=False, weights='imagenet')\n",
    "    last_layer = model.output\n",
    "    \n",
    "    new_last_layer = UpSampling2D(2)(last_layer)\n",
    "    \n",
    "    conv = Conv2D(512,(3,3) , padding='valid')(new_last_layer)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(256,(3,3) , padding='valid')(lr)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    another_up_layer = UpSampling2D(2)(lr)\n",
    "    \n",
    "    conv = Conv2D(256,(3,3) , padding='valid')(another_up_layer)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(256,(3,3) , padding='valid')(lr)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(128,(3,3) , strides = (2, 2), padding='valid')(lr)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(64,(3,3) , padding='valid')(lr)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(64,(3,3) , padding='valid')(lr)\n",
    "    conv = Dropout(0.4)(conv)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    lr = LeakyReLU(alpha=0.1)(bn)\n",
    "    \n",
    "    conv = Conv2D(30,(1,1) , padding='same')(lr)\n",
    "#    conv = Dropout(0.4)(conv)\n",
    "#    bn = BatchNormalization()(conv)\n",
    "#    lr = LeakyRelu(alpha=0.1)(bn)\n",
    "\n",
    "    final = Reshape((grid_y_axis,grid_x_axis,num_anchors,info))(conv)\n",
    "\n",
    "    model = Model(inp,final)\n",
    "    features = model.output\n",
    "\n",
    "    return model, features\n",
    "\n",
    "input_size = (target_w, target_h, 3)\n",
    "my_yolo_invoice_model, features_1 = yolo_model(input_size)\n",
    "\n",
    "\n",
    "my_model_1, features_2 = yolo_model(input_size)\n",
    "my_model_2, features_3 = yolo_model(input_size)\n",
    "\n",
    "print(my_model_1.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "my_model_1.compile(optimizer= opt,loss=yolo_my_loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/scar3crow/Dropbox/WorkStation-Subrata/python/venv1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/5\n",
      "28/28 [==============================] - 269s 10s/step - loss: 10310.7928 - accuracy: 0.0768 - val_loss: 9228.9614 - val_accuracy: 0.1407\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 140s 5s/step - loss: 9733.9142 - accuracy: 0.0755 - val_loss: 9493.9355 - val_accuracy: 0.1487\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 135s 5s/step - loss: 9667.6391 - accuracy: 0.0747 - val_loss: 9857.2954 - val_accuracy: 0.1241\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 133s 5s/step - loss: 9296.8830 - accuracy: 0.0716 - val_loss: 9961.8042 - val_accuracy: 0.1152\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 134s 5s/step - loss: 9237.8970 - accuracy: 0.0738 - val_loss: 9854.7388 - val_accuracy: 0.1257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ffa9b4a6940>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_1.fit(X_train ,Y_train ,epochs= 5,batch_size = 4, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "my_model_2.compile(optimizer= opt,loss=yolo_my_loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/5\n",
      "28/28 [==============================] - 732s 26s/step - loss: 10666.9745 - accuracy: 0.1079 - val_loss: 9359.6025 - val_accuracy: 0.0365\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 133s 5s/step - loss: 10244.0806 - accuracy: 0.1169 - val_loss: 9797.1753 - val_accuracy: 0.0254\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 136s 5s/step - loss: 9903.6975 - accuracy: 0.1272 - val_loss: 10586.7803 - val_accuracy: 0.0130\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 134s 5s/step - loss: 9655.2091 - accuracy: 0.1386 - val_loss: 11212.1104 - val_accuracy: 0.0150\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 133s 5s/step - loss: 9311.2352 - accuracy: 0.1396 - val_loss: 11281.1006 - val_accuracy: 0.0344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ffb1bc7cc18>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_2.fit(X_train ,Y_train ,epochs= 5,batch_size = 4, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/20\n",
      "28/28 [==============================] - 126s 5s/step - loss: 9160.9930 - accuracy: 0.1404 - val_loss: 11221.5405 - val_accuracy: 0.0583\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 134s 5s/step - loss: 8766.9420 - accuracy: 0.1396 - val_loss: 11242.6411 - val_accuracy: 0.0669\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 132s 5s/step - loss: 8429.4667 - accuracy: 0.1294 - val_loss: 11125.7871 - val_accuracy: 0.0806\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 135s 5s/step - loss: 8215.1627 - accuracy: 0.1303 - val_loss: 10941.2134 - val_accuracy: 0.0856\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 136s 5s/step - loss: 8834.7207 - accuracy: 0.1207 - val_loss: 10758.3223 - val_accuracy: 0.0722\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 138s 5s/step - loss: 7700.3325 - accuracy: 0.1150 - val_loss: 10238.6450 - val_accuracy: 0.0376\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 134s 5s/step - loss: 7321.8449 - accuracy: 0.1108 - val_loss: 9719.4492 - val_accuracy: 0.0204\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 137s 5s/step - loss: 7298.1205 - accuracy: 0.1034 - val_loss: 8911.6240 - val_accuracy: 0.0220\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 136s 5s/step - loss: 6931.2564 - accuracy: 0.1070 - val_loss: 8506.0593 - val_accuracy: 0.0194\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 138s 5s/step - loss: 7020.2924 - accuracy: 0.1018 - val_loss: 8076.4780 - val_accuracy: 0.0228\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 137s 5s/step - loss: 6708.3109 - accuracy: 0.1006 - val_loss: 7689.7898 - val_accuracy: 0.0239\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 143s 5s/step - loss: 6490.6778 - accuracy: 0.1073 - val_loss: 7019.6689 - val_accuracy: 0.0209\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 140s 5s/step - loss: 6268.4753 - accuracy: 0.0973 - val_loss: 5909.6360 - val_accuracy: 0.0159\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 138s 5s/step - loss: 6099.9956 - accuracy: 0.0957 - val_loss: 5149.6965 - val_accuracy: 0.0146\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 136s 5s/step - loss: 5835.8934 - accuracy: 0.1023 - val_loss: 4802.5261 - val_accuracy: 0.0111\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 143s 5s/step - loss: 5800.1266 - accuracy: 0.0963 - val_loss: 4584.1326 - val_accuracy: 0.0107\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 144s 5s/step - loss: 5498.2051 - accuracy: 0.0977 - val_loss: 4307.8669 - val_accuracy: 0.0098\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 138s 5s/step - loss: 5359.4633 - accuracy: 0.1010 - val_loss: 3948.1255 - val_accuracy: 0.0104\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 136s 5s/step - loss: 5295.9659 - accuracy: 0.0972 - val_loss: 3662.2726 - val_accuracy: 0.0120\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 137s 5s/step - loss: 4927.7019 - accuracy: 0.1016 - val_loss: 3357.2859 - val_accuracy: 0.0104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ffa90724160>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model_2.fit(X_train ,Y_train ,epochs= 20,batch_size = 4, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_sigmoid(x):\n",
    "    result = 1/(1 + np.exp(-x))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "grid_size = [15., 15.]\n",
    "ratio = 480./15.      ## ratio = 32\n",
    "ignore_thresh = 0.5\n",
    "Lambda_Coord = 5.0\n",
    "Lambda_no_obj = 0.5\n",
    "    \n",
    "grid_x = np.arange(grid_size[1])\n",
    "grid_y = np.arange(grid_size[0])\n",
    "    \n",
    "a = np.array(np.meshgrid(grid_x, grid_y))\n",
    "b = np.array(np.meshgrid(grid_x, grid_y))\n",
    "c = np.array(np.meshgrid(grid_x, grid_y))\n",
    "d = np.concatenate((a,b,c), axis = 0)\n",
    "e = d.transpose(2, 1, 0)\n",
    "grid_final = np.reshape(e,[15,15,3,2])\n",
    "\n",
    "print(grid_final[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([85, 86, 87, 88, 89], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "id_train0 = r_new_data.index[r_new_data['img_idx'] == 5] # Finding the index\n",
    "#idd = all_image_line.index[all_image_line[0] == 26]\n",
    "\n",
    "print(id_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " '/home/scar3crow/Downloads/8-6-new-scan/106a.jpg',\n",
       " array([[  2.,   1., 130.,  52.],\n",
       "        [231.,   9., 271.,  30.],\n",
       "        [323.,   9., 373.,  31.],\n",
       "        [230.,  63., 319.,  85.],\n",
       "        [  1.,  53., 155., 125.]], dtype=float32),\n",
       " array([0, 1, 2, 3, 4]),\n",
       " 416,\n",
       " 134]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_line[17] # here box is in x1, y1, x2, y2 format as per original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>img_idx</th>\n",
       "      <th>i_path</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>obj_class</th>\n",
       "      <th>img_wd</th>\n",
       "      <th>img_ht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>106a.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/106a.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>51</td>\n",
       "      <td>vendor</td>\n",
       "      <td>416</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>106a.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/106a.jpg</td>\n",
       "      <td>231</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>invoice</td>\n",
       "      <td>416</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>106a.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/106a.jpg</td>\n",
       "      <td>323</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "      <td>inv_date</td>\n",
       "      <td>416</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>106a.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/106a.jpg</td>\n",
       "      <td>230</td>\n",
       "      <td>63</td>\n",
       "      <td>89</td>\n",
       "      <td>22</td>\n",
       "      <td>po</td>\n",
       "      <td>416</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>106a.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>/home/scar3crow/Downloads/8-6-new-scan/106a.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>154</td>\n",
       "      <td>72</td>\n",
       "      <td>buyer</td>\n",
       "      <td>416</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      img_id  img_idx                                           i_path    x  \\\n",
       "85  106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    2   \n",
       "86  106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  231   \n",
       "87  106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  323   \n",
       "88  106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg  230   \n",
       "89  106a.jpg        5  /home/scar3crow/Downloads/8-6-new-scan/106a.jpg    1   \n",
       "\n",
       "     y  width  height obj_class  img_wd  img_ht  \n",
       "85   1    128      51    vendor     416     134  \n",
       "86   9     40      21   invoice     416     134  \n",
       "87   9     50      22  inv_date     416     134  \n",
       "88  63     89      22        po     416     134  \n",
       "89  53    154      72     buyer     416     134  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_new_data[85:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 2 0\n",
      "9 2 0 1\n",
      "12 2 0 2\n",
      "9 8 0 3\n",
      "2 9 2 4\n",
      "===============================\n",
      "(15, 15, 3, 10)\n",
      "================================\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.15865384 0.1977612  0.30769232 0.38059703 1.         1.\n",
      "  0.         0.         0.         0.        ]]\n",
      "================================\n",
      "[[2. 2.]\n",
      " [2. 2.]\n",
      " [2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "anchors = anchors_wrt_target    ## grid-no.-x, grid_no._y, anchor_no., class_no. = x,y,k,c\n",
    "img_idx, img_resized, y_true, anchor_mask = parse_data(all_image_line[17], class_num, target_size, anchors)\n",
    "print('===============================')\n",
    "print(y_true.shape)\n",
    "print('================================')\n",
    "print(y_true[2,2])\n",
    "print('================================')\n",
    "print(grid_final[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43487748, 0.09272044, 0.0390249 , 0.26069487, 0.22265465,\n",
       "        0.18564138, 0.2278643 , 0.59262076, 0.05990115, 0.57574226],\n",
       "       [0.35897673, 0.37744268, 0.28782252, 0.35605669, 0.02753171,\n",
       "        0.77120674, 0.14989155, 0.67797714, 0.02268381, 0.61713271],\n",
       "       [0.03405847, 0.93673087, 0.89324448, 0.61316689, 0.75676532,\n",
       "        0.28641744, 0.55525129, 0.03295617, 0.14728204, 0.24865604]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.random.rand(15,450)\n",
    "y_pred = np.reshape(y_pred, [15,15,3,10])\n",
    "y_pred[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [1.]] [[1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.60703776 0.52316352]\n",
      " [0.58879271 0.59325616]\n",
      " [0.50851379 0.71843883]]\n",
      "=======================================\n",
      "[[2.60703776 2.52316352]\n",
      " [2.58879271 2.59325616]\n",
      " [2.50851379 2.71843883]]\n",
      "=======================================\n",
      "[[0.17380252 0.1682109 ]\n",
      " [0.17258618 0.17288374]\n",
      " [0.16723425 0.18122926]]\n",
      "=======================================\n",
      "[[0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.15865384 0.1977612 ]]\n",
      "(15, 15, 3, 1) (15, 15, 3, 2) (15, 15, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "loss = tf.zeros(1, dtype='float32')\n",
    "    \n",
    "    \n",
    "#    m = y_true.shape[0]\n",
    "#    m = np.expand_dims(m, axis=-1)\n",
    "#    mf = K.cast(m, dtype='float32')\n",
    "\n",
    "    \n",
    "obj_mask_y = y_true[..., 4:5]\n",
    "#obj_mask = K.cast(obj_mask_y, dtype='float32')\n",
    "print(obj_mask_y[2,2], obj_mask_y[2,9])\n",
    "    \n",
    "#    true_box_wh = y_true[..., 2:4]\n",
    "#    weight = 2 - true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "#    weight = np.expand_dims(weight, axis=-1)\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n",
    "pred_box_xy = K.sigmoid(y_pred[..., :2])\n",
    "pred_box_xy = K.eval(pred_box_xy)\n",
    "print(pred_box_xy[2,2])\n",
    "print('=======================================')\n",
    "                                                            \n",
    "pred_box_xy = pred_box_xy + grid_final  # this gives x & y in no. of cells. x & y w.r.t. target\n",
    "print(pred_box_xy[2,2])                                                            # image = (x & y in no. of cells) / no. of cells\n",
    "print('=======================================')        \n",
    "#    Lambda_Coord = K.cast(Lambda_Coord, dtype = 'float32')\n",
    "pred_box_xy_wrt_target_image = (pred_box_xy * 32) / 480.\n",
    "print(pred_box_xy_wrt_target_image[2,2])                                                            \n",
    "print('=======================================')  \n",
    "true_box_xy_wrt_target_image = y_true[..., :2]\n",
    "print(true_box_xy_wrt_target_image[2,2])\n",
    "    \n",
    "#$ pred_box_xy_wrt_ti = K.cast(pred_box_xy_wrt_target_image, dtype = 'float32')\n",
    "#$ true_box_xy_wrt_ti = K.cast(true_box_xy_wrt_target_image, dtype = 'float32')\n",
    "    \n",
    "#$ xy_arr = K.cast((true_box_xy_wrt_ti - pred_box_xy_wrt_ti), dtype='float32')\n",
    "    \n",
    "#$ xy_loss = K.cast(Lambda_Coord * tf.reduce_sum(tf.square(xy_arr) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "print(obj_mask_y.shape, pred_box_xy_wrt_target_image.shape, true_box_xy_wrt_target_image.shape)    \n",
    "#$ xy_loss = (Lambda_Coord *np.sum(mean_squared_error(true_box_xy_wrt_target_image, pred_box_xy_wrt_target_image) * obj_mask))\n",
    "    \n",
    "#    xy_loss = (Lambda_Coord *np.sum(mean_squared_error(true_box_xy_wrt_ti, pred_box_xy_wrt_ti) * obj_mask*weight)) / m\n",
    "    \n",
    "#    xy_loss = (Lambda_Coord*tf.reduce_sum(tf.square(true_box_xy_wrt_ti - pred_box_xy_wrt_ti) *obj_mask))/m\n",
    "#    wh_loss = tf.reduce_sum(tf.square(true_tw_th - pred_tw_th) * object_mask * box_loss_scale * mix_w) / N\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17380252 -0.1682109 ]\n",
      " [-0.17258618 -0.17288374]\n",
      " [-0.00858041  0.01653194]]\n"
     ]
    }
   ],
   "source": [
    "aaaa = true_box_xy_wrt_target_image -pred_box_xy_wrt_target_image\n",
    "print(aaaa[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [-0.00858041  0.01653194]]\n"
     ]
    }
   ],
   "source": [
    "aaa = true_box_xy_wrt_target_image -(pred_box_xy_wrt_target_image * obj_mask_y)\n",
    "print(aaa[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.02073151e-02 2.82949073e-02]\n",
      " [2.97859897e-02 2.98887890e-02]\n",
      " [7.36234797e-05 2.73304950e-04]]\n"
     ]
    }
   ],
   "source": [
    "bbbb = np.power(aaaa, 2)\n",
    "print(bbbb[2,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [7.36234797e-05 2.73304950e-04]]\n"
     ]
    }
   ],
   "source": [
    "bbb = np.power(aaa, 2)\n",
    "print(bbb[2,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [7.36234797e-05 2.73304950e-04]]\n",
      "=========================\n",
      "[[0.18302608 0.2386279 ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "=========================\n",
      "[[0.44309909 0.46891106]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "=========================\n",
      "[[0.00828158 0.00866909]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "=========================\n",
      "[[0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.20149265 0.23503648]]\n",
      "=========================\n",
      "(15, 15, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "cccc = bbbb * obj_mask_y\n",
    "print(cccc[2,2])\n",
    "print('=========================')\n",
    "print(cccc[2,9])\n",
    "print('=========================')\n",
    "print(cccc[2,12])\n",
    "print('=========================')\n",
    "print(cccc[8, 9])\n",
    "print('=========================')\n",
    "print(cccc[9, 2])\n",
    "print('=========================')\n",
    "\n",
    "print(cccc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [7.36234797e-05 2.73304950e-04]]\n",
      "=========================\n",
      "[[0.18302608 0.2386279 ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "=========================\n",
      "[[0.44309909 0.46891106]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "=========================\n",
      "[[0.00828158 0.00866909]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "=========================\n",
      "[[0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.20149265 0.23503648]]\n",
      "=========================\n",
      "(15, 15, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(bbb[2,2])\n",
    "print('=========================')\n",
    "print(bbb[2,9])\n",
    "print('=========================')\n",
    "print(bbb[2,12])\n",
    "print('=========================')\n",
    "print(bbb[8, 9])\n",
    "print('=========================')\n",
    "print(bbb[9, 2])\n",
    "print('=========================')\n",
    "\n",
    "print(bbb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7874908516137276"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dddd = np.sum(cccc)\n",
    "dddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7874908516137276"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd = np.sum(bbb)\n",
    "ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "=========================\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "=========================\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "=========================\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "=========================\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "=========================\n",
      "(15, 15, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "print(cccc[2,3])\n",
    "print('=========================')\n",
    "print(cccc[2,10])\n",
    "print('=========================')\n",
    "print(cccc[2,11])\n",
    "print('=========================')\n",
    "print(cccc[8, 10])\n",
    "print('=========================')\n",
    "print(cccc[9, 3])\n",
    "print('=========================')\n",
    "\n",
    "print(cccc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [1.]] [[1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[1.03979638 1.29783159]\n",
      " [1.3335206  1.42768849]\n",
      " [2.44304321 1.84626909]]\n",
      "=======================================\n",
      "[[[[0.15625    0.11904762]\n",
      "   [0.5625     0.26746644]\n",
      "   [0.37980769 0.36309524]]]]\n",
      "=======================================\n",
      "[[0.16246818 0.15450376]\n",
      " [0.75010534 0.38185875]\n",
      " [0.92788661 0.67037151]]\n",
      "=======================================\n",
      "[[0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.30769232 0.38059703]]\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "loss = tf.zeros(1, dtype='float32')\n",
    "    \n",
    "    \n",
    "#    m = y_true.shape[0]\n",
    "#    m = np.expand_dims(m, axis=-1)\n",
    "#    mf = K.cast(m, dtype='float32')\n",
    "\n",
    "    \n",
    "obj_mask_y = y_true[..., 4:5]\n",
    "#obj_mask = K.cast(obj_mask_y, dtype='float32')\n",
    "print(obj_mask_y[2,2], obj_mask_y[2,9])\n",
    "    \n",
    "#    true_box_wh = y_true[..., 2:4]\n",
    "#    weight = 2 - true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "#    weight = np.expand_dims(weight, axis=-1)\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n",
    "\n",
    "\n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++    \n",
    "pred_box_wdht = np.exp(y_pred[..., 2:4])\n",
    "print(pred_box_wdht[2,2])\n",
    "print('=======================================')\n",
    "anchors = np.reshape(anchors_wrt_target, [1,1,3,2])/480.\n",
    "print(anchors)\n",
    "print('=======================================')\n",
    "pred_box_wdht = np.exp(y_pred[..., 2:4]) * (anchors_wrt_target/480.)\n",
    "print(pred_box_wdht[2,2])\n",
    "print('=======================================')\n",
    "#$    pred_box_wh = K.cast(pred_box_wdht, dtype = 'float32')\n",
    "true_box_wdht = y_true[..., 2:4]\n",
    "#$    true_box_wh = K.cast(true_box_wdht, dtype = 'float32')\n",
    "print(true_box_wdht[2,2])\n",
    "print('=======================================')\n",
    "    \n",
    "#    wh_arr = K.cast((K.sqrt(true_box_wh) - K.sqrt(pred_box_wh)), dtype='float32')\n",
    "    \n",
    "#    wh_loss = K.cast(Lambda_Coord * tf.reduce_sum(tf.square(wh_arr) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16246818 -0.15450376]\n",
      " [-0.75010534 -0.38185875]\n",
      " [-0.62019429 -0.28977449]]\n"
     ]
    }
   ],
   "source": [
    "ffff = true_box_wdht - pred_box_wdht\n",
    "print(ffff[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02639591 0.02387141]\n",
      " [0.56265802 0.14581611]\n",
      " [0.38464095 0.08396925]]\n"
     ]
    }
   ],
   "source": [
    "gggg = np.power(ffff, 2)\n",
    "print(gggg[2,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.38464095 0.08396925]]\n",
      "=========================\n",
      "[[0.09631664 0.0145423 ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "=========================\n",
      "[[0.00146837 0.0007298 ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "=========================\n",
      "[[0.00877394 0.00042433]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]]\n",
      "=========================\n",
      "[[0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.26326866 0.11321882]]\n",
      "=========================\n",
      "(15, 15, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "hhhh = gggg * obj_mask_y\n",
    "print(hhhh[2,2])\n",
    "print('=========================')\n",
    "print(hhhh[2,9])\n",
    "print('=========================')\n",
    "print(hhhh[2,12])\n",
    "print('=========================')\n",
    "print(hhhh[8, 9])\n",
    "print('=========================')\n",
    "print(hhhh[9, 2])\n",
    "print('=========================')\n",
    "\n",
    "print(hhhh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967353063197183"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jjjj = np.sum(hhhh)\n",
    "jjjj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ethanyanjiali/deep-vision/blob/master/YOLO/tensorflow/utils.py\n",
    "\n",
    "def xywh_go_x1y1x2y2(box):\n",
    "    xy = box[..., 0:2]\n",
    "    wh = box[..., 2:4]\n",
    "\n",
    "    x1y1 = xy - wh / 2\n",
    "    x2y2 = xy + wh / 2\n",
    "\n",
    "    y_box = np.concatenate([x1y1, x2y2], axis=-1)\n",
    "    return y_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22265465]\n",
      " [0.02753171]\n",
      " [0.75676532]]\n",
      "============================================================\n",
      "[[0.55543484]\n",
      " [0.50688249]\n",
      " [0.68065104]]\n",
      "============================================================\n",
      "[[0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.15865384 0.1977612 ]]\n",
      "[[0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.30769232 0.38059703]]\n",
      "============================================================\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.15865384 0.1977612  0.30769232 0.38059703]]\n",
      "============================================================\n",
      "[[0.17380252 0.1682109  0.16246818 0.15450376]\n",
      " [0.17258618 0.17288374 0.75010534 0.38185875]\n",
      " [0.16723425 0.18122926 0.92788661 0.67037151]]\n",
      "============================================================\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.00480768 0.00746268 0.3125     0.3880597 ]]\n",
      "============================================================\n",
      "[[ 0.09256843  0.09095902  0.25503661  0.24546278]\n",
      " [-0.20246649 -0.01804563  0.54763885  0.36381312]\n",
      " [-0.29670905 -0.1539565   0.63117756  0.51641501]]\n",
      "============================================================\n",
      "(15, 15, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_obj = y_pred[..., 4:5]\n",
    "print(pred_obj[2,2])\n",
    "print('============================================================')\n",
    "\n",
    "pred_obj_mask = my_sigmoid(y_pred[..., 4:5])  # shape = 28, 15, 15, 3, 1\n",
    "\n",
    "print(pred_obj_mask[2,2])\n",
    "print('============================================================')\n",
    "\n",
    "print(true_box_xy_wrt_target_image[2, 2])\n",
    "print(true_box_wdht[2,2])\n",
    "print('============================================================')\n",
    "\n",
    "true_box_wrt_ti = np.concatenate([true_box_xy_wrt_target_image, true_box_wdht], axis = -1)  ## in x,y,w,h format\n",
    "print(true_box_wrt_ti[2,2])\n",
    "print('============================================================')\n",
    "\n",
    "pred_box_wrt_ti = np.concatenate([pred_box_xy_wrt_target_image, pred_box_wdht], axis = -1)  ## in x,y,w,h format\n",
    "print(pred_box_wrt_ti[2,2])\n",
    "print('============================================================')\n",
    "    \n",
    "true_box_wrt_ti = xywh_go_x1y1x2y2(true_box_wrt_ti)  ## converted to x1,y1,x2,y2 format\n",
    "pred_box_wrt_ti = xywh_go_x1y1x2y2(pred_box_wrt_ti)  ## converted to x1,y1,x2,y2 format\n",
    "\n",
    "print(true_box_wrt_ti[2,2])\n",
    "print('============================================================')\n",
    "print(pred_box_wrt_ti[2,2])\n",
    "print('============================================================')\n",
    "\n",
    "print(true_box_wrt_ti.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#    ignore_mask = calc_ignore_mask(ignore_thresh, true_box_wrt_ti, pred_box_wrt_ti)\n",
    "    \n",
    "#    ignore_mask = K.cast(ignore_mask, dtype = 'float32')                               \n",
    "\n",
    "#    obj_loss = K.cast(K.sum(K.binary_crossentropy(obj_mask, pred_obj_mask) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "#    no_obj_mask = 1. - obj_mask_y\n",
    "#    no_obj_mask = K.cast(no_obj_mask, dtype  = 'float32')\n",
    "    \n",
    "#    noobj_loss = K.cast(Lambda_no_obj * K.sum(binary_cross_entropy(obj_mask, pred_obj_mask) * no_obj_mask * ignore_mask), dtype='float32')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_iou(box_a, box_b):\n",
    "    \"\"\"\n",
    "    calculate iou between box_a and multiple box_b in a broadcast way\n",
    "    inputs: box_a: a tensor full of boxes, eg. (B, N, 4), box is in x1y1x2y2\n",
    "            box_b: another tensor full of boxes, eg. (B, M, 4)\n",
    "    \"\"\"\n",
    "\n",
    "    # (B, N, 1, 4)\n",
    "    box_a = tf.expand_dims(box_a, -2)\n",
    "    # (B, 1, M, 4)\n",
    "    box_b = tf.expand_dims(box_b, -3)\n",
    "    # (B, N, M, 4)\n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_a), tf.shape(box_b))\n",
    "\n",
    "    # (B, N, M, 4)\n",
    "    # (B, N, M, 4)\n",
    "    box_a = tf.broadcast_to(box_a, new_shape)\n",
    "    box_b = tf.broadcast_to(box_b, new_shape)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    al, at, ar, ab = tf.split(box_a, 4, -1)\n",
    "    bl, bt, br, bb = tf.split(box_b, 4, -1)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    left = tf.math.maximum(al, bl)\n",
    "    right = tf.math.minimum(ar, br)\n",
    "    top = tf.math.maximum(at, bt)\n",
    "    bot = tf.math.minimum(ab, bb)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    iw = tf.clip_by_value(right - left, 0, 1)\n",
    "    ih = tf.clip_by_value(bot - top, 0, 1)\n",
    "    i = iw * ih\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "    area_a = (ar - al) * (ab - at)\n",
    "    area_b = (br - bl) * (bb - bt)\n",
    "    union = area_a + area_b - i\n",
    "\n",
    "    # (B, N, M)\n",
    "    iou = tf.squeeze(i / (union + 1e-7), axis=-1)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def calc_ignore_mask(ignore_thresh, true_box, pred_box):\n",
    "    \n",
    "        # YOLOv3:\n",
    "        # \"If the bounding box prior is not the best but does overlap a ground\n",
    "        # truth object by more than some threshold we ignore the prediction,\n",
    "        # following [17]. We use the threshold of .5.\"\n",
    "        # calculate the iou for each pair of pred bbox and true bbox, then find the best among them\n",
    "\n",
    "        # (None, 13, 13, 3, 4)\n",
    "        \n",
    "        true_box_reorganised = xywh_to_x1y1x2y2(true_box)  # reorganised to x1, y1, x2, y2\n",
    "        pred_box_reorganised = xywh_to_x1y1x2y2(pred_box)\n",
    "        \n",
    "        true_box_shape = tf.shape(true_box_reorganised)  \n",
    "        # (None, 13, 13, 3, 4)\n",
    "        pred_box_shape = tf.shape(pred_box_reorganised)  \n",
    "        # (None, 507, 4)\n",
    "        true_box_reorganised = tf.reshape(true_box_reorganised, [true_box_shape[0], -1, 4])\n",
    "        # sort true_box to have non-zero boxes rank first\n",
    "        true_box_reorganised = tf.sort(true_box_reorganised, axis=1, direction=\"DESCENDING\")\n",
    "        # (None, 100, 4)\n",
    "        # only use maximum 100 boxes per groundtruth to calcualte IOU, otherwise\n",
    "        # GPU emory comsumption would explode for a matrix like (16, 52*52*3, 52*52*3, 4)\n",
    "        true_box_reorganised = true_box_reorganised[:, 0:100, :]\n",
    "        # (None, 507, 4)\n",
    "        pred_box_reorganised = tf.reshape(pred_box_reorganised, [pred_box_shape[0], -1, 4])\n",
    "\n",
    "        # https://github.com/dmlc/gluon-cv/blob/06bb7ec2044cdf3f433721be9362ab84b02c5a90/gluoncv/model_zoo/yolo/yolo_target.py#L198\n",
    "        # (None, 507, 507)\n",
    "        iou = broadcast_iou(pred_box_reorganised, true_box_reorganised)\n",
    "        # (None, 507)\n",
    "        best_iou = tf.reduce_max(iou, axis=-1)\n",
    "        # (None, 13, 13, 3)\n",
    "        best_iou = tf.reshape(best_iou, [pred_box_shape[0], pred_box_shape[1], pred_box_shape[2], pred_box_shape[3]])\n",
    "        # ignore_mask = 1 => don't ignore\n",
    "        # ignore_mask = 0 => should ignore\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "        # (None, 13, 13, 3, 1)\n",
    "        ignore_mask = tf.expand_dims(ignore_mask, axis=-1)\n",
    "        \n",
    "        return ignore_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 15, 3, 4)\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.00480768 0.00746268 0.3125     0.3880597 ]]\n",
      "===========================================\n",
      "(15, 45, 4)\n",
      "[0.00480768 0.00746268 0.3125     0.3880597 ]\n",
      "[0.55288464 0.47014928 0.7668269  0.63432837]\n",
      "===========================================\n",
      "(15, 45, 4)\n",
      "[0.7764423  0.06716419 0.8966346  0.3880597 ]\n",
      "[0.55288464 0.47014928 0.7668269  0.63432837]\n",
      "===========================================\n",
      "(15, 15, 3, 4)\n",
      "[[ 0.09256843  0.09095902  0.25503661  0.24546278]\n",
      " [-0.20246649 -0.01804563  0.54763885  0.36381312]\n",
      " [-0.29670905 -0.1539565   0.63117756  0.51641501]]\n",
      "===========================================\n",
      "(15, 45, 4)\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "(15, 45, 4)\n",
      "===========================================\n",
      "pred_box shape =  (15, 45, 1, 4)\n",
      "===========================================\n",
      "true_box shape =  (15, 1, 45, 4)\n",
      "new shape =  [15 45 45  4]\n",
      "true_box shape =  (15, 45, 45, 4)\n",
      "[[0.7764423  0.06716419 0.8966346  0.3880597 ]\n",
      " [0.55528843 0.06716419 0.6514423  0.2313433 ]\n",
      " [0.00480768 0.00746268 0.3125     0.22388062]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "===========================================\n",
      "(15, 45, 45)\n",
      "[0.         0.         0.31941167 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "best =  (15, 45)\n",
      "best =  [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.31941167 0.1484363  0.11740641 0.4963582  0.13822661 0.11516222\n",
      "  0.30808225 0.23247956 0.10705313 0.20385127 0.09111996 0.2318686\n",
      "  0.08716069 0.17362991 0.10847124 0.         0.04260801 0.13948561\n",
      "  0.         0.0387163  0.         0.         0.         0.02871302\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00388883 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00768076 0.         0.         0.0234597  0.\n",
      "  0.         0.03743737 0.02801621 0.03265417 0.06331677 0.09890786\n",
      "  0.13609056 0.0735504  0.13751538 0.3565507  0.09082769 0.18423894\n",
      "  0.30041724 0.13421321 0.07170524 0.17676996 0.0560712  0.05629238\n",
      "  0.         0.0811279  0.09036271 0.         0.0601502  0.09673584\n",
      "  0.         0.0712884  0.09048697 0.         0.         0.03509943\n",
      "  0.         0.         0.02778011]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0279248  0.04215166 0.         0.0228469  0.01498918\n",
      "  0.         0.05393586 0.         0.         0.10110861 0.08518045\n",
      "  0.         0.12846251 0.         0.         0.11978302 0.\n",
      "  0.         0.2082091  0.08403183 0.         0.09204015 0.\n",
      "  0.         0.21353522 0.08229756 0.         0.15810756 0.09590296\n",
      "  0.         0.16865684 0.04816975 0.         0.03479904 0.02273013\n",
      "  0.         0.08595777 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#$ ignore_mask = calc_ignore_mask(ignore_thresh, true_box_wrt_ti, pred_box_wrt_ti)\n",
    "print(true_box_wrt_ti.shape)  # shape = 15, 15, 3, 4\n",
    "print(true_box_wrt_ti[2,2])  # (2,2-anchor-2), (2,9-anchor-0), (2,12-anchor-0), (8,9-anchor-0), (9,2-anchor-2)\n",
    "print('===========================================')\n",
    "true_box_reorganised = np.reshape(true_box_wrt_ti, [true_box_wrt_ti.shape[0], -1, 4]) # change shape to 15, 45, 4\n",
    "print(true_box_reorganised.shape)\n",
    "print(true_box_reorganised[2,2*3+2])  # '+2' since anchor[2]\n",
    "print(true_box_reorganised[8, 9*3+0]) # '+0' since anchor[0]\n",
    "print('===========================================')\n",
    "inter_true = tf.sort(true_box_reorganised, axis=1, direction=\"DESCENDING\") # sorting in descending order\n",
    "true_box_reorganised = K.eval(inter_true)\n",
    "print(true_box_reorganised.shape)\n",
    "print(true_box_reorganised[2,0])\n",
    "print(true_box_reorganised[8,0])\n",
    "print('===========================================')\n",
    "print(pred_box_wrt_ti.shape)  # shape = 15, 15, 3, 4\n",
    "print(pred_box_wrt_ti[2,2])  # (2,2-anchor-2), (2,9-anchor-0), (2,12-anchor-0), (8,9-anchor-0), (9,2-anchor-2)\n",
    "print('===========================================')\n",
    "\n",
    "pred_box_reorganised = np.reshape(pred_box_wrt_ti, [pred_box_wrt_ti.shape[0], -1, 4])\n",
    "print(pred_box_reorganised.shape)\n",
    "print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "\n",
    "#$$$$$  iou = broadcast_iou(pred_box_reorganised, true_box_reorganised)\n",
    "\n",
    "# (B, N, 1, 4)\n",
    "\n",
    "box_a = pred_box_reorganised\n",
    "box_b = true_box_reorganised\n",
    "print(box_b.shape)\n",
    "print('===========================================')\n",
    "\n",
    "box_a = np.expand_dims(box_a, -2)\n",
    "    # (B, 1, M, 4)\n",
    "box_b = np.expand_dims(box_b, -3)\n",
    "print('pred_box shape = ', box_a.shape)\n",
    "print('===========================================')\n",
    "print('true_box shape = ', box_b.shape)\n",
    "print\n",
    "\n",
    "\n",
    "    # (B, N, M, 4)\n",
    "new_shape_inter = tf.broadcast_dynamic_shape(tf.shape(box_a), tf.shape(box_b))\n",
    "new_shape = K.eval(new_shape_inter)\n",
    "print('new shape = ', new_shape)\n",
    "\n",
    "    # (B, N, M, 4)\n",
    "    # (B, N, M, 4)\n",
    "box_a = tf.broadcast_to(box_a, new_shape)\n",
    "box_b = tf.broadcast_to(box_b, new_shape)\n",
    "\n",
    "print('true_box shape = ', K.eval(box_b).shape)\n",
    "print( K.eval(box_b)[2,0])\n",
    "print('===========================================')\n",
    "\n",
    "box_a = K.cast(box_a, dtype = 'float32')\n",
    "box_b = K.cast(box_b, dtype = 'float32')\n",
    "\n",
    "\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "al, at, ar, ab = tf.split(box_a, 4, -1)\n",
    "bl, bt, br, bb = tf.split(box_b, 4, -1)\n",
    "#print(K.eval(bl).shape)\n",
    "#print(K.eval(bl)[2,0])\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "left = tf.math.maximum(al, bl)\n",
    "right = tf.math.minimum(ar, br)\n",
    "top = tf.math.maximum(at, bt)\n",
    "bot = tf.math.minimum(ab, bb)\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "iw = tf.clip_by_value(right - left, 0, 1)\n",
    "ih = tf.clip_by_value(bot - top, 0, 1)\n",
    "i = iw * ih\n",
    "\n",
    "    # (B, N, M, 1)\n",
    "area_a = (ar - al) * (ab - at)\n",
    "area_b = (br - bl) * (bb - bt)\n",
    "union = area_a + area_b - i\n",
    "\n",
    "    # (B, N, M)\n",
    "iou = tf.squeeze(i / (union + 1e-7), axis=-1)\n",
    "print(K.eval(iou).shape)\n",
    "print(K.eval(iou)[2,0])\n",
    "\n",
    "best_iou = tf.reduce_max(iou, axis=-1)\n",
    "print('best = ', K.eval(best_iou).shape)\n",
    "print('best = ', K.eval(best_iou))\n",
    "\n",
    "        # (None, 13, 13, 3)\n",
    "#        best_iou = tf.reshape(best_iou, [pred_box_shape[0], pred_box_shape[1], pred_box_shape[2], pred_box_shape[3]])\n",
    "        # ignore_mask = 1 => don't ignore\n",
    "        # ignore_mask = 0 => should ignore\n",
    "#        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "        # (None, 13, 13, 3, 1)\n",
    "#        ignore_mask = tf.expand_dims(ignore_mask, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#    ignore_mask = K.cast(ignore_mask, dtype = 'float32')                               \n",
    "\n",
    "#    obj_loss = K.cast(K.sum(K.binary_crossentropy(obj_mask, pred_obj_mask) * obj_mask), dtype = 'float32')\n",
    "    \n",
    "#    no_obj_mask = 1. - obj_mask_y\n",
    "#    no_obj_mask = K.cast(no_obj_mask, dtype  = 'float32')\n",
    "    \n",
    "#    noobj_loss = K.cast(Lambda_no_obj * K.sum(binary_cross_entropy(obj_mask, pred_obj_mask) * no_obj_mask * ignore_mask), dtype='float32')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.0279248 , 0.04215166, 0.        ,\n",
       "       0.0228469 , 0.01498918, 0.        , 0.05393586, 0.        ,\n",
       "       0.        , 0.10110861, 0.08518045, 0.        , 0.12846251,\n",
       "       0.        , 0.        , 0.11978302, 0.        , 0.        ,\n",
       "       0.2082091 , 0.08403183, 0.        , 0.09204015, 0.        ,\n",
       "       0.        , 0.21353522, 0.08229756, 0.        , 0.15810756,\n",
       "       0.09590296, 0.        , 0.16865684, 0.04816975, 0.        ,\n",
       "       0.03479904, 0.02273013, 0.        , 0.08595777, 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrrr = K.eval(best_iou)\n",
    "rrrr[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.00480768, 0.00746268, 0.3125    , 0.3880597 ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.55528843, 0.06716419, 0.6514423 , 0.22388062],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.7764423 , 0.06716419, 0.8966346 , 0.2313433 ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_box_reorganised[2]  ## result before sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 45, 4)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qqqq[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 4)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_box_reorganised[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.  ,   2.8 ,  10.  ,  26.9 ,  62.3 , 166.32], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
    "b = tf.sort(a,axis=-1,direction='ASCENDING',name=None)\n",
    "c = tf.keras.backend.eval(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 45, 4)\n",
      "(15, 45, 4)\n"
     ]
    }
   ],
   "source": [
    "a = true_box_reorganised\n",
    "b = tf.sort(a,axis=1,direction='DESCENDING',name=None)\n",
    "c = K.eval(b)\n",
    "print(a.shape)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55288464, 0.47014928, 0.7668269 , 0.63432837],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(a), type(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
