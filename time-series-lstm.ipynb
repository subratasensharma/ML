{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://machinelearningmastery.com\n",
    "## /how-to-develop-lstm-models-for-multi-step-time-series-forecasting-of-household-power-consumption/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data\n",
    "dataset = pd.read_csv('household_power_consumption.txt', sep=';', header=0, low_memory=False, \\\n",
    "                   infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.840</td>\n",
       "      <td>18.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.290</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.680</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Global_active_power Global_reactive_power  Voltage  \\\n",
       "datetime                                                                 \n",
       "2006-12-16 17:24:00               4.216                 0.418  234.840   \n",
       "2006-12-16 17:25:00               5.360                 0.436  233.630   \n",
       "2006-12-16 17:26:00               5.374                 0.498  233.290   \n",
       "2006-12-16 17:27:00               5.388                 0.502  233.740   \n",
       "2006-12-16 17:28:00               3.666                 0.528  235.680   \n",
       "\n",
       "                    Global_intensity Sub_metering_1 Sub_metering_2  \\\n",
       "datetime                                                             \n",
       "2006-12-16 17:24:00           18.400          0.000          1.000   \n",
       "2006-12-16 17:25:00           23.000          0.000          1.000   \n",
       "2006-12-16 17:26:00           23.000          0.000          2.000   \n",
       "2006-12-16 17:27:00           23.000          0.000          1.000   \n",
       "2006-12-16 17:28:00           15.800          0.000          1.000   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "datetime                             \n",
       "2006-12-16 17:24:00            17.0  \n",
       "2006-12-16 17:25:00            16.0  \n",
       "2006-12-16 17:26:00            17.0  \n",
       "2006-12-16 17:27:00            17.0  \n",
       "2006-12-16 17:28:00            17.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It is a multivariate series comprised of seven variables (besides the date and time); they are:\n",
    "\n",
    "## global_active_power: The total active power consumed by the household (kilowatts).\n",
    "## global_reactive_power: The total reactive power consumed by the household (kilowatts).\n",
    "## voltage: Average voltage (volts).\n",
    "## global_intensity: Average current intensity (amps).\n",
    "## sub_metering_1: Active energy for kitchen (watt-hours of active energy).\n",
    "## sub_metering_2: Active energy for laundry (watt-hours of active energy).\n",
    "## sub_metering_3: Active energy for climate control systems (watt-hours of active energy).\n",
    "\n",
    "## Active and reactive energy refer to the technical details of alternative current."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2075259 entries, 2006-12-16 17:24:00 to 2010-11-26 21:02:00\n",
      "Data columns (total 7 columns):\n",
      "Global_active_power      object\n",
      "Global_reactive_power    object\n",
      "Voltage                  object\n",
      "Global_intensity         object\n",
      "Sub_metering_1           object\n",
      "Sub_metering_2           object\n",
      "Sub_metering_3           float64\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 126.7+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2075259\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:58:00</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.000</td>\n",
       "      <td>240.430</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:59:00</th>\n",
       "      <td>0.944</td>\n",
       "      <td>0.000</td>\n",
       "      <td>240.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 21:00:00</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.820</td>\n",
       "      <td>3.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 21:01:00</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.700</td>\n",
       "      <td>3.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 21:02:00</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.550</td>\n",
       "      <td>3.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Global_active_power Global_reactive_power  Voltage  \\\n",
       "datetime                                                                 \n",
       "2010-11-26 20:58:00               0.946                 0.000  240.430   \n",
       "2010-11-26 20:59:00               0.944                 0.000  240.000   \n",
       "2010-11-26 21:00:00               0.938                 0.000  239.820   \n",
       "2010-11-26 21:01:00               0.934                 0.000  239.700   \n",
       "2010-11-26 21:02:00               0.932                 0.000  239.550   \n",
       "\n",
       "                    Global_intensity Sub_metering_1 Sub_metering_2  \\\n",
       "datetime                                                             \n",
       "2010-11-26 20:58:00            4.000          0.000          0.000   \n",
       "2010-11-26 20:59:00            4.000          0.000          0.000   \n",
       "2010-11-26 21:00:00            3.800          0.000          0.000   \n",
       "2010-11-26 21:01:00            3.800          0.000          0.000   \n",
       "2010-11-26 21:02:00            3.800          0.000          0.000   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "datetime                             \n",
       "2010-11-26 20:58:00             0.0  \n",
       "2010-11-26 20:59:00             0.0  \n",
       "2010-11-26 21:00:00             0.0  \n",
       "2010-11-26 21:01:00             0.0  \n",
       "2010-11-26 21:02:00             0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2075259\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2075259 entries, 2006-12-16 17:24:00 to 2010-11-26 21:02:00\n",
      "Data columns (total 7 columns):\n",
      "Global_active_power      float32\n",
      "Global_reactive_power    float32\n",
      "Voltage                  float32\n",
      "Global_intensity         float32\n",
      "Sub_metering_1           float32\n",
      "Sub_metering_2           float32\n",
      "Sub_metering_3           float32\n",
      "dtypes: float32(7)\n",
      "memory usage: 71.2 MB\n"
     ]
    }
   ],
   "source": [
    "# mark all missing values indicated with a ‘?‘ character with a NaN value.\n",
    "\n",
    "dataset.replace('?', 'nan', inplace=True)\n",
    "\n",
    "# make dataset numeric\n",
    "\n",
    "dataset = dataset.astype('float32')\n",
    "\n",
    "print(len(dataset))\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075259, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We also need to fill in the missing values now that they have been marked.\n",
    "\n",
    "## A very simple approach would be to copy the observation from the same time the day before. We can implement\n",
    "## this in a function named fill_missing() that will take the NumPy array of the data and copy values from exactly\n",
    "## 24 hours ago.\n",
    "\n",
    "def fill_missing(values):\n",
    "    one_day = 60 * 24\n",
    "    for row in range(values.shape[0]):\n",
    "        for col in range(values.shape[1]):\n",
    "            if values[row, col] == 'nan':\n",
    "                values[row, col] = values[row - one_day, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_missing(dataset.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.216,   0.418, 234.84 , ...,   0.   ,   1.   ,  17.   ],\n",
       "       [  5.36 ,   0.436, 233.63 , ...,   0.   ,   1.   ,  16.   ],\n",
       "       [  5.374,   0.498, 233.29 , ...,   0.   ,   2.   ,  17.   ],\n",
       "       ...,\n",
       "       [  0.938,   0.   , 239.82 , ...,   0.   ,   0.   ,   0.   ],\n",
       "       [  0.934,   0.   , 239.7  , ...,   0.   ,   0.   ,   0.   ],\n",
       "       [  0.932,   0.   , 239.55 , ...,   0.   ,   0.   ,   0.   ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.839996</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630005</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.289993</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740005</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.679993</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:29:00</th>\n",
       "      <td>3.520</td>\n",
       "      <td>0.522</td>\n",
       "      <td>235.020004</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:30:00</th>\n",
       "      <td>3.702</td>\n",
       "      <td>0.520</td>\n",
       "      <td>235.089996</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:31:00</th>\n",
       "      <td>3.700</td>\n",
       "      <td>0.520</td>\n",
       "      <td>235.220001</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:32:00</th>\n",
       "      <td>3.668</td>\n",
       "      <td>0.510</td>\n",
       "      <td>233.990005</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:33:00</th>\n",
       "      <td>3.662</td>\n",
       "      <td>0.510</td>\n",
       "      <td>233.860001</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:34:00</th>\n",
       "      <td>4.448</td>\n",
       "      <td>0.498</td>\n",
       "      <td>232.860001</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:35:00</th>\n",
       "      <td>5.412</td>\n",
       "      <td>0.470</td>\n",
       "      <td>232.779999</td>\n",
       "      <td>23.200001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:36:00</th>\n",
       "      <td>5.224</td>\n",
       "      <td>0.478</td>\n",
       "      <td>232.990005</td>\n",
       "      <td>22.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:37:00</th>\n",
       "      <td>5.268</td>\n",
       "      <td>0.398</td>\n",
       "      <td>232.910004</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:38:00</th>\n",
       "      <td>4.054</td>\n",
       "      <td>0.422</td>\n",
       "      <td>235.240005</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:39:00</th>\n",
       "      <td>3.384</td>\n",
       "      <td>0.282</td>\n",
       "      <td>237.139999</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:40:00</th>\n",
       "      <td>3.270</td>\n",
       "      <td>0.152</td>\n",
       "      <td>236.729996</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:41:00</th>\n",
       "      <td>3.430</td>\n",
       "      <td>0.156</td>\n",
       "      <td>237.059998</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:42:00</th>\n",
       "      <td>3.266</td>\n",
       "      <td>0.000</td>\n",
       "      <td>237.130005</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:43:00</th>\n",
       "      <td>3.728</td>\n",
       "      <td>0.000</td>\n",
       "      <td>235.839996</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:44:00</th>\n",
       "      <td>5.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>232.690002</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:45:00</th>\n",
       "      <td>7.706</td>\n",
       "      <td>0.000</td>\n",
       "      <td>230.979996</td>\n",
       "      <td>33.200001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:46:00</th>\n",
       "      <td>7.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>232.210007</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:47:00</th>\n",
       "      <td>5.174</td>\n",
       "      <td>0.000</td>\n",
       "      <td>234.190002</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:48:00</th>\n",
       "      <td>4.474</td>\n",
       "      <td>0.000</td>\n",
       "      <td>234.960007</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:49:00</th>\n",
       "      <td>3.248</td>\n",
       "      <td>0.000</td>\n",
       "      <td>236.660004</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:50:00</th>\n",
       "      <td>3.236</td>\n",
       "      <td>0.000</td>\n",
       "      <td>235.839996</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:51:00</th>\n",
       "      <td>3.228</td>\n",
       "      <td>0.000</td>\n",
       "      <td>235.600006</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:52:00</th>\n",
       "      <td>3.258</td>\n",
       "      <td>0.000</td>\n",
       "      <td>235.490005</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:53:00</th>\n",
       "      <td>3.178</td>\n",
       "      <td>0.000</td>\n",
       "      <td>235.279999</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:33:00</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.000</td>\n",
       "      <td>240.279999</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:34:00</th>\n",
       "      <td>0.968</td>\n",
       "      <td>0.000</td>\n",
       "      <td>237.570007</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:35:00</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.000</td>\n",
       "      <td>238.009995</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:36:00</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.000</td>\n",
       "      <td>238.070007</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:37:00</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.000</td>\n",
       "      <td>237.899994</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:38:00</th>\n",
       "      <td>0.976</td>\n",
       "      <td>0.096</td>\n",
       "      <td>236.970001</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:39:00</th>\n",
       "      <td>0.984</td>\n",
       "      <td>0.100</td>\n",
       "      <td>238.160004</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:40:00</th>\n",
       "      <td>0.986</td>\n",
       "      <td>0.102</td>\n",
       "      <td>238.919998</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:41:00</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.106</td>\n",
       "      <td>239.570007</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:42:00</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.106</td>\n",
       "      <td>239.600006</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:43:00</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.106</td>\n",
       "      <td>239.639999</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:44:00</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.102</td>\n",
       "      <td>238.690002</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:45:00</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.092</td>\n",
       "      <td>238.320007</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:46:00</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.000</td>\n",
       "      <td>238.529999</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:47:00</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>238.710007</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:48:00</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.250000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:49:00</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.000</td>\n",
       "      <td>238.160004</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:50:00</th>\n",
       "      <td>1.198</td>\n",
       "      <td>0.128</td>\n",
       "      <td>238.110001</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:51:00</th>\n",
       "      <td>1.024</td>\n",
       "      <td>0.106</td>\n",
       "      <td>238.839996</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:52:00</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.050003</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:53:00</th>\n",
       "      <td>0.944</td>\n",
       "      <td>0.000</td>\n",
       "      <td>238.720001</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:54:00</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.309998</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:55:00</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.740005</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:56:00</th>\n",
       "      <td>0.942</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.410004</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:57:00</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.000</td>\n",
       "      <td>240.330002</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:58:00</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.000</td>\n",
       "      <td>240.429993</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 20:59:00</th>\n",
       "      <td>0.944</td>\n",
       "      <td>0.000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 21:00:00</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.820007</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 21:01:00</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.699997</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 21:02:00</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.550003</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2075259 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power     Voltage  \\\n",
       "datetime                                                                      \n",
       "2006-12-16 17:24:00                4.216                  0.418  234.839996   \n",
       "2006-12-16 17:25:00                5.360                  0.436  233.630005   \n",
       "2006-12-16 17:26:00                5.374                  0.498  233.289993   \n",
       "2006-12-16 17:27:00                5.388                  0.502  233.740005   \n",
       "2006-12-16 17:28:00                3.666                  0.528  235.679993   \n",
       "2006-12-16 17:29:00                3.520                  0.522  235.020004   \n",
       "2006-12-16 17:30:00                3.702                  0.520  235.089996   \n",
       "2006-12-16 17:31:00                3.700                  0.520  235.220001   \n",
       "2006-12-16 17:32:00                3.668                  0.510  233.990005   \n",
       "2006-12-16 17:33:00                3.662                  0.510  233.860001   \n",
       "2006-12-16 17:34:00                4.448                  0.498  232.860001   \n",
       "2006-12-16 17:35:00                5.412                  0.470  232.779999   \n",
       "2006-12-16 17:36:00                5.224                  0.478  232.990005   \n",
       "2006-12-16 17:37:00                5.268                  0.398  232.910004   \n",
       "2006-12-16 17:38:00                4.054                  0.422  235.240005   \n",
       "2006-12-16 17:39:00                3.384                  0.282  237.139999   \n",
       "2006-12-16 17:40:00                3.270                  0.152  236.729996   \n",
       "2006-12-16 17:41:00                3.430                  0.156  237.059998   \n",
       "2006-12-16 17:42:00                3.266                  0.000  237.130005   \n",
       "2006-12-16 17:43:00                3.728                  0.000  235.839996   \n",
       "2006-12-16 17:44:00                5.894                  0.000  232.690002   \n",
       "2006-12-16 17:45:00                7.706                  0.000  230.979996   \n",
       "2006-12-16 17:46:00                7.026                  0.000  232.210007   \n",
       "2006-12-16 17:47:00                5.174                  0.000  234.190002   \n",
       "2006-12-16 17:48:00                4.474                  0.000  234.960007   \n",
       "2006-12-16 17:49:00                3.248                  0.000  236.660004   \n",
       "2006-12-16 17:50:00                3.236                  0.000  235.839996   \n",
       "2006-12-16 17:51:00                3.228                  0.000  235.600006   \n",
       "2006-12-16 17:52:00                3.258                  0.000  235.490005   \n",
       "2006-12-16 17:53:00                3.178                  0.000  235.279999   \n",
       "...                                  ...                    ...         ...   \n",
       "2010-11-26 20:33:00                0.978                  0.000  240.279999   \n",
       "2010-11-26 20:34:00                0.968                  0.000  237.570007   \n",
       "2010-11-26 20:35:00                0.960                  0.000  238.009995   \n",
       "2010-11-26 20:36:00                0.964                  0.000  238.070007   \n",
       "2010-11-26 20:37:00                0.980                  0.000  237.899994   \n",
       "2010-11-26 20:38:00                0.976                  0.096  236.970001   \n",
       "2010-11-26 20:39:00                0.984                  0.100  238.160004   \n",
       "2010-11-26 20:40:00                0.986                  0.102  238.919998   \n",
       "2010-11-26 20:41:00                0.990                  0.106  239.570007   \n",
       "2010-11-26 20:42:00                0.988                  0.106  239.600006   \n",
       "2010-11-26 20:43:00                0.988                  0.106  239.639999   \n",
       "2010-11-26 20:44:00                0.982                  0.102  238.690002   \n",
       "2010-11-26 20:45:00                0.972                  0.092  238.320007   \n",
       "2010-11-26 20:46:00                0.908                  0.000  238.529999   \n",
       "2010-11-26 20:47:00                0.910                  0.000  238.710007   \n",
       "2010-11-26 20:48:00                0.912                  0.000  239.250000   \n",
       "2010-11-26 20:49:00                0.948                  0.000  238.160004   \n",
       "2010-11-26 20:50:00                1.198                  0.128  238.110001   \n",
       "2010-11-26 20:51:00                1.024                  0.106  238.839996   \n",
       "2010-11-26 20:52:00                0.946                  0.000  239.050003   \n",
       "2010-11-26 20:53:00                0.944                  0.000  238.720001   \n",
       "2010-11-26 20:54:00                0.946                  0.000  239.309998   \n",
       "2010-11-26 20:55:00                0.946                  0.000  239.740005   \n",
       "2010-11-26 20:56:00                0.942                  0.000  239.410004   \n",
       "2010-11-26 20:57:00                0.946                  0.000  240.330002   \n",
       "2010-11-26 20:58:00                0.946                  0.000  240.429993   \n",
       "2010-11-26 20:59:00                0.944                  0.000  240.000000   \n",
       "2010-11-26 21:00:00                0.938                  0.000  239.820007   \n",
       "2010-11-26 21:01:00                0.934                  0.000  239.699997   \n",
       "2010-11-26 21:02:00                0.932                  0.000  239.550003   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "datetime                                                                \n",
       "2006-12-16 17:24:00         18.400000             0.0             1.0   \n",
       "2006-12-16 17:25:00         23.000000             0.0             1.0   \n",
       "2006-12-16 17:26:00         23.000000             0.0             2.0   \n",
       "2006-12-16 17:27:00         23.000000             0.0             1.0   \n",
       "2006-12-16 17:28:00         15.800000             0.0             1.0   \n",
       "2006-12-16 17:29:00         15.000000             0.0             2.0   \n",
       "2006-12-16 17:30:00         15.800000             0.0             1.0   \n",
       "2006-12-16 17:31:00         15.800000             0.0             1.0   \n",
       "2006-12-16 17:32:00         15.800000             0.0             1.0   \n",
       "2006-12-16 17:33:00         15.800000             0.0             2.0   \n",
       "2006-12-16 17:34:00         19.600000             0.0             1.0   \n",
       "2006-12-16 17:35:00         23.200001             0.0             1.0   \n",
       "2006-12-16 17:36:00         22.400000             0.0             1.0   \n",
       "2006-12-16 17:37:00         22.600000             0.0             2.0   \n",
       "2006-12-16 17:38:00         17.600000             0.0             1.0   \n",
       "2006-12-16 17:39:00         14.200000             0.0             0.0   \n",
       "2006-12-16 17:40:00         13.800000             0.0             0.0   \n",
       "2006-12-16 17:41:00         14.400000             0.0             0.0   \n",
       "2006-12-16 17:42:00         13.800000             0.0             0.0   \n",
       "2006-12-16 17:43:00         16.400000             0.0             0.0   \n",
       "2006-12-16 17:44:00         25.400000             0.0             0.0   \n",
       "2006-12-16 17:45:00         33.200001             0.0             0.0   \n",
       "2006-12-16 17:46:00         30.600000             0.0             0.0   \n",
       "2006-12-16 17:47:00         22.000000             0.0             0.0   \n",
       "2006-12-16 17:48:00         19.400000             0.0             0.0   \n",
       "2006-12-16 17:49:00         13.600000             0.0             0.0   \n",
       "2006-12-16 17:50:00         13.600000             0.0             0.0   \n",
       "2006-12-16 17:51:00         13.600000             0.0             0.0   \n",
       "2006-12-16 17:52:00         13.800000             0.0             0.0   \n",
       "2006-12-16 17:53:00         13.400000             0.0             0.0   \n",
       "...                               ...             ...             ...   \n",
       "2010-11-26 20:33:00          4.000000             0.0             1.0   \n",
       "2010-11-26 20:34:00          4.000000             0.0             1.0   \n",
       "2010-11-26 20:35:00          4.000000             0.0             1.0   \n",
       "2010-11-26 20:36:00          4.000000             0.0             1.0   \n",
       "2010-11-26 20:37:00          4.200000             0.0             1.0   \n",
       "2010-11-26 20:38:00          4.000000             0.0             2.0   \n",
       "2010-11-26 20:39:00          4.200000             0.0             1.0   \n",
       "2010-11-26 20:40:00          4.200000             0.0             1.0   \n",
       "2010-11-26 20:41:00          4.200000             0.0             1.0   \n",
       "2010-11-26 20:42:00          4.200000             0.0             1.0   \n",
       "2010-11-26 20:43:00          4.200000             0.0             1.0   \n",
       "2010-11-26 20:44:00          4.000000             0.0             1.0   \n",
       "2010-11-26 20:45:00          4.000000             0.0             2.0   \n",
       "2010-11-26 20:46:00          3.800000             0.0             1.0   \n",
       "2010-11-26 20:47:00          3.800000             0.0             1.0   \n",
       "2010-11-26 20:48:00          3.800000             0.0             1.0   \n",
       "2010-11-26 20:49:00          4.000000             0.0             1.0   \n",
       "2010-11-26 20:50:00          5.000000             0.0             1.0   \n",
       "2010-11-26 20:51:00          4.200000             0.0             1.0   \n",
       "2010-11-26 20:52:00          4.000000             0.0             0.0   \n",
       "2010-11-26 20:53:00          4.000000             0.0             0.0   \n",
       "2010-11-26 20:54:00          4.000000             0.0             0.0   \n",
       "2010-11-26 20:55:00          4.000000             0.0             0.0   \n",
       "2010-11-26 20:56:00          4.000000             0.0             0.0   \n",
       "2010-11-26 20:57:00          4.000000             0.0             0.0   \n",
       "2010-11-26 20:58:00          4.000000             0.0             0.0   \n",
       "2010-11-26 20:59:00          4.000000             0.0             0.0   \n",
       "2010-11-26 21:00:00          3.800000             0.0             0.0   \n",
       "2010-11-26 21:01:00          3.800000             0.0             0.0   \n",
       "2010-11-26 21:02:00          3.800000             0.0             0.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "datetime                             \n",
       "2006-12-16 17:24:00            17.0  \n",
       "2006-12-16 17:25:00            16.0  \n",
       "2006-12-16 17:26:00            17.0  \n",
       "2006-12-16 17:27:00            17.0  \n",
       "2006-12-16 17:28:00            17.0  \n",
       "2006-12-16 17:29:00            17.0  \n",
       "2006-12-16 17:30:00            17.0  \n",
       "2006-12-16 17:31:00            17.0  \n",
       "2006-12-16 17:32:00            17.0  \n",
       "2006-12-16 17:33:00            16.0  \n",
       "2006-12-16 17:34:00            17.0  \n",
       "2006-12-16 17:35:00            17.0  \n",
       "2006-12-16 17:36:00            16.0  \n",
       "2006-12-16 17:37:00            17.0  \n",
       "2006-12-16 17:38:00            17.0  \n",
       "2006-12-16 17:39:00            17.0  \n",
       "2006-12-16 17:40:00            17.0  \n",
       "2006-12-16 17:41:00            17.0  \n",
       "2006-12-16 17:42:00            18.0  \n",
       "2006-12-16 17:43:00            17.0  \n",
       "2006-12-16 17:44:00            16.0  \n",
       "2006-12-16 17:45:00            17.0  \n",
       "2006-12-16 17:46:00            16.0  \n",
       "2006-12-16 17:47:00            17.0  \n",
       "2006-12-16 17:48:00            17.0  \n",
       "2006-12-16 17:49:00            17.0  \n",
       "2006-12-16 17:50:00            17.0  \n",
       "2006-12-16 17:51:00            17.0  \n",
       "2006-12-16 17:52:00            17.0  \n",
       "2006-12-16 17:53:00            17.0  \n",
       "...                             ...  \n",
       "2010-11-26 20:33:00             0.0  \n",
       "2010-11-26 20:34:00             0.0  \n",
       "2010-11-26 20:35:00             0.0  \n",
       "2010-11-26 20:36:00             0.0  \n",
       "2010-11-26 20:37:00             0.0  \n",
       "2010-11-26 20:38:00             0.0  \n",
       "2010-11-26 20:39:00             0.0  \n",
       "2010-11-26 20:40:00             0.0  \n",
       "2010-11-26 20:41:00             0.0  \n",
       "2010-11-26 20:42:00             0.0  \n",
       "2010-11-26 20:43:00             0.0  \n",
       "2010-11-26 20:44:00             0.0  \n",
       "2010-11-26 20:45:00             0.0  \n",
       "2010-11-26 20:46:00             0.0  \n",
       "2010-11-26 20:47:00             0.0  \n",
       "2010-11-26 20:48:00             0.0  \n",
       "2010-11-26 20:49:00             0.0  \n",
       "2010-11-26 20:50:00             0.0  \n",
       "2010-11-26 20:51:00             0.0  \n",
       "2010-11-26 20:52:00             0.0  \n",
       "2010-11-26 20:53:00             0.0  \n",
       "2010-11-26 20:54:00             0.0  \n",
       "2010-11-26 20:55:00             0.0  \n",
       "2010-11-26 20:56:00             0.0  \n",
       "2010-11-26 20:57:00             0.0  \n",
       "2010-11-26 20:58:00             0.0  \n",
       "2010-11-26 20:59:00             0.0  \n",
       "2010-11-26 21:00:00             0.0  \n",
       "2010-11-26 21:01:00             0.0  \n",
       "2010-11-26 21:02:00             0.0  \n",
       "\n",
       "[2075259 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A fourth sub-metering variable can be created by subtracting the sum of three defined sub-metering variables\n",
    "## from the total active energy as follows:\n",
    "\n",
    "values = dataset.values\n",
    "dataset['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] + values[:,6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>sub_metering_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.839996</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>52.266670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630005</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.333336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.289993</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>70.566666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740005</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>71.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.679993</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.099998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power     Voltage  \\\n",
       "datetime                                                                      \n",
       "2006-12-16 17:24:00                4.216                  0.418  234.839996   \n",
       "2006-12-16 17:25:00                5.360                  0.436  233.630005   \n",
       "2006-12-16 17:26:00                5.374                  0.498  233.289993   \n",
       "2006-12-16 17:27:00                5.388                  0.502  233.740005   \n",
       "2006-12-16 17:28:00                3.666                  0.528  235.679993   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "datetime                                                                \n",
       "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
       "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
       "2006-12-16 17:27:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:28:00              15.8             0.0             1.0   \n",
       "\n",
       "                     Sub_metering_3  sub_metering_4  \n",
       "datetime                                             \n",
       "2006-12-16 17:24:00            17.0       52.266670  \n",
       "2006-12-16 17:25:00            16.0       72.333336  \n",
       "2006-12-16 17:26:00            17.0       70.566666  \n",
       "2006-12-16 17:27:00            17.0       71.800003  \n",
       "2006-12-16 17:28:00            17.0       43.099998  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save updated dataset\n",
    "dataset.to_csv('household_power_consumption_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1442, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>sub_metering_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16</th>\n",
       "      <td>1209.176025</td>\n",
       "      <td>34.922001</td>\n",
       "      <td>93552.53125</td>\n",
       "      <td>5180.799805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>4926.0</td>\n",
       "      <td>14680.933594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-17</th>\n",
       "      <td>3390.459961</td>\n",
       "      <td>226.005997</td>\n",
       "      <td>345725.31250</td>\n",
       "      <td>14398.599609</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>13341.0</td>\n",
       "      <td>36946.667969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-18</th>\n",
       "      <td>2203.825928</td>\n",
       "      <td>161.792007</td>\n",
       "      <td>347373.62500</td>\n",
       "      <td>9247.200195</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>14018.0</td>\n",
       "      <td>19028.433594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-19</th>\n",
       "      <td>1666.193970</td>\n",
       "      <td>150.942001</td>\n",
       "      <td>348479.00000</td>\n",
       "      <td>7094.000000</td>\n",
       "      <td>839.0</td>\n",
       "      <td>7602.0</td>\n",
       "      <td>6197.0</td>\n",
       "      <td>13131.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-20</th>\n",
       "      <td>2225.748047</td>\n",
       "      <td>160.998001</td>\n",
       "      <td>348923.62500</td>\n",
       "      <td>9313.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>14063.0</td>\n",
       "      <td>20384.800781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Global_active_power  Global_reactive_power       Voltage  \\\n",
       "datetime                                                               \n",
       "2006-12-16          1209.176025              34.922001   93552.53125   \n",
       "2006-12-17          3390.459961             226.005997  345725.31250   \n",
       "2006-12-18          2203.825928             161.792007  347373.62500   \n",
       "2006-12-19          1666.193970             150.942001  348479.00000   \n",
       "2006-12-20          2225.748047             160.998001  348923.62500   \n",
       "\n",
       "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
       "datetime                                                                       \n",
       "2006-12-16       5180.799805             0.0           546.0          4926.0   \n",
       "2006-12-17      14398.599609          2033.0          4187.0         13341.0   \n",
       "2006-12-18       9247.200195          1063.0          2621.0         14018.0   \n",
       "2006-12-19       7094.000000           839.0          7602.0          6197.0   \n",
       "2006-12-20       9313.000000             0.0          2648.0         14063.0   \n",
       "\n",
       "            sub_metering_4  \n",
       "datetime                    \n",
       "2006-12-16    14680.933594  \n",
       "2006-12-17    36946.667969  \n",
       "2006-12-18    19028.433594  \n",
       "2006-12-19    13131.900391  \n",
       "2006-12-20    20384.800781  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Problem Framing :\n",
    "## There are many ways to harness and explore the household power consumption dataset.\n",
    "\n",
    "## In this tutorial, we will use the data to explore a very specific question; that is:\n",
    "\n",
    "## \"Given recent power consumption, what is the expected power consumption for the week ahead?\"\n",
    "\n",
    "## This requires that a predictive model forecast the total active power for each day over the next seven days.\n",
    "\n",
    "## Technically, this framing of the problem is referred to as a multi-step time series forecasting problem, given\n",
    "## the multiple forecast steps. A model that makes use of multiple input variables may be referred to as a\n",
    "## multivariate multi-step time series forecasting model.\n",
    "\n",
    "## A model of this type could be helpful within the household in planning expenditures. It could also be helpful\n",
    "## on the supply side for planning electricity demand for a specific household.\n",
    "\n",
    "## This framing of the dataset also suggests that it would be useful to downsample the per-minute observations of\n",
    "## power consumption to daily totals. This is not required, but makes sense, given that we are interested in total\n",
    "## power per day.\n",
    "\n",
    "## We can achieve this easily using the resample() function on the pandas DataFrame. Calling this function with the\n",
    "## argument ‘D‘ allows the loaded data indexed by date-time to be grouped by day (see all offset aliases). We can \n",
    "## then calculate the sum of all observations for each day and create a new dataset of daily power consumption data\n",
    "## for each of the eight variables.\n",
    "\n",
    "# resample minute data to total for each day\n",
    "# from pandas import read_csv\n",
    "# load the new file\n",
    "# dataset = read_csv('household_power_consumption.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# resample data to daily\n",
    "daily_groups = dataset.resample('D')\n",
    "daily_data = daily_groups.sum()\n",
    "# summarize\n",
    "print(daily_data.shape)\n",
    "#print(daily_data.head())\n",
    "# save\n",
    "daily_data.to_csv('household_power_consumption_days.csv')\n",
    "daily_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation Metric\n",
    "## A forecast will be comprised of seven values, one for each day of the week ahead.\n",
    "\n",
    "## It is common with multi-step forecasting problems to evaluate each forecasted time step separately. This is\n",
    "## helpful for a few reasons:\n",
    "\n",
    "## To comment on the skill at a specific lead time (e.g. +1 day vs +3 days).\n",
    "## To contrast models based on their skills at different lead times (e.g. models good at +1 day vs models good\n",
    "## at days +5).\n",
    "## The units of the total power are kilowatts and it would be useful to have an error metric that was also in the\n",
    "## same units. Both Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) fit this bill, although RMSE is\n",
    "## more commonly used and will be adopted in this tutorial. Unlike MAE, RMSE is more punishing of forecast errors.\n",
    "\n",
    "## The performance metric for this problem will be the RMSE for each lead time from day 1 to day 7.\n",
    "\n",
    "## As a short-cut, it may be useful to summarize the performance of a model using a single score in order to aide\n",
    "## in model selection.\n",
    "\n",
    "## One possible score that could be used would be the RMSE across all forecast days.\n",
    "\n",
    "## The function evaluate_forecasts() below will implement this behavior and return the performance of a model\n",
    "## based on multiple seven-day forecasts.\n",
    "\n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        # calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "        # store\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores\n",
    "\n",
    "## Running the function will first return the overall RMSE regardless of day, then an array of RMSE scores for\n",
    "## each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>sub_metering_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-11-19</th>\n",
       "      <td>1570.400024</td>\n",
       "      <td>122.928001</td>\n",
       "      <td>345667.34375</td>\n",
       "      <td>6593.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>13776.333008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-20</th>\n",
       "      <td>2197.006104</td>\n",
       "      <td>153.768005</td>\n",
       "      <td>346476.00000</td>\n",
       "      <td>9320.200195</td>\n",
       "      <td>4367.0</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>11433.0</td>\n",
       "      <td>17869.767578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-21</th>\n",
       "      <td>900.909973</td>\n",
       "      <td>119.624001</td>\n",
       "      <td>347299.46875</td>\n",
       "      <td>3798.600098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>4778.0</td>\n",
       "      <td>9731.166992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22</th>\n",
       "      <td>2041.536011</td>\n",
       "      <td>142.354004</td>\n",
       "      <td>345883.84375</td>\n",
       "      <td>8660.400391</td>\n",
       "      <td>4855.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>10136.0</td>\n",
       "      <td>16924.599609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-23</th>\n",
       "      <td>1577.536011</td>\n",
       "      <td>137.449997</td>\n",
       "      <td>346428.75000</td>\n",
       "      <td>6731.200195</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>7611.0</td>\n",
       "      <td>16352.266602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-24</th>\n",
       "      <td>1796.248047</td>\n",
       "      <td>132.460007</td>\n",
       "      <td>345644.59375</td>\n",
       "      <td>7559.399902</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>2848.0</td>\n",
       "      <td>12224.0</td>\n",
       "      <td>13769.466797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25</th>\n",
       "      <td>1431.163940</td>\n",
       "      <td>116.127998</td>\n",
       "      <td>347812.21875</td>\n",
       "      <td>6004.000000</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>5072.0</td>\n",
       "      <td>17278.732422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26</th>\n",
       "      <td>1488.104004</td>\n",
       "      <td>120.826004</td>\n",
       "      <td>303487.56250</td>\n",
       "      <td>6259.799805</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>9989.0</td>\n",
       "      <td>13347.733398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Global_active_power  Global_reactive_power       Voltage  \\\n",
       "datetime                                                               \n",
       "2010-11-19          1570.400024             122.928001  345667.34375   \n",
       "2010-11-20          2197.006104             153.768005  346476.00000   \n",
       "2010-11-21           900.909973             119.624001  347299.46875   \n",
       "2010-11-22          2041.536011             142.354004  345883.84375   \n",
       "2010-11-23          1577.536011             137.449997  346428.75000   \n",
       "2010-11-24          1796.248047             132.460007  345644.59375   \n",
       "2010-11-25          1431.163940             116.127998  347812.21875   \n",
       "2010-11-26          1488.104004             120.826004  303487.56250   \n",
       "\n",
       "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
       "datetime                                                                       \n",
       "2010-11-19       6593.000000             0.0           483.0         11914.0   \n",
       "2010-11-20       9320.200195          4367.0          2947.0         11433.0   \n",
       "2010-11-21       3798.600098             0.0           506.0          4778.0   \n",
       "2010-11-22       8660.400391          4855.0          2110.0         10136.0   \n",
       "2010-11-23       6731.200195          1871.0           458.0          7611.0   \n",
       "2010-11-24       7559.399902          1096.0          2848.0         12224.0   \n",
       "2010-11-25       6004.000000          1076.0           426.0          5072.0   \n",
       "2010-11-26       6259.799805          1080.0           385.0          9989.0   \n",
       "\n",
       "            sub_metering_4  \n",
       "datetime                    \n",
       "2010-11-19    13776.333008  \n",
       "2010-11-20    17869.767578  \n",
       "2010-11-21     9731.166992  \n",
       "2010-11-22    16924.599609  \n",
       "2010-11-23    16352.266602  \n",
       "2010-11-24    13769.466797  \n",
       "2010-11-25    17278.732422  \n",
       "2010-11-26    13347.733398  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data.tail(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>sub_metering_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16</th>\n",
       "      <td>1209.176025</td>\n",
       "      <td>34.922001</td>\n",
       "      <td>93552.53125</td>\n",
       "      <td>5180.799805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>4926.0</td>\n",
       "      <td>14680.933594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-17</th>\n",
       "      <td>3390.459961</td>\n",
       "      <td>226.005997</td>\n",
       "      <td>345725.31250</td>\n",
       "      <td>14398.599609</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>13341.0</td>\n",
       "      <td>36946.667969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-18</th>\n",
       "      <td>2203.825928</td>\n",
       "      <td>161.792007</td>\n",
       "      <td>347373.62500</td>\n",
       "      <td>9247.200195</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>14018.0</td>\n",
       "      <td>19028.433594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-19</th>\n",
       "      <td>1666.193970</td>\n",
       "      <td>150.942001</td>\n",
       "      <td>348479.00000</td>\n",
       "      <td>7094.000000</td>\n",
       "      <td>839.0</td>\n",
       "      <td>7602.0</td>\n",
       "      <td>6197.0</td>\n",
       "      <td>13131.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-20</th>\n",
       "      <td>2225.748047</td>\n",
       "      <td>160.998001</td>\n",
       "      <td>348923.62500</td>\n",
       "      <td>9313.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>14063.0</td>\n",
       "      <td>20384.800781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Global_active_power  Global_reactive_power       Voltage  \\\n",
       "datetime                                                               \n",
       "2006-12-16          1209.176025              34.922001   93552.53125   \n",
       "2006-12-17          3390.459961             226.005997  345725.31250   \n",
       "2006-12-18          2203.825928             161.792007  347373.62500   \n",
       "2006-12-19          1666.193970             150.942001  348479.00000   \n",
       "2006-12-20          2225.748047             160.998001  348923.62500   \n",
       "\n",
       "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
       "datetime                                                                       \n",
       "2006-12-16       5180.799805             0.0           546.0          4926.0   \n",
       "2006-12-17      14398.599609          2033.0          4187.0         13341.0   \n",
       "2006-12-18       9247.200195          1063.0          2621.0         14018.0   \n",
       "2006-12-19       7094.000000           839.0          7602.0          6197.0   \n",
       "2006-12-20       9313.000000             0.0          2648.0         14063.0   \n",
       "\n",
       "            sub_metering_4  \n",
       "datetime                    \n",
       "2006-12-16    14680.933594  \n",
       "2006-12-17    36946.667969  \n",
       "2006-12-18    19028.433594  \n",
       "2006-12-19    13131.900391  \n",
       "2006-12-20    20384.800781  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a 1st date in YYYY-MM-DD format :2006-12-16\n",
      "Enter a 2nd date in YYYY-MM-DD format :2006-12-20\n",
      "There are 4 days between 2006-12-16 and 2006-12-20\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "a='%Y-%m-%d'\n",
    "\n",
    "#.zfill(x) fill up to x-1 with 0s so 1-1-1 will turn into 0001-1-1\n",
    "#strptime gets only yyyy format, not yy, yy or y\n",
    "\n",
    "stringdate1=input('Enter a 1st date in YYYY-MM-DD format :').zfill(8)\n",
    "date1 = datetime.strptime(stringdate1, a)\n",
    "\n",
    "stringdate2=input('Enter a 2nd date in YYYY-MM-DD format :').zfill(8)\n",
    "date2 = datetime.strptime(stringdate2, a)\n",
    "\n",
    "td=(date2-date1).days\n",
    "\n",
    "#if not converting datetime into str with strftime - use .format\n",
    "\n",
    "print('There are {} days between {} and {}'.format(\n",
    "td, \"{:%Y-%m-%d}\".format(date1), \"{:%Y-%m-%d}\".format(date2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_days = pd.read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, \\\n",
    "                           parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>sub_metering_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-12-16</td>\n",
       "      <td>1209.176</td>\n",
       "      <td>34.922</td>\n",
       "      <td>93552.53</td>\n",
       "      <td>5180.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>4926.0</td>\n",
       "      <td>14680.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-12-17</td>\n",
       "      <td>3390.460</td>\n",
       "      <td>226.006</td>\n",
       "      <td>345725.30</td>\n",
       "      <td>14398.6</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>13341.0</td>\n",
       "      <td>36946.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-12-18</td>\n",
       "      <td>2203.826</td>\n",
       "      <td>161.792</td>\n",
       "      <td>347373.62</td>\n",
       "      <td>9247.2</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>14018.0</td>\n",
       "      <td>19028.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-12-19</td>\n",
       "      <td>1666.194</td>\n",
       "      <td>150.942</td>\n",
       "      <td>348479.00</td>\n",
       "      <td>7094.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>7602.0</td>\n",
       "      <td>6197.0</td>\n",
       "      <td>13131.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-12-20</td>\n",
       "      <td>2225.748</td>\n",
       "      <td>160.998</td>\n",
       "      <td>348923.62</td>\n",
       "      <td>9313.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>14063.0</td>\n",
       "      <td>20384.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime  Global_active_power  Global_reactive_power    Voltage  \\\n",
       "0 2006-12-16             1209.176                 34.922   93552.53   \n",
       "1 2006-12-17             3390.460                226.006  345725.30   \n",
       "2 2006-12-18             2203.826                161.792  347373.62   \n",
       "3 2006-12-19             1666.194                150.942  348479.00   \n",
       "4 2006-12-20             2225.748                160.998  348923.62   \n",
       "\n",
       "   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
       "0            5180.8             0.0           546.0          4926.0   \n",
       "1           14398.6          2033.0          4187.0         13341.0   \n",
       "2            9247.2          1063.0          2621.0         14018.0   \n",
       "3            7094.0           839.0          7602.0          6197.0   \n",
       "4            9313.0             0.0          2648.0         14063.0   \n",
       "\n",
       "   sub_metering_4  \n",
       "0       14680.934  \n",
       "1       36946.668  \n",
       "2       19028.434  \n",
       "3       13131.900  \n",
       "4       20384.800  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_days.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>sub_metering_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>2010-11-17</td>\n",
       "      <td>1582.032</td>\n",
       "      <td>141.916000</td>\n",
       "      <td>347691.22</td>\n",
       "      <td>6669.0</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>8915.0</td>\n",
       "      <td>15808.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>2010-11-18</td>\n",
       "      <td>1652.152</td>\n",
       "      <td>206.196000</td>\n",
       "      <td>347064.12</td>\n",
       "      <td>7022.8</td>\n",
       "      <td>2175.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>9449.0</td>\n",
       "      <td>15422.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>2010-11-19</td>\n",
       "      <td>1570.400</td>\n",
       "      <td>122.928000</td>\n",
       "      <td>345667.34</td>\n",
       "      <td>6593.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>13776.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2010-11-20</td>\n",
       "      <td>2197.006</td>\n",
       "      <td>153.768000</td>\n",
       "      <td>346476.00</td>\n",
       "      <td>9320.2</td>\n",
       "      <td>4367.0</td>\n",
       "      <td>2947.0</td>\n",
       "      <td>11433.0</td>\n",
       "      <td>17869.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2010-11-21</td>\n",
       "      <td>900.910</td>\n",
       "      <td>119.624000</td>\n",
       "      <td>347299.47</td>\n",
       "      <td>3798.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>4778.0</td>\n",
       "      <td>9731.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2010-11-22</td>\n",
       "      <td>2041.536</td>\n",
       "      <td>142.354000</td>\n",
       "      <td>345883.84</td>\n",
       "      <td>8660.4</td>\n",
       "      <td>4855.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>10136.0</td>\n",
       "      <td>16924.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2010-11-23</td>\n",
       "      <td>1577.536</td>\n",
       "      <td>137.450000</td>\n",
       "      <td>346428.75</td>\n",
       "      <td>6731.2</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>7611.0</td>\n",
       "      <td>16352.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>1796.248</td>\n",
       "      <td>132.460000</td>\n",
       "      <td>345644.60</td>\n",
       "      <td>7559.4</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>2848.0</td>\n",
       "      <td>12224.0</td>\n",
       "      <td>13769.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>1431.164</td>\n",
       "      <td>116.128000</td>\n",
       "      <td>347812.22</td>\n",
       "      <td>6004.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>5072.0</td>\n",
       "      <td>17278.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>1488.104</td>\n",
       "      <td>120.826004</td>\n",
       "      <td>303487.56</td>\n",
       "      <td>6259.8</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>9989.0</td>\n",
       "      <td>13347.733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime  Global_active_power  Global_reactive_power    Voltage  \\\n",
       "1432 2010-11-17             1582.032             141.916000  347691.22   \n",
       "1433 2010-11-18             1652.152             206.196000  347064.12   \n",
       "1434 2010-11-19             1570.400             122.928000  345667.34   \n",
       "1435 2010-11-20             2197.006             153.768000  346476.00   \n",
       "1436 2010-11-21              900.910             119.624000  347299.47   \n",
       "1437 2010-11-22             2041.536             142.354000  345883.84   \n",
       "1438 2010-11-23             1577.536             137.450000  346428.75   \n",
       "1439 2010-11-24             1796.248             132.460000  345644.60   \n",
       "1440 2010-11-25             1431.164             116.128000  347812.22   \n",
       "1441 2010-11-26             1488.104             120.826004  303487.56   \n",
       "\n",
       "      Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
       "1432            6669.0          1153.0           491.0          8915.0   \n",
       "1433            7022.8          2175.0           489.0          9449.0   \n",
       "1434            6593.0             0.0           483.0         11914.0   \n",
       "1435            9320.2          4367.0          2947.0         11433.0   \n",
       "1436            3798.6             0.0           506.0          4778.0   \n",
       "1437            8660.4          4855.0          2110.0         10136.0   \n",
       "1438            6731.2          1871.0           458.0          7611.0   \n",
       "1439            7559.4          1096.0          2848.0         12224.0   \n",
       "1440            6004.0          1076.0           426.0          5072.0   \n",
       "1441            6259.8          1080.0           385.0          9989.0   \n",
       "\n",
       "      sub_metering_4  \n",
       "1432       15808.200  \n",
       "1433       15422.866  \n",
       "1434       13776.333  \n",
       "1435       17869.768  \n",
       "1436        9731.167  \n",
       "1437       16924.600  \n",
       "1438       16352.267  \n",
       "1439       13769.467  \n",
       "1440       17278.732  \n",
       "1441       13347.733  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_days.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>sub_metering_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1209.176</td>\n",
       "      <td>34.922</td>\n",
       "      <td>93552.53</td>\n",
       "      <td>5180.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>4926.0</td>\n",
       "      <td>14680.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3390.460</td>\n",
       "      <td>226.006</td>\n",
       "      <td>345725.30</td>\n",
       "      <td>14398.6</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>13341.0</td>\n",
       "      <td>36946.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2203.826</td>\n",
       "      <td>161.792</td>\n",
       "      <td>347373.62</td>\n",
       "      <td>9247.2</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>14018.0</td>\n",
       "      <td>19028.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1666.194</td>\n",
       "      <td>150.942</td>\n",
       "      <td>348479.00</td>\n",
       "      <td>7094.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>7602.0</td>\n",
       "      <td>6197.0</td>\n",
       "      <td>13131.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2225.748</td>\n",
       "      <td>160.998</td>\n",
       "      <td>348923.62</td>\n",
       "      <td>9313.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>14063.0</td>\n",
       "      <td>20384.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Global_active_power  Global_reactive_power    Voltage  Global_intensity  \\\n",
       "0             1209.176                 34.922   93552.53            5180.8   \n",
       "1             3390.460                226.006  345725.30           14398.6   \n",
       "2             2203.826                161.792  347373.62            9247.2   \n",
       "3             1666.194                150.942  348479.00            7094.0   \n",
       "4             2225.748                160.998  348923.62            9313.0   \n",
       "\n",
       "   Sub_metering_1  Sub_metering_2  Sub_metering_3  sub_metering_4  \n",
       "0             0.0           546.0          4926.0       14680.934  \n",
       "1          2033.0          4187.0         13341.0       36946.668  \n",
       "2          1063.0          2621.0         14018.0       19028.434  \n",
       "3           839.0          7602.0          6197.0       13131.900  \n",
       "4             0.0          2648.0         14063.0       20384.800  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_days_df = dataset_days.drop('datetime', axis = 1)\n",
    "dataset_days_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 7, 1)\n",
      "3390.46 1308.836\n",
      "(46, 7, 1)\n",
      "2083.4539999999997 2197.006\n"
     ]
    }
   ],
   "source": [
    "## Train and Test Sets\n",
    "# We will use the first three years of data for training predictive models and the final year for evaluating models.\n",
    "\n",
    "# The data in a given dataset will be divided into standard weeks. These are weeks that begin on a Sunday and end\n",
    "# on a Saturday.\n",
    "\n",
    "# The final year of the data is in 2010 and the first Sunday for 2010 was January 3rd. The data ends in mid November\n",
    "# 2010 and the closest final Saturday in the data is November 20th. This gives 46 weeks of test data.\n",
    "\n",
    "# The daily data starts in late 2006. The first Sunday in the dataset is December 17th, which is the second row of\n",
    "# data.Organizing the data into standard weeks gives 159 full standard weeks for training a predictive model.\n",
    "\n",
    "# The data ends in mid November 2010 and the closest final Saturday in the data is November 20th. \n",
    "####################################################################################################################\n",
    "# Starting from 1st Sunday i.e. 2006-12-17 i.e. 2nd row of data-frame, total no. of days are :\n",
    "td=((dataset_days['datetime'][len(dataset_days)-1]-dataset_days['datetime'][1]).days) + 1 # td = 1441 days\n",
    "test_data_days = (3 * 52 + 3) * 7  ## = 1113, 3 weeks added to make it same as the example of this tutorial site.\n",
    "balance_days = td - test_data_days  ## = 328\n",
    "balance_weeks = balance_days // 7 ## = 46, '//' - this type of division used to get only the integer part of week\n",
    "train_data_days = balance_weeks * 7 ## = 322\n",
    "\n",
    "## split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "    # split into standard weeks\n",
    "    train = data[1:(test_data_days+1)]\n",
    "    test = data[(test_data_days+1):-6]\n",
    "    # restructure into windows of weekly data\n",
    "    train = np.array(np.split(train, len(train)/7)).reshape(159,7,1)\n",
    "    test = np.array(np.split(test, len(test)/7)).reshape(46,7,1)\n",
    "    return train, test\n",
    "\n",
    "## Actual splitting :\n",
    "train, test = split_dataset(dataset_days_df['Global_active_power'])\n",
    "# validate train data\n",
    "print(train.shape)\n",
    "print(train[0, 0, 0], train[-1, -1, 0])\n",
    "# validate test\n",
    "print(test.shape)\n",
    "print(test[0, 0, 0], test[-1, -1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1113, 8)\n",
      "=========================\n",
      "(322, 8)\n",
      "+++++++++++++++++++++++++++\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 7 to array axis with dimension 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-cd01f9918b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m## Actual splitting :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_days_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# validate train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-cd01f9918b12>\u001b[0m in \u001b[0;36msplit_dataset\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+++++++++++++++++++++++++++'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# restructure into windows of weekly data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m159\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 7 to array axis with dimension 8"
     ]
    }
   ],
   "source": [
    "## split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "    # split into standard weeks\n",
    "    train = data[1:(test_data_days+1)]\n",
    "    print(train.shape)\n",
    "    print('=========================')\n",
    "    \n",
    "    test = data[(test_data_days+1):-6]\n",
    "    print(test.shape)\n",
    "    print('+++++++++++++++++++++++++++')\n",
    "    \n",
    "    # restructure into windows of weekly data\n",
    "    train = np.array(np.split(train, len(train)/7)).reshape(159,7,8)\n",
    "    test = np.array(np.split(test, len(test)/7)).reshape(46,7,8)\n",
    "    return train, test\n",
    "\n",
    "## Actual splitting :\n",
    "train, test = split_dataset(dataset_days_df)\n",
    "# validate train data\n",
    "print(train.shape)\n",
    "print(train[0, 0, 0], train[-1, -1, 0])\n",
    "# validate test\n",
    "print(test.shape)\n",
    "print(test[0, 0, 0], test[-1, -1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.0\n",
      "<class 'list'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "159\n",
      "(159, 7, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.3904600e+03, 2.2600600e+02, 3.4572530e+05, 1.4398600e+04,\n",
       "        2.0330000e+03, 4.1870000e+03, 1.3341000e+04, 3.6946668e+04],\n",
       "       [2.2038260e+03, 1.6179200e+02, 3.4737362e+05, 9.2472000e+03,\n",
       "        1.0630000e+03, 2.6210000e+03, 1.4018000e+04, 1.9028434e+04],\n",
       "       [1.6661940e+03, 1.5094200e+02, 3.4847900e+05, 7.0940000e+03,\n",
       "        8.3900000e+02, 7.6020000e+03, 6.1970000e+03, 1.3131900e+04],\n",
       "       [2.2257480e+03, 1.6099800e+02, 3.4892362e+05, 9.3130000e+03,\n",
       "        0.0000000e+00, 2.6480000e+03, 1.4063000e+04, 2.0384800e+04],\n",
       "       [1.7166240e+03, 1.4416600e+02, 3.4661630e+05, 7.2386000e+03,\n",
       "        1.7650000e+03, 2.6230000e+03, 1.0421000e+04, 1.3801400e+04],\n",
       "       [2.3413380e+03, 1.8690600e+02, 3.4730575e+05, 9.8970000e+03,\n",
       "        3.1510000e+03, 3.5000000e+02, 1.1131000e+04, 2.4390300e+04],\n",
       "       [4.7733860e+03, 2.2147000e+02, 3.4579594e+05, 2.0200400e+04,\n",
       "        2.6690000e+03, 4.2500000e+02, 1.4726000e+04, 6.1736434e+04]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dataset_days_df[1:(test_data_days+1)]\n",
    "print(len(train)/7)\n",
    "aa=(np.split(train, 159))\n",
    "print(type(aa))\n",
    "print(type(train))\n",
    "print(len(aa))\n",
    "\n",
    "bb = np.empty(shape=(159,7,8))\n",
    "\n",
    "for i in range(159):\n",
    "    for j in range(7):\n",
    "        for k in range(8):\n",
    "            bb[i][j][k] = np.array(aa[i].iloc[j, k])\n",
    "print(bb.shape)\n",
    "\n",
    "\n",
    "bb[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3390.460\n",
       "2    2203.826\n",
       "3    1666.194\n",
       "4    2225.748\n",
       "5    1716.624\n",
       "6    2341.338\n",
       "7    4773.386\n",
       "Name: Global_active_power, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[0].iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us start a UNIVARIATE LSTM Model :\n",
    "\n",
    "## https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split a univariate sequence into samples:\n",
    "\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "## returns X-numpy arrays of shape : no.of samples X n_steps and\n",
    "## y-numpy arrays of shape : no.of samples X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting above univariate sequence into samples of 3 time steps as input 'X' and one time step as output 'y' :\n",
    "\n",
    "n_steps = 3\n",
    "X, y = split_sequence(univ_seq, n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(6, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(np.array(X)))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If 1st Input =  [10 20 30] 1st Output =  40\n",
      "If 2nd Input =  [20 30 40] 2nd Output =  50\n",
      "If 4th Input =  [40 50 60] 4th Output =  70\n",
      "in_put shape =  (6, 3)\n",
      "out_put shape =  (6,)\n"
     ]
    }
   ],
   "source": [
    "print('If 1st Input = ', X[0], '1st Output = ', y[0])\n",
    "print('If 2nd Input = ', X[1], '2nd Output = ', y[1])\n",
    "print('If 4th Input = ', X[3], '4th Output = ', y[3])\n",
    "print('in_put shape = ', X.shape)\n",
    "print('out_put shape = ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] 40\n",
      "[20 30 40] 50\n",
      "[30 40 50] 60\n",
      "[40 50 60] 70\n",
      "[50 60 70] 80\n",
      "[60 70 80] 90\n"
     ]
    }
   ],
   "source": [
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers import RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101.32057]]\n"
     ]
    }
   ],
   "source": [
    "## Vanila LSTM :\n",
    "\n",
    "## We are working with a univariate series, so the number of features is one, for one variable.\n",
    "\n",
    "# reshape input X from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features))) # try with activation = 'linear'\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# The shape of the input for each sample is specified in the input_shape argument on the definition of first\n",
    "# hidden layer.\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101.99585]]\n"
     ]
    }
   ],
   "source": [
    "## Vanila LSTM :\n",
    "\n",
    "## We are working with a univariate series, so the number of features is one, for one variable.\n",
    "\n",
    "# reshape input X from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=False, input_shape=(n_steps, n_features))) # try with activation = 'linear'\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# The shape of the input for each sample is specified in the input_shape argument on the definition of first\n",
    "# hidden layer.\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://machinelearningmastery.com/lstm-autoencoders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102.05469]]\n"
     ]
    }
   ],
   "source": [
    "## Stacked LSTM :\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='linear', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50, activation='linear'))  ## # try with activation = 'linear' at both places\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# An LSTM layer requires a three-dimensional input and LSTMs by default will produce a two-dimensional output\n",
    "# as an interpretation from the end of the sequence.\n",
    "\n",
    "# We can address this by having the LSTM output a value for each time step in the input data by setting the\n",
    "# return_sequences=True argument on the layer. This allows us to have 3D output from hidden LSTM layer as input\n",
    "# to the next.\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101.48527]]\n"
     ]
    }
   ],
   "source": [
    "## Bidirectional LSTM :\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100.57967]]\n"
     ]
    }
   ],
   "source": [
    "## CNN LSTM :\n",
    "\n",
    "# The first step is to split the input sequences into subsequences that can be processed by the CNN model. For\n",
    "# example, we can first split our univariate time series data into input/output samples with four steps as input\n",
    "# and one as output. Each sample can then be split into two sub-samples, each with two time steps. The CNN can\n",
    "# interpret each subsequence of two time steps and provide a time series of interpretations of the subsequences\n",
    "# to the LSTM model to process as input.\n",
    "\n",
    "# We can parameterize this and define the number of subsequences as n_seq and the number of time steps per\n",
    "# subsequence as n_steps. The input data can then be reshaped to have the required structure:\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 4\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(univ_seq, n_steps)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_steps = 2\n",
    "X = X.reshape((X.shape[0], n_seq, n_steps, n_features))\n",
    "\n",
    "# We want to reuse the same CNN model when reading in each sub-sequence of data separately.\n",
    "\n",
    "# This can be achieved by wrapping the entire CNN model in a TimeDistributed wrapper that will apply the\n",
    "# entire model once per input, in this case, once per input subsequence.\n",
    "\n",
    "# The CNN model first has a convolutional layer for reading across the subsequence that requires a number of\n",
    "# filters and a kernel size to be specified. The number of filters is the number of reads or interpretations of\n",
    "# the input sequence. The kernel size is the number of time steps included of each ‘read’ operation of the input\n",
    "# sequence.\n",
    "\n",
    "# The convolution layer is followed by a max pooling layer that distills the filter maps down to 1/4 of their\n",
    "# size that includes the most salient features. These structures are then flattened down to a single one-dimensional\n",
    "# vector to be used as a single input time step to the LSTM layer.\n",
    "\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), \\\n",
    "                          input_shape=(None, n_steps, n_features)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=500, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = np.array([60, 70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_seq, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, 2, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10],\n",
       "        [20]],\n",
       "\n",
       "       [[30],\n",
       "        [40]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103.57239]]\n"
     ]
    }
   ],
   "source": [
    "## ConvLSTM :\n",
    "\n",
    "# A type of LSTM related to the CNN-LSTM is the ConvLSTM, where the convolutional reading of input is built directly\n",
    "# into each LSTM unit.\n",
    "\n",
    "# The ConvLSTM was developed for reading two-dimensional spatial-temporal data, but can be adapted for use with\n",
    "# univariate time series forecasting.\n",
    "\n",
    "# The layer expects input as a sequence of two-dimensional images, therefore the shape of input data must be:\n",
    "\n",
    "#                               [samples, timesteps, rows, columns, features]\n",
    "\n",
    "# For our purposes, we can split each sample into subsequences where timesteps will become the number of\n",
    "# subsequences, or n_seq, and columns will be the number of time steps for each subsequence, or n_steps. The number\n",
    "# of rows is fixed at 1 as we are working with one-dimensional data :\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 4\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(univ_seq, n_steps)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_steps = 2\n",
    "X = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))\n",
    "\n",
    "# We can define the ConvLSTM as a single layer in terms of the number of filters and a two-dimensional kernel size\n",
    "# in terms of (rows, columns). As we are working with a one-dimensional series, the number of rows is always fixed\n",
    "# to 1 in the kernel.\n",
    "\n",
    "# The output of the model must then be flattened before it can be interpreted and a prediction made.\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_steps, n_features)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=500, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = np.array([60, 70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_seq, 1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[10],\n",
       "         [20]]],\n",
       "\n",
       "\n",
       "       [[[30],\n",
       "         [40]]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multivariate LSTM Models\n",
    "\n",
    "## There are two main models that we may require with multivariate time series data; they are:\n",
    "\n",
    "## 1. Multiple Input Series.\n",
    "## 2. Multiple Parallel Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "## Multiple Input Series :\n",
    "\n",
    "## A problem may have two or more parallel input time series and an output time series that is dependent on\n",
    "## the input time series.\n",
    "\n",
    "## The input time series are parallel because each series has an observation at the same time steps.\n",
    "\n",
    "# define input & output sequence\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = np.array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "\n",
    "# Convert above to a single dataset :\n",
    "\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]]\n",
      "++++++++++++++\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]]\n",
      "++++++++++++++\n",
      "[30 35 65]\n",
      "++++++++++++++\n",
      "65\n",
      "++++++++++++++\n",
      "[30 35]\n",
      "++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "print(dataset[0:3])\n",
    "print('++++++++++++++')\n",
    "print(dataset[0:3, :-1])\n",
    "print('++++++++++++++')\n",
    "print(dataset[2])\n",
    "print('++++++++++++++')\n",
    "print(dataset[2, -1])\n",
    "print('++++++++++++++')\n",
    "print(dataset[2, :-1])\n",
    "print('++++++++++++++')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTMs can support parallel input time series as separate variables or features. Therefore, we need to split the\n",
    "# data into samples maintaining the order of observations across the two input sequences.\n",
    "\n",
    "# That is, if the first 'n' time steps of each parallel series are provided as input to the model the model should\n",
    "# associate this with the value in the output series at the 'n-th' time step.\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 3, 2) (7,)\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] 65\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] 85\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] 105\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] 125\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] 145\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] 165\n",
      "[[70 75]\n",
      " [80 85]\n",
      " [90 95]] 185\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "print(X.shape, y.shape)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "    \n",
    "# We can see that the X component has a three-dimensional structure.\n",
    "\n",
    "# The first dimension is the number of samples, in this case 7. The second dimension is the number of time steps\n",
    "# per sample, in this case 3, the value specified to the function. Finally, the last dimension specifies the number\n",
    "# of parallel time series or the number of variables, in this case 2 for the two parallel series.\n",
    "\n",
    "# This is the exact three-dimensional structure expected by an LSTM as input. The data is ready to use without\n",
    "# further reshaping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[208.05183]]\n"
     ]
    }
   ],
   "source": [
    "## Vanilla LSTM :\n",
    "\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features))) # try with activation = 'linear'\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# The shape of the input for each sample is specified in the input_shape argument on the definition of first\n",
    "# hidden layer.\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = np.array([[80, 85], [90, 95], [100, 105]])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple Parallel Series\n",
    "# An alternate time series problem is the case where there are multiple parallel time series and a value must be\n",
    "# predicted for each.\n",
    "\n",
    "# For example, given the data from the previous section:\n",
    "# [[ 10  15  25]\n",
    "#  [ 20  25  45]\n",
    "#  [ 30  35  65]\n",
    "#  [ 40  45  85]\n",
    "#  [ 50  55 105]\n",
    "#  [ 60  65 125]\n",
    "#  [ 70  75 145]\n",
    "#  [ 80  85 165] \n",
    "#  [ 90  95 185]]\n",
    "# We may want to predict the value for each of the three time series for the next time step. This might be\n",
    "# referred to as multivariate forecasting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 3) (6, 3)\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]] [40 45 85]\n",
      "[[20 25 45]\n",
      " [30 35 65]\n",
      " [40 45 85]] [ 50  55 105]\n",
      "[[ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]] [ 60  65 125]\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]] [ 70  75 145]\n",
      "[[ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]] [ 80  85 165]\n",
      "[[ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]] [ 90  95 185]\n"
     ]
    }
   ],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    " \n",
    "# define input sequence\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = np.array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "print(X.shape, y.shape)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101.56405 108.04345 211.44759]]\n"
     ]
    }
   ],
   "source": [
    "## Vanilla LSTM\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(n_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = np.array([[70,75,145], [80,85,165], [90,95,185]])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102.14695 107.60262 209.53247]]\n"
     ]
    }
   ],
   "source": [
    "## Stacked LSTM\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=400, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = np.array([[70,75,145], [80,85,165], [90,95,185]])\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi-Step LSTM Models\n",
    "# A time series forecasting problem that requires a prediction of multiple time steps into the future can be\n",
    "# referred to as multi-step time series forecasting.\n",
    "\n",
    "# Specifically, these are problems where the forecast horizon or interval is more than one time step.\n",
    "\n",
    "# There are two main types of LSTM models that can be used for multi-step forecasting; they are:\n",
    "\n",
    "#   1. Vector Output Model\n",
    "#   2. Encoder-Decoder Model\n",
    "#Before we look at these models, let’s first look at the preparation of data for multi-step forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] [40 50]\n",
      "[20 30 40] [50 60]\n",
      "[30 40 50] [60 70]\n",
      "[40 50 60] [70 80]\n",
      "[50 60 70] [80 90]\n",
      "(5, 3)\n",
      "(5, 2)\n"
     ]
    }
   ],
   "source": [
    "# Data preparation :\n",
    "# Here, both the input and output components will be comprised of multiple time steps and may or may not have\n",
    "# the same number of steps.\n",
    "\n",
    "# For example, given the univariate time series: [10, 20, 30, 40, 50, 60, 70, 80, 90] we could use 3 time steps as\n",
    "# input and forecast the next 2 time steps.Here the 1st sample input is [10, 20, 30] and output is [40, 50]\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106.53106 122.68206]]\n"
     ]
    }
   ],
   "source": [
    "# Vector Output Model\n",
    "# Like other types of neural network models, the LSTM can output a vector directly that can be interpreted as a\n",
    "# multi-step forecast.\n",
    "\n",
    "# This approach was seen in the previous section were one time step of each output time series was forecasted as a\n",
    "# vector.\n",
    "\n",
    "# As with the LSTMs for univariate data in a prior section, the prepared samples must first be reshaped. The LSTM\n",
    "# expects data to have a three-dimensional structure of [samples, timesteps, features], and in this case, we only\n",
    "# have one feature so the reshape is straightforward.\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=50, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107.60564 125.18237]]\n"
     ]
    }
   ],
   "source": [
    "# univariate multi-step vector-output stacked lstm example\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='linear', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='linear'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=50, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder-Decoder Model\n",
    "# A model specifically developed for forecasting variable length output sequences is called the Encoder-Decoder\n",
    "# LSTM.\n",
    "\n",
    "# The model was designed for prediction problems where there are both input and output sequences, so-called\n",
    "# sequence-to-sequence, or seq2seq problems, such as translating text from one language to another.\n",
    "\n",
    "# This model can be used for multi-step time series forecasting.\n",
    "\n",
    "# As its name suggests, the model is comprised of two sub-models: the encoder and the decoder.\n",
    "\n",
    "# (1) The encoder is a model responsible for reading and interpreting the input sequence. The output of the encoder\n",
    "# is a fixed length vector that represents the model’s interpretation of the sequence. The encoder is traditionally\n",
    "# a Vanilla LSTM model, although other encoder models can be used such as Stacked, Bidirectional, and CNN models.\n",
    "\n",
    "# The decoder uses the output of the encoder as an input.\n",
    "\n",
    "# (2) First, the fixed-length output of the encoder is repeated, once for each required time step in the output\n",
    "# sequence.\n",
    "\n",
    "# (3) This sequence is then provided to an LSTM decoder model. The model must output a value for each value in the\n",
    "# output time step, which can be interpreted by a single output model.\n",
    "\n",
    "# (4) We can use the same output layer or layers to make each one-step prediction in the output sequence. This can\n",
    "# be achieved by wrapping the output part of the model in a TimeDistributed wrapper.\n",
    "\n",
    "# (5) As with other LSTM models, the input data must be reshaped into the expected three-dimensional shape of\n",
    "# [samples,timesteps, features].\n",
    "\n",
    "# (6) In the case of the Encoder-Decoder model, the output, or y part, of the training dataset must also have this\n",
    "# shape.\n",
    "# This is because the model will predict a given number of time steps with a given number of features for each input\n",
    "# sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 99.9752]\n",
      "  [118.3034]]]\n"
     ]
    }
   ],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features] - Sl (5) & (6) above\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))  ## as per Sl. (5) above\n",
    "y = y.reshape((y.shape[0], y.shape[1], n_features))  ## as per Sl. (6) above\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_steps_in, n_features))) ## encoder : as per Sl. (1) above\n",
    "model.add(RepeatVector(n_steps_out))  ## as per Sl. (2) above\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))  ## decoder : as per Sl. (3) above\n",
    "model.add(TimeDistributed(Dense(1)))  ## output sequence as per Sl. (4) above\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = np.array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multivariate Multi-Step LSTM Models\n",
    "# In the previous sections, we have looked at univariate, multivariate, and multi-step time series forecasting.\n",
    "\n",
    "# It is possible to mix and match the different types of LSTM models presented so far for the different problems.\n",
    "# This too applies to time series forecasting problems that involve multivariate and multi-step forecasting, but\n",
    "# it may be a little more challenging.\n",
    "\n",
    "# In this section, we will provide short examples of data preparation and modeling for multivariate multi-step\n",
    "# time series forecasting as a template to ease this challenge, specifically:\n",
    "\n",
    "#      1. Multiple Input Multi-Step Output.\n",
    "#      2. Multiple Parallel Input and Multi-Step Output.\n",
    "# Perhaps the biggest stumbling block is in the preparation of data, so this is where we will focus our attention.\n",
    "\n",
    "# 1. Multiple Input Multi-Step Output :\n",
    "# There are those multivariate time series forecasting problems where the output series is separate but dependent\n",
    "# upon the input time series, and multiple time steps are required for the output series.\n",
    "\n",
    "# For example, consider our multivariate time series from a prior section:\n",
    "#     [[ 10  15  25]\n",
    "#      [ 20  25  45]\n",
    "#      [ 30  35  65]\n",
    "#      [ 40  45  85]\n",
    "#      [ 50  55 105]\n",
    "#      [ 60  65 125]\n",
    "#      [ 70  75 145]\n",
    "#      [ 80  85 165]\n",
    "#      [ 90  95 185]]\n",
    "\n",
    "# We may use three prior time steps of each of the two input time series to predict two time steps of the output\n",
    "# time series.\n",
    "\n",
    "# Input: 10, 15        Output: 65\n",
    "#        20, 25                85\n",
    "#        30, 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 2) (6, 2)\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] [65 85]\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] [ 85 105]\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] [105 125]\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] [125 145]\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] [145 165]\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] [165 185]\n"
     ]
    }
   ],
   "source": [
    "# multivariate multi-step data preparation\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    " \n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    " \n",
    "# define input sequence\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = np.array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(X.shape, y.shape)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[188.50548 211.53194]]\n"
     ]
    }
   ],
   "source": [
    "## vector output with a Stacked LSTM model :\n",
    "\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([[70, 75], [80, 85], [90, 95]])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Parallel Input and Multi-Step Output:\n",
    "# A problem with parallel time series may require the prediction of multiple time steps of each time series.\n",
    "\n",
    "# For example, consider our multivariate time series from a prior section:\n",
    "#    [[ 10  15  25]\n",
    "#     [ 20  25  45]\n",
    "#     [ 30  35  65]\n",
    "#     [ 40  45  85]\n",
    "#     [ 50  55 105]\n",
    "#     [ 60  65 125]\n",
    "#     [ 70  75 145]\n",
    "#     [ 80  85 165]\n",
    "#     [ 90  95 185]]\n",
    "\n",
    "# We may use the last three time steps from each of the three time series as input to the model and predict the\n",
    "# next time steps of each of the three time series as output.\n",
    "\n",
    "# The first sample in the training dataset would be the following.\n",
    "\n",
    "# Input: 10, 15, 25        Output: 40, 45, 85\n",
    "#        20, 25, 45                50, 55, 105\n",
    "#        30, 35, 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 3) (5, 2, 3)\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]] [[ 40  45  85]\n",
      " [ 50  55 105]]\n",
      "[[20 25 45]\n",
      " [30 35 65]\n",
      " [40 45 85]] [[ 50  55 105]\n",
      " [ 60  65 125]]\n",
      "[[ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]] [[ 60  65 125]\n",
      " [ 70  75 145]]\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]] [[ 70  75 145]\n",
      " [ 80  85 165]]\n",
      "[[ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]] [[ 80  85 165]\n",
      " [ 90  95 185]]\n"
     ]
    }
   ],
   "source": [
    "# multivariate multi-step data preparation\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    " \n",
    "# define input sequence\n",
    "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = np.array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(X.shape, y.shape)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 92.19106   97.599976 190.41624 ]\n",
      "  [103.94066  109.12895  213.57095 ]]]\n"
     ]
    }
   ],
   "source": [
    "## Encoder Decoder model :\n",
    "\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=300, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = np.array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
