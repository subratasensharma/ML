{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading data - an excell file :\n",
    "\n",
    "data1 = pd.ExcelFile('Tranzact2.xlsx')\n",
    "tranzact_data1 = data1.parse(0)\n",
    "\n",
    "lamba = len(tranzact_data1)\n",
    "\n",
    "tranzact_data2 = tranzact_data1.iloc[0:lamba, 0:3] ## Remove unnecessary columns\n",
    "\n",
    "tranzact_data2['Item'] = tranzact_data2['Item'].map(lambda x: x if type(x)!=str else x.lower()) ## make Items in lower case\n",
    "\n",
    "\n",
    "tranzact_data = tranzact_data2.dropna() ## remove rows with cell value none\n",
    "\n",
    "tranzact_data = tranzact_data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27044\n"
     ]
    }
   ],
   "source": [
    "## Cleaning the Item Description to create a feature matrix :\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "tranzact_data['features'] = tranzact_data['Item'].str.replace(r'\\b\\d+\\b','')  ## remove integers\n",
    "\n",
    "tranzact_data['features'] = tranzact_data['features'].str.replace(r'\\W',' ')   ## remove puntuations\n",
    "\n",
    "tranzact_data['features'] = tranzact_data['features'].str.replace(r'\\b\\d+\\mm\\b',' ')   ## remove all 'mm' dimensions only\n",
    "\n",
    "tranzact_data['features'] = tranzact_data['features'].str.replace(r'\\b\\w\\b','') ## remove stand alone single letters\n",
    "\n",
    "tranzact_data['features'] = tranzact_data['features'].str.replace(r'\\s+',' ') ## remove gaps between words to singe gap\n",
    "\n",
    "## Removing unneccessary words like measurment units etc.\n",
    "                                                                        \n",
    "words = stopwords.words(\"english\")\n",
    "words.remove('for')\n",
    "words.append('mm')\n",
    "words.append('ft')\n",
    "words.append('as')\n",
    "words.append('to')\n",
    "words.append('nos')\n",
    "\n",
    "tranzact_data['features']= tranzact_data['features'].apply(lambda x:' '.join([i for i in x.split()\n",
    "                                                                                if i not in words]).lower())\n",
    "\n",
    "\n",
    "## Removing duplicate words from individual features\n",
    "\n",
    "tranzact_data['features']= tranzact_data['features'].apply(lambda x:' '.join([i for i in (sorted(set(x.split()), \\\n",
    "                                                                                key=x.split().index))]).lower())\n",
    "\n",
    "## Removing only single word features :\n",
    "\n",
    "tranzact_data = tranzact_data[tranzact_data['features'].str.contains(' ')]\n",
    "tranzact_data = tranzact_data.reset_index(drop=True)\n",
    "\n",
    "print(len(tranzact_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27044\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tranzact_data)):\n",
    "    if tranzact_data['features'][i] == '':\n",
    "        \n",
    "        tranzact_data['Supplier'][i] = np.nan\n",
    "    \n",
    "        \n",
    "tranzact_data = tranzact_data.dropna()\n",
    "tranzact_data = tranzact_data.reset_index(drop=True)\n",
    "print(len(tranzact_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To check no. of Suppliers & no. of unique featuresin the data base :\n",
    "\n",
    "# print('Supplier = ', len(tranzact_data.Supplier.value_counts()))\n",
    "# print('Unique Features = ', len(tranzact_data.features.value_counts()))\n",
    "# print('Tranzact_data length = ', len(tranzact_data))\n",
    "# tranzact_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Above indicates that there are 2337 suppliers supplying 28921 items(as per no. of rows)\n",
    "## above indicates that there are 16728 unique features out of 28921 items(as per rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's reduce no. of Suppliers : criterian - apperaing at least 10 times in the data frame\n",
    "\n",
    "# tranzact_data_short = tranzact_data.groupby(\"Supplier\").filter(lambda x: len(x) > 10)\n",
    "\n",
    "# print(len(tranzact_data_short))\n",
    "# print(len(tranzact_data_short.Supplier.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Above indicates that there are now 391 suppliers supplying 23649 items(as per no. of rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing duplicate features + Supplier combinations :\n",
    "\n",
    "for i in range (len(tranzact_data)):\n",
    "    \n",
    "    idx_feature = []\n",
    "    idx_Supplier = []\n",
    "    idx_common = []\n",
    "\n",
    "    idx_feature = tranzact_data.index[tranzact_data['features'] == tranzact_data['features'][i]].tolist()\n",
    "    idx_Supplier = tranzact_data.index[tranzact_data['Supplier'] == tranzact_data['Supplier'][i]].tolist()\n",
    "    idx_common = list(set(idx_feature).intersection(idx_Supplier))\n",
    "    \n",
    "    if len(idx_common) > 1:\n",
    "        \n",
    "        tranzact_data['Supplier'][idx_common[1:]] = np.nan\n",
    "        \n",
    "tranzact_data_final = tranzact_data.dropna()\n",
    "tranzact_data_final = tranzact_data_final.reset_index(drop=True)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranzact_data_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To cross check no. of Suppliers & no. of unique features in the data base :\n",
    "\n",
    "# print('Supplier = ', len(tranzact_data_final.Supplier.value_counts()))\n",
    "# print('Unique Features = ', len(tranzact_data_final.features.value_counts()))\n",
    "# print('Total no. of entrys = ', len(tranzact_data_final))\n",
    "# tranzact_data_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating seacrh engine file  and digitising original features :\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "col = ['Supplier', 'features']\n",
    "tranzact_data_search = tranzact_data_final[col]\n",
    "\n",
    "\n",
    "tranzact_data_search['Supplier_id'] = tranzact_data_search['Supplier'].factorize()[0]  ## Indexing\n",
    "\n",
    "supplier_id_tranzact_data_search = tranzact_data_search[['Supplier', 'Supplier_id']].drop_duplicates(). \\\n",
    "                                                        sort_values('Supplier_id')\n",
    "\n",
    "## Create two dictionaries :\n",
    "\n",
    "supplier_to_id = dict(supplier_id_tranzact_data_search.values)\n",
    "id_to_supplier = dict(supplier_id_tranzact_data_search[['Supplier_id', 'Supplier']].values)\n",
    "\n",
    "## Digitising :\n",
    "\n",
    "my_vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=1, norm='l2', ngram_range=(1, 2))\n",
    "digital_features = my_vectorizer.fit(tranzact_data_search['features'])\n",
    "my_vector = digital_features.transform(tranzact_data_search['features']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input Text data :\n",
    "\n",
    "text_data = ['lock nut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From Teaxt data to text feature :\n",
    "\n",
    "text_data_lower_case = [x.lower() for x in text_data]\n",
    "\n",
    "text_data1 = pd.Series(text_data_lower_case)\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "text_data_feature = text_data1.str.replace(r'\\b\\d+\\b','')  ## remove integers\n",
    "\n",
    "text_data_feature = text_data_feature.str.replace(r'\\W',' ')   ## remove puntuations\n",
    "\n",
    "text_data_feature = text_data_feature.str.replace(r'\\b\\d+\\mm\\b',' ')   ## remove all 'mm' dimensions only\n",
    "\n",
    "text_data_feature = text_data_feature.str.replace(r'\\b\\w\\b','') ## remove stand alone single letters\n",
    "\n",
    "text_data_feature = text_data_feature.str.replace(r'\\s+',' ') ## remove gaps between words to singe gap\n",
    "\n",
    "\n",
    "## Removing unneccessary words like measurment units etc.\n",
    "                                                                        \n",
    "words = stopwords.words(\"english\")\n",
    "words.remove('for')\n",
    "words.append('mm')\n",
    "words.append('ft')\n",
    "words.append('as')\n",
    "words.append('to')\n",
    "words.append('nos')\n",
    "\n",
    "text_data_feature = text_data_feature.apply(lambda x:' '.join([i for i in x.split()\n",
    "                                                                                if i not in words]).lower())\n",
    "\n",
    "text_data_feature = text_data_feature.apply(lambda x:' '.join([i for i in (sorted(set(x.split()), \\\n",
    "                                                                                key=x.split().index))]).lower())\n",
    "## Cosine Similarity :\n",
    "\n",
    "def cos_cdist(matrix, vector):\n",
    "    v = vector.reshape(1, -1)\n",
    "    return scipy.spatial.distance.cdist(matrix, v, 'cosine').reshape(-1)\n",
    "\n",
    "## Creating test vector from Text features :\n",
    "\n",
    "merge_text_feature = []\n",
    "merge_text_feature_digit = []\n",
    "merge_digit_vector = []\n",
    "test_digit_vector = []\n",
    "\n",
    "merge_text_feature = tranzact_data_search['features'].append(pd.Series(text_data_feature))\n",
    "\n",
    "merge_text_feature = merge_text_feature.reset_index(drop=True)\n",
    "\n",
    "merge_text_feature_digit = my_vectorizer.fit(merge_text_feature)\n",
    "\n",
    "# encode document\n",
    "merge_digit_vector = merge_text_feature_digit.transform(merge_text_feature).toarray()\n",
    "\n",
    "\n",
    "test_digit_vector = merge_digit_vector[len(merge_digit_vector)-1].reshape((merge_digit_vector.shape)[1],)\n",
    "\n",
    "## Finding cosine similarity :\n",
    "\n",
    "c_d = []\n",
    "\n",
    "c_d = np.round((1 - cos_cdist(my_vector, test_digit_vector)), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MK Engineering Works\n",
      "Caliber Enterprises\n",
      "VAKRATUNDA\n",
      "CESARE BONETTI INDIA PVT. LTD.\n",
      "Shah Brothers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_index</th>\n",
       "      <th>Item</th>\n",
       "      <th>Supplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>lock nut</td>\n",
       "      <td>MK Engineering Works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>lock nut</td>\n",
       "      <td>Caliber Enterprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>lock nut</td>\n",
       "      <td>VAKRATUNDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>lock nut</td>\n",
       "      <td>CESARE BONETTI INDIA PVT. LTD.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>lock nut</td>\n",
       "      <td>Shah Brothers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600</td>\n",
       "      <td>lock nut m27x3p</td>\n",
       "      <td>Mahavir Enterprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.556</td>\n",
       "      <td>lock nut m20x2.5p</td>\n",
       "      <td>Waaree Industries Pvt.Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.541</td>\n",
       "      <td>lock nut m12x1.25p</td>\n",
       "      <td>DAMODAR ENTERPRISES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_index                Item                        Supplier\n",
       "0    1.000            lock nut            MK Engineering Works\n",
       "1    1.000            lock nut             Caliber Enterprises\n",
       "2    1.000            lock nut                      VAKRATUNDA\n",
       "3    1.000            lock nut  CESARE BONETTI INDIA PVT. LTD.\n",
       "4    1.000            lock nut                   Shah Brothers\n",
       "5    0.600     lock nut m27x3p             Mahavir Enterprises\n",
       "6    0.556   lock nut m20x2.5p      Waaree Industries Pvt.Ltd.\n",
       "7    0.541  lock nut m12x1.25p             DAMODAR ENTERPRISES"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "result_frame = []\n",
    "max_c_s_index = []\n",
    "max_c_s_index = np.argsort(c_d)[-50:][::-1]\n",
    "\n",
    "for i in max_c_s_index:\n",
    "    \n",
    "    result.append(np.array([c_d[i], tranzact_data_final['Item'][i], tranzact_data_search['Supplier'][i]]))\n",
    "\n",
    "result_frame = pd.DataFrame(result, columns=['c_index', 'Item', 'Supplier'])\n",
    "\n",
    "result_frame.c_index = result_frame.c_index.astype('float64')\n",
    "\n",
    "result_frame.drop_duplicates(subset='Supplier', keep = 'first', inplace = True)\n",
    "result_frame = result_frame.reset_index(drop=True)\n",
    "\n",
    "kount = 0\n",
    "\n",
    "for i in range(len(result_frame['Supplier'])):\n",
    "    if result_frame['c_index'][i] >= 0.10:\n",
    "        print(result_frame['Supplier'][i])\n",
    "        kount = kount+1\n",
    "        if kount == 5 :\n",
    "            break\n",
    "result_frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
